// Copyright 2023 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.8
// 	protoc        v3.21.6
// source: cloud/dataplex/v1/data.proto

package dataplexdata

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	durationpb "google.golang.org/protobuf/types/known/durationpb"
	timestamppb "google.golang.org/protobuf/types/known/timestamppb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// State of a resource.
type State int32

const (
	// State is not specified.
	State_STATE_UNSPECIFIED State = 0
	// Resource is active, i.e., ready to use.
	State_ACTIVE State = 1
	// Resource is under creation.
	State_CREATING State = 2
	// Resource is under deletion.
	State_DELETING State = 3
	// Resource is active but has unresolved actions.
	State_ACTION_REQUIRED State = 4
)

// Enum value maps for State.
var (
	State_name = map[int32]string{
		0: "STATE_UNSPECIFIED",
		1: "ACTIVE",
		2: "CREATING",
		3: "DELETING",
		4: "ACTION_REQUIRED",
	}
	State_value = map[string]int32{
		"STATE_UNSPECIFIED": 0,
		"ACTIVE":            1,
		"CREATING":          2,
		"DELETING":          3,
		"ACTION_REQUIRED":   4,
	}
)

func (x State) Enum() *State {
	p := new(State)
	*p = x
	return p
}

func (x State) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (State) Descriptor() protoreflect.EnumDescriptor {
	return file_cloud_dataplex_v1_data_proto_enumTypes[0].Descriptor()
}

func (State) Type() protoreflect.EnumType {
	return &file_cloud_dataplex_v1_data_proto_enumTypes[0]
}

func (x State) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use State.Descriptor instead.
func (State) EnumDescriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{0}
}

// The type of DataScan.
type DataScanType int32

const (
	// The DataScan type is unspecified.
	DataScanType_DATA_SCAN_TYPE_UNSPECIFIED DataScanType = 0
	// Data Quality scan.
	DataScanType_DATA_QUALITY DataScanType = 1
	// Data Profile scan.
	DataScanType_DATA_PROFILE DataScanType = 2
)

// Enum value maps for DataScanType.
var (
	DataScanType_name = map[int32]string{
		0: "DATA_SCAN_TYPE_UNSPECIFIED",
		1: "DATA_QUALITY",
		2: "DATA_PROFILE",
	}
	DataScanType_value = map[string]int32{
		"DATA_SCAN_TYPE_UNSPECIFIED": 0,
		"DATA_QUALITY":               1,
		"DATA_PROFILE":               2,
	}
)

func (x DataScanType) Enum() *DataScanType {
	p := new(DataScanType)
	*p = x
	return p
}

func (x DataScanType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (DataScanType) Descriptor() protoreflect.EnumDescriptor {
	return file_cloud_dataplex_v1_data_proto_enumTypes[1].Descriptor()
}

func (DataScanType) Type() protoreflect.EnumType {
	return &file_cloud_dataplex_v1_data_proto_enumTypes[1]
}

func (x DataScanType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use DataScanType.Descriptor instead.
func (DataScanType) EnumDescriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{1}
}

// Current state of association.
type Lake_MetastoreStatus_State int32

const (
	// Unspecified.
	Lake_MetastoreStatus_STATE_UNSPECIFIED Lake_MetastoreStatus_State = 0
	// A Metastore service instance is not associated with the lake.
	Lake_MetastoreStatus_NONE Lake_MetastoreStatus_State = 1
	// A Metastore service instance is attached to the lake.
	Lake_MetastoreStatus_READY Lake_MetastoreStatus_State = 2
	// Attach/detach is in progress.
	Lake_MetastoreStatus_UPDATING Lake_MetastoreStatus_State = 3
	// Attach/detach could not be done due to errors.
	Lake_MetastoreStatus_ERROR Lake_MetastoreStatus_State = 4
)

// Enum value maps for Lake_MetastoreStatus_State.
var (
	Lake_MetastoreStatus_State_name = map[int32]string{
		0: "STATE_UNSPECIFIED",
		1: "NONE",
		2: "READY",
		3: "UPDATING",
		4: "ERROR",
	}
	Lake_MetastoreStatus_State_value = map[string]int32{
		"STATE_UNSPECIFIED": 0,
		"NONE":              1,
		"READY":             2,
		"UPDATING":          3,
		"ERROR":             4,
	}
)

func (x Lake_MetastoreStatus_State) Enum() *Lake_MetastoreStatus_State {
	p := new(Lake_MetastoreStatus_State)
	*p = x
	return p
}

func (x Lake_MetastoreStatus_State) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Lake_MetastoreStatus_State) Descriptor() protoreflect.EnumDescriptor {
	return file_cloud_dataplex_v1_data_proto_enumTypes[2].Descriptor()
}

func (Lake_MetastoreStatus_State) Type() protoreflect.EnumType {
	return &file_cloud_dataplex_v1_data_proto_enumTypes[2]
}

func (x Lake_MetastoreStatus_State) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Lake_MetastoreStatus_State.Descriptor instead.
func (Lake_MetastoreStatus_State) EnumDescriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{0, 1, 0}
}

// Type of zone.
type Zone_Type int32

const (
	// Zone type not specified.
	Zone_TYPE_UNSPECIFIED Zone_Type = 0
	// A zone that contains data that needs further processing before it is
	// considered generally ready for consumption and analytics workloads.
	Zone_RAW Zone_Type = 1
	// A zone that contains data that is considered to be ready for broader
	// consumption and analytics workloads. Curated structured data stored in
	// Cloud Storage must conform to certain file formats (parquet, avro and
	// orc) and organized in a hive-compatible directory layout.
	Zone_CURATED Zone_Type = 2
)

// Enum value maps for Zone_Type.
var (
	Zone_Type_name = map[int32]string{
		0: "TYPE_UNSPECIFIED",
		1: "RAW",
		2: "CURATED",
	}
	Zone_Type_value = map[string]int32{
		"TYPE_UNSPECIFIED": 0,
		"RAW":              1,
		"CURATED":          2,
	}
)

func (x Zone_Type) Enum() *Zone_Type {
	p := new(Zone_Type)
	*p = x
	return p
}

func (x Zone_Type) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Zone_Type) Descriptor() protoreflect.EnumDescriptor {
	return file_cloud_dataplex_v1_data_proto_enumTypes[3].Descriptor()
}

func (Zone_Type) Type() protoreflect.EnumType {
	return &file_cloud_dataplex_v1_data_proto_enumTypes[3]
}

func (x Zone_Type) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Zone_Type.Descriptor instead.
func (Zone_Type) EnumDescriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{2, 0}
}

// Location type of the resources attached to a zone.
type Zone_ResourceSpec_LocationType int32

const (
	// Unspecified location type.
	Zone_ResourceSpec_LOCATION_TYPE_UNSPECIFIED Zone_ResourceSpec_LocationType = 0
	// Resources that are associated with a single region.
	Zone_ResourceSpec_SINGLE_REGION Zone_ResourceSpec_LocationType = 1
	// Resources that are associated with a multi-region location.
	Zone_ResourceSpec_MULTI_REGION Zone_ResourceSpec_LocationType = 2
)

// Enum value maps for Zone_ResourceSpec_LocationType.
var (
	Zone_ResourceSpec_LocationType_name = map[int32]string{
		0: "LOCATION_TYPE_UNSPECIFIED",
		1: "SINGLE_REGION",
		2: "MULTI_REGION",
	}
	Zone_ResourceSpec_LocationType_value = map[string]int32{
		"LOCATION_TYPE_UNSPECIFIED": 0,
		"SINGLE_REGION":             1,
		"MULTI_REGION":              2,
	}
)

func (x Zone_ResourceSpec_LocationType) Enum() *Zone_ResourceSpec_LocationType {
	p := new(Zone_ResourceSpec_LocationType)
	*p = x
	return p
}

func (x Zone_ResourceSpec_LocationType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Zone_ResourceSpec_LocationType) Descriptor() protoreflect.EnumDescriptor {
	return file_cloud_dataplex_v1_data_proto_enumTypes[4].Descriptor()
}

func (Zone_ResourceSpec_LocationType) Type() protoreflect.EnumType {
	return &file_cloud_dataplex_v1_data_proto_enumTypes[4]
}

func (x Zone_ResourceSpec_LocationType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Zone_ResourceSpec_LocationType.Descriptor instead.
func (Zone_ResourceSpec_LocationType) EnumDescriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{2, 0, 0}
}

// The state of the security policy.
type Asset_SecurityStatus_State int32

const (
	// State unspecified.
	Asset_SecurityStatus_STATE_UNSPECIFIED Asset_SecurityStatus_State = 0
	// Security policy has been successfully applied to the attached resource.
	Asset_SecurityStatus_READY Asset_SecurityStatus_State = 1
	// Security policy is in the process of being applied to the attached
	// resource.
	Asset_SecurityStatus_APPLYING Asset_SecurityStatus_State = 2
	// Security policy could not be applied to the attached resource due to
	// errors.
	Asset_SecurityStatus_ERROR Asset_SecurityStatus_State = 3
)

// Enum value maps for Asset_SecurityStatus_State.
var (
	Asset_SecurityStatus_State_name = map[int32]string{
		0: "STATE_UNSPECIFIED",
		1: "READY",
		2: "APPLYING",
		3: "ERROR",
	}
	Asset_SecurityStatus_State_value = map[string]int32{
		"STATE_UNSPECIFIED": 0,
		"READY":             1,
		"APPLYING":          2,
		"ERROR":             3,
	}
)

func (x Asset_SecurityStatus_State) Enum() *Asset_SecurityStatus_State {
	p := new(Asset_SecurityStatus_State)
	*p = x
	return p
}

func (x Asset_SecurityStatus_State) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Asset_SecurityStatus_State) Descriptor() protoreflect.EnumDescriptor {
	return file_cloud_dataplex_v1_data_proto_enumTypes[5].Descriptor()
}

func (Asset_SecurityStatus_State) Type() protoreflect.EnumType {
	return &file_cloud_dataplex_v1_data_proto_enumTypes[5]
}

func (x Asset_SecurityStatus_State) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Asset_SecurityStatus_State.Descriptor instead.
func (Asset_SecurityStatus_State) EnumDescriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{3, 0, 0}
}

// Type of resource.
type Asset_ResourceSpec_Type int32

const (
	// Type not specified.
	Asset_ResourceSpec_TYPE_UNSPECIFIED Asset_ResourceSpec_Type = 0
	// Cloud Storage bucket.
	Asset_ResourceSpec_STORAGE_BUCKET Asset_ResourceSpec_Type = 1
	// BigQuery dataset.
	Asset_ResourceSpec_BIGQUERY_DATASET Asset_ResourceSpec_Type = 2
)

// Enum value maps for Asset_ResourceSpec_Type.
var (
	Asset_ResourceSpec_Type_name = map[int32]string{
		0: "TYPE_UNSPECIFIED",
		1: "STORAGE_BUCKET",
		2: "BIGQUERY_DATASET",
	}
	Asset_ResourceSpec_Type_value = map[string]int32{
		"TYPE_UNSPECIFIED": 0,
		"STORAGE_BUCKET":   1,
		"BIGQUERY_DATASET": 2,
	}
)

func (x Asset_ResourceSpec_Type) Enum() *Asset_ResourceSpec_Type {
	p := new(Asset_ResourceSpec_Type)
	*p = x
	return p
}

func (x Asset_ResourceSpec_Type) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Asset_ResourceSpec_Type) Descriptor() protoreflect.EnumDescriptor {
	return file_cloud_dataplex_v1_data_proto_enumTypes[6].Descriptor()
}

func (Asset_ResourceSpec_Type) Type() protoreflect.EnumType {
	return &file_cloud_dataplex_v1_data_proto_enumTypes[6]
}

func (x Asset_ResourceSpec_Type) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Asset_ResourceSpec_Type.Descriptor instead.
func (Asset_ResourceSpec_Type) EnumDescriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{3, 2, 0}
}

// Access Mode determines how data stored within the resource is read. This
// is only applicable to storage bucket assets.
type Asset_ResourceSpec_AccessMode int32

const (
	// Access mode unspecified.
	Asset_ResourceSpec_ACCESS_MODE_UNSPECIFIED Asset_ResourceSpec_AccessMode = 0
	// Default. Data is accessed directly using storage APIs.
	Asset_ResourceSpec_DIRECT Asset_ResourceSpec_AccessMode = 1
	// Data is accessed through a managed interface using BigQuery APIs.
	Asset_ResourceSpec_MANAGED Asset_ResourceSpec_AccessMode = 2
)

// Enum value maps for Asset_ResourceSpec_AccessMode.
var (
	Asset_ResourceSpec_AccessMode_name = map[int32]string{
		0: "ACCESS_MODE_UNSPECIFIED",
		1: "DIRECT",
		2: "MANAGED",
	}
	Asset_ResourceSpec_AccessMode_value = map[string]int32{
		"ACCESS_MODE_UNSPECIFIED": 0,
		"DIRECT":                  1,
		"MANAGED":                 2,
	}
)

func (x Asset_ResourceSpec_AccessMode) Enum() *Asset_ResourceSpec_AccessMode {
	p := new(Asset_ResourceSpec_AccessMode)
	*p = x
	return p
}

func (x Asset_ResourceSpec_AccessMode) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Asset_ResourceSpec_AccessMode) Descriptor() protoreflect.EnumDescriptor {
	return file_cloud_dataplex_v1_data_proto_enumTypes[7].Descriptor()
}

func (Asset_ResourceSpec_AccessMode) Type() protoreflect.EnumType {
	return &file_cloud_dataplex_v1_data_proto_enumTypes[7]
}

func (x Asset_ResourceSpec_AccessMode) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Asset_ResourceSpec_AccessMode.Descriptor instead.
func (Asset_ResourceSpec_AccessMode) EnumDescriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{3, 2, 1}
}

// The state of a resource.
type Asset_ResourceStatus_State int32

const (
	// State unspecified.
	Asset_ResourceStatus_STATE_UNSPECIFIED Asset_ResourceStatus_State = 0
	// Resource does not have any errors.
	Asset_ResourceStatus_READY Asset_ResourceStatus_State = 1
	// Resource has errors.
	Asset_ResourceStatus_ERROR Asset_ResourceStatus_State = 2
)

// Enum value maps for Asset_ResourceStatus_State.
var (
	Asset_ResourceStatus_State_name = map[int32]string{
		0: "STATE_UNSPECIFIED",
		1: "READY",
		2: "ERROR",
	}
	Asset_ResourceStatus_State_value = map[string]int32{
		"STATE_UNSPECIFIED": 0,
		"READY":             1,
		"ERROR":             2,
	}
)

func (x Asset_ResourceStatus_State) Enum() *Asset_ResourceStatus_State {
	p := new(Asset_ResourceStatus_State)
	*p = x
	return p
}

func (x Asset_ResourceStatus_State) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Asset_ResourceStatus_State) Descriptor() protoreflect.EnumDescriptor {
	return file_cloud_dataplex_v1_data_proto_enumTypes[8].Descriptor()
}

func (Asset_ResourceStatus_State) Type() protoreflect.EnumType {
	return &file_cloud_dataplex_v1_data_proto_enumTypes[8]
}

func (x Asset_ResourceStatus_State) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Asset_ResourceStatus_State.Descriptor instead.
func (Asset_ResourceStatus_State) EnumDescriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{3, 3, 0}
}

// Current state of discovery.
type Asset_DiscoveryStatus_State int32

const (
	// State is unspecified.
	Asset_DiscoveryStatus_STATE_UNSPECIFIED Asset_DiscoveryStatus_State = 0
	// Discovery for the asset is scheduled.
	Asset_DiscoveryStatus_SCHEDULED Asset_DiscoveryStatus_State = 1
	// Discovery for the asset is running.
	Asset_DiscoveryStatus_IN_PROGRESS Asset_DiscoveryStatus_State = 2
	// Discovery for the asset is currently paused (e.g. due to a lack
	// of available resources). It will be automatically resumed.
	Asset_DiscoveryStatus_PAUSED Asset_DiscoveryStatus_State = 3
	// Discovery for the asset is disabled.
	Asset_DiscoveryStatus_DISABLED Asset_DiscoveryStatus_State = 5
)

// Enum value maps for Asset_DiscoveryStatus_State.
var (
	Asset_DiscoveryStatus_State_name = map[int32]string{
		0: "STATE_UNSPECIFIED",
		1: "SCHEDULED",
		2: "IN_PROGRESS",
		3: "PAUSED",
		5: "DISABLED",
	}
	Asset_DiscoveryStatus_State_value = map[string]int32{
		"STATE_UNSPECIFIED": 0,
		"SCHEDULED":         1,
		"IN_PROGRESS":       2,
		"PAUSED":            3,
		"DISABLED":          5,
	}
)

func (x Asset_DiscoveryStatus_State) Enum() *Asset_DiscoveryStatus_State {
	p := new(Asset_DiscoveryStatus_State)
	*p = x
	return p
}

func (x Asset_DiscoveryStatus_State) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Asset_DiscoveryStatus_State) Descriptor() protoreflect.EnumDescriptor {
	return file_cloud_dataplex_v1_data_proto_enumTypes[9].Descriptor()
}

func (Asset_DiscoveryStatus_State) Type() protoreflect.EnumType {
	return &file_cloud_dataplex_v1_data_proto_enumTypes[9]
}

func (x Asset_DiscoveryStatus_State) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Asset_DiscoveryStatus_State.Descriptor instead.
func (Asset_DiscoveryStatus_State) EnumDescriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{3, 4, 0}
}

type DataQualityRule_StatisticRangeExpectation_ColumnStatistic int32

const (
	// Unspecified statistic type
	DataQualityRule_StatisticRangeExpectation_STATISTIC_UNDEFINED DataQualityRule_StatisticRangeExpectation_ColumnStatistic = 0
	// Evaluate the column mean
	DataQualityRule_StatisticRangeExpectation_MEAN DataQualityRule_StatisticRangeExpectation_ColumnStatistic = 1
	// Evaluate the column min
	DataQualityRule_StatisticRangeExpectation_MIN DataQualityRule_StatisticRangeExpectation_ColumnStatistic = 2
	// Evaluate the column max
	DataQualityRule_StatisticRangeExpectation_MAX DataQualityRule_StatisticRangeExpectation_ColumnStatistic = 3
)

// Enum value maps for DataQualityRule_StatisticRangeExpectation_ColumnStatistic.
var (
	DataQualityRule_StatisticRangeExpectation_ColumnStatistic_name = map[int32]string{
		0: "STATISTIC_UNDEFINED",
		1: "MEAN",
		2: "MIN",
		3: "MAX",
	}
	DataQualityRule_StatisticRangeExpectation_ColumnStatistic_value = map[string]int32{
		"STATISTIC_UNDEFINED": 0,
		"MEAN":                1,
		"MIN":                 2,
		"MAX":                 3,
	}
)

func (x DataQualityRule_StatisticRangeExpectation_ColumnStatistic) Enum() *DataQualityRule_StatisticRangeExpectation_ColumnStatistic {
	p := new(DataQualityRule_StatisticRangeExpectation_ColumnStatistic)
	*p = x
	return p
}

func (x DataQualityRule_StatisticRangeExpectation_ColumnStatistic) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (DataQualityRule_StatisticRangeExpectation_ColumnStatistic) Descriptor() protoreflect.EnumDescriptor {
	return file_cloud_dataplex_v1_data_proto_enumTypes[10].Descriptor()
}

func (DataQualityRule_StatisticRangeExpectation_ColumnStatistic) Type() protoreflect.EnumType {
	return &file_cloud_dataplex_v1_data_proto_enumTypes[10]
}

func (x DataQualityRule_StatisticRangeExpectation_ColumnStatistic) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use DataQualityRule_StatisticRangeExpectation_ColumnStatistic.Descriptor instead.
func (DataQualityRule_StatisticRangeExpectation_ColumnStatistic) EnumDescriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{14, 5, 0}
}

// Determines how often and when the job will run.
type Task_TriggerSpec_Type int32

const (
	// Unspecified trigger type.
	Task_TriggerSpec_TYPE_UNSPECIFIED Task_TriggerSpec_Type = 0
	// The task runs one-time shortly after Task Creation.
	Task_TriggerSpec_ON_DEMAND Task_TriggerSpec_Type = 1
	// The task is scheduled to run periodically.
	Task_TriggerSpec_RECURRING Task_TriggerSpec_Type = 2
)

// Enum value maps for Task_TriggerSpec_Type.
var (
	Task_TriggerSpec_Type_name = map[int32]string{
		0: "TYPE_UNSPECIFIED",
		1: "ON_DEMAND",
		2: "RECURRING",
	}
	Task_TriggerSpec_Type_value = map[string]int32{
		"TYPE_UNSPECIFIED": 0,
		"ON_DEMAND":        1,
		"RECURRING":        2,
	}
)

func (x Task_TriggerSpec_Type) Enum() *Task_TriggerSpec_Type {
	p := new(Task_TriggerSpec_Type)
	*p = x
	return p
}

func (x Task_TriggerSpec_Type) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Task_TriggerSpec_Type) Descriptor() protoreflect.EnumDescriptor {
	return file_cloud_dataplex_v1_data_proto_enumTypes[11].Descriptor()
}

func (Task_TriggerSpec_Type) Type() protoreflect.EnumType {
	return &file_cloud_dataplex_v1_data_proto_enumTypes[11]
}

func (x Task_TriggerSpec_Type) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Task_TriggerSpec_Type.Descriptor instead.
func (Task_TriggerSpec_Type) EnumDescriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{21, 1, 0}
}

type Job_Service int32

const (
	// Service used to run the job is unspecified.
	Job_SERVICE_UNSPECIFIED Job_Service = 0
	// Dataproc service is used to run this job.
	Job_DATAPROC Job_Service = 1
)

// Enum value maps for Job_Service.
var (
	Job_Service_name = map[int32]string{
		0: "SERVICE_UNSPECIFIED",
		1: "DATAPROC",
	}
	Job_Service_value = map[string]int32{
		"SERVICE_UNSPECIFIED": 0,
		"DATAPROC":            1,
	}
)

func (x Job_Service) Enum() *Job_Service {
	p := new(Job_Service)
	*p = x
	return p
}

func (x Job_Service) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Job_Service) Descriptor() protoreflect.EnumDescriptor {
	return file_cloud_dataplex_v1_data_proto_enumTypes[12].Descriptor()
}

func (Job_Service) Type() protoreflect.EnumType {
	return &file_cloud_dataplex_v1_data_proto_enumTypes[12]
}

func (x Job_Service) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Job_Service.Descriptor instead.
func (Job_Service) EnumDescriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{22, 0}
}

type Job_State int32

const (
	// The job state is unknown.
	Job_STATE_UNSPECIFIED Job_State = 0
	// The job is running.
	Job_RUNNING Job_State = 1
	// The job is cancelling.
	Job_CANCELLING Job_State = 2
	// The job cancellation was successful.
	Job_CANCELLED Job_State = 3
	// The job completed successfully.
	Job_SUCCEEDED Job_State = 4
	// The job is no longer running due to an error.
	Job_FAILED Job_State = 5
	// The job was cancelled outside of Dataplex.
	Job_ABORTED Job_State = 6
)

// Enum value maps for Job_State.
var (
	Job_State_name = map[int32]string{
		0: "STATE_UNSPECIFIED",
		1: "RUNNING",
		2: "CANCELLING",
		3: "CANCELLED",
		4: "SUCCEEDED",
		5: "FAILED",
		6: "ABORTED",
	}
	Job_State_value = map[string]int32{
		"STATE_UNSPECIFIED": 0,
		"RUNNING":           1,
		"CANCELLING":        2,
		"CANCELLED":         3,
		"SUCCEEDED":         4,
		"FAILED":            5,
		"ABORTED":           6,
	}
)

func (x Job_State) Enum() *Job_State {
	p := new(Job_State)
	*p = x
	return p
}

func (x Job_State) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Job_State) Descriptor() protoreflect.EnumDescriptor {
	return file_cloud_dataplex_v1_data_proto_enumTypes[13].Descriptor()
}

func (Job_State) Type() protoreflect.EnumType {
	return &file_cloud_dataplex_v1_data_proto_enumTypes[13]
}

func (x Job_State) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Job_State.Descriptor instead.
func (Job_State) EnumDescriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{22, 1}
}

// A lake is a centralized repository for managing enterprise data across the
// organization distributed across many cloud projects, and stored in a variety
// of storage services such as Google Cloud Storage and BigQuery. The resources
// attached to a lake are referred to as managed resources. Data within these
// managed resources can be structured or unstructured. A lake provides data
// admins with tools to organize, secure and manage their data at scale, and
// provides data scientists and data engineers an integrated experience to
// easily search, discover, analyze and transform data and associated metadata.
type Lake struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Output only. The relative resource name of the lake, of the form:
	// `projects/{project_number}/locations/{location_id}/lakes/{lake_id}`.
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Optional. User friendly display name.
	DisplayName string `protobuf:"bytes,2,opt,name=display_name,json=displayName,proto3" json:"display_name,omitempty"`
	// Output only. System generated globally unique ID for the lake. This ID will
	// be different if the lake is deleted and re-created with the same name.
	Uid string `protobuf:"bytes,3,opt,name=uid,proto3" json:"uid,omitempty"`
	// Output only. The time when the lake was created.
	CreateTime *timestamppb.Timestamp `protobuf:"bytes,4,opt,name=create_time,json=createTime,proto3" json:"create_time,omitempty"`
	// Output only. The time when the lake was last updated.
	UpdateTime *timestamppb.Timestamp `protobuf:"bytes,5,opt,name=update_time,json=updateTime,proto3" json:"update_time,omitempty"`
	// Optional. User-defined labels for the lake.
	Labels map[string]string `protobuf:"bytes,6,rep,name=labels,proto3" json:"labels,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	// Optional. Description of the lake.
	Description string `protobuf:"bytes,7,opt,name=description,proto3" json:"description,omitempty"`
	// Output only. Current state of the lake.
	State State `protobuf:"varint,8,opt,name=state,proto3,enum=google.events.cloud.dataplex.v1.State" json:"state,omitempty"`
	// Output only. Service account associated with this lake. This service
	// account must be authorized to access or operate on resources managed by the
	// lake.
	ServiceAccount string `protobuf:"bytes,9,opt,name=service_account,json=serviceAccount,proto3" json:"service_account,omitempty"`
	// Optional. Settings to manage lake and Dataproc Metastore service instance
	// association.
	Metastore *Lake_Metastore `protobuf:"bytes,102,opt,name=metastore,proto3" json:"metastore,omitempty"`
	// Output only. Aggregated status of the underlying assets of the lake.
	AssetStatus *AssetStatus `protobuf:"bytes,103,opt,name=asset_status,json=assetStatus,proto3" json:"asset_status,omitempty"`
	// Output only. Metastore status of the lake.
	MetastoreStatus *Lake_MetastoreStatus `protobuf:"bytes,104,opt,name=metastore_status,json=metastoreStatus,proto3" json:"metastore_status,omitempty"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *Lake) Reset() {
	*x = Lake{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Lake) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Lake) ProtoMessage() {}

func (x *Lake) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Lake.ProtoReflect.Descriptor instead.
func (*Lake) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{0}
}

func (x *Lake) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *Lake) GetDisplayName() string {
	if x != nil {
		return x.DisplayName
	}
	return ""
}

func (x *Lake) GetUid() string {
	if x != nil {
		return x.Uid
	}
	return ""
}

func (x *Lake) GetCreateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.CreateTime
	}
	return nil
}

func (x *Lake) GetUpdateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.UpdateTime
	}
	return nil
}

func (x *Lake) GetLabels() map[string]string {
	if x != nil {
		return x.Labels
	}
	return nil
}

func (x *Lake) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *Lake) GetState() State {
	if x != nil {
		return x.State
	}
	return State_STATE_UNSPECIFIED
}

func (x *Lake) GetServiceAccount() string {
	if x != nil {
		return x.ServiceAccount
	}
	return ""
}

func (x *Lake) GetMetastore() *Lake_Metastore {
	if x != nil {
		return x.Metastore
	}
	return nil
}

func (x *Lake) GetAssetStatus() *AssetStatus {
	if x != nil {
		return x.AssetStatus
	}
	return nil
}

func (x *Lake) GetMetastoreStatus() *Lake_MetastoreStatus {
	if x != nil {
		return x.MetastoreStatus
	}
	return nil
}

// Aggregated status of the underlying assets of a lake or zone.
type AssetStatus struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Last update time of the status.
	UpdateTime *timestamppb.Timestamp `protobuf:"bytes,1,opt,name=update_time,json=updateTime,proto3" json:"update_time,omitempty"`
	// Number of active assets.
	ActiveAssets int32 `protobuf:"varint,2,opt,name=active_assets,json=activeAssets,proto3" json:"active_assets,omitempty"`
	// Number of assets that are in process of updating the security policy on
	// attached resources.
	SecurityPolicyApplyingAssets int32 `protobuf:"varint,3,opt,name=security_policy_applying_assets,json=securityPolicyApplyingAssets,proto3" json:"security_policy_applying_assets,omitempty"`
	unknownFields                protoimpl.UnknownFields
	sizeCache                    protoimpl.SizeCache
}

func (x *AssetStatus) Reset() {
	*x = AssetStatus{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AssetStatus) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AssetStatus) ProtoMessage() {}

func (x *AssetStatus) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AssetStatus.ProtoReflect.Descriptor instead.
func (*AssetStatus) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{1}
}

func (x *AssetStatus) GetUpdateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.UpdateTime
	}
	return nil
}

func (x *AssetStatus) GetActiveAssets() int32 {
	if x != nil {
		return x.ActiveAssets
	}
	return 0
}

func (x *AssetStatus) GetSecurityPolicyApplyingAssets() int32 {
	if x != nil {
		return x.SecurityPolicyApplyingAssets
	}
	return 0
}

// A zone represents a logical group of related assets within a lake. A zone can
// be used to map to organizational structure or represent stages of data
// readiness from raw to curated. It provides managing behavior that is shared
// or inherited by all contained assets.
type Zone struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Output only. The relative resource name of the zone, of the form:
	// `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}`.
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Optional. User friendly display name.
	DisplayName string `protobuf:"bytes,2,opt,name=display_name,json=displayName,proto3" json:"display_name,omitempty"`
	// Output only. System generated globally unique ID for the zone. This ID will
	// be different if the zone is deleted and re-created with the same name.
	Uid string `protobuf:"bytes,3,opt,name=uid,proto3" json:"uid,omitempty"`
	// Output only. The time when the zone was created.
	CreateTime *timestamppb.Timestamp `protobuf:"bytes,4,opt,name=create_time,json=createTime,proto3" json:"create_time,omitempty"`
	// Output only. The time when the zone was last updated.
	UpdateTime *timestamppb.Timestamp `protobuf:"bytes,5,opt,name=update_time,json=updateTime,proto3" json:"update_time,omitempty"`
	// Optional. User defined labels for the zone.
	Labels map[string]string `protobuf:"bytes,6,rep,name=labels,proto3" json:"labels,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	// Optional. Description of the zone.
	Description string `protobuf:"bytes,7,opt,name=description,proto3" json:"description,omitempty"`
	// Output only. Current state of the zone.
	State State `protobuf:"varint,8,opt,name=state,proto3,enum=google.events.cloud.dataplex.v1.State" json:"state,omitempty"`
	// Required. Immutable. The type of the zone.
	Type Zone_Type `protobuf:"varint,9,opt,name=type,proto3,enum=google.events.cloud.dataplex.v1.Zone_Type" json:"type,omitempty"`
	// Optional. Specification of the discovery feature applied to data in this
	// zone.
	DiscoverySpec *Zone_DiscoverySpec `protobuf:"bytes,103,opt,name=discovery_spec,json=discoverySpec,proto3" json:"discovery_spec,omitempty"`
	// Required. Specification of the resources that are referenced by the assets
	// within this zone.
	ResourceSpec *Zone_ResourceSpec `protobuf:"bytes,104,opt,name=resource_spec,json=resourceSpec,proto3" json:"resource_spec,omitempty"`
	// Output only. Aggregated status of the underlying assets of the zone.
	AssetStatus   *AssetStatus `protobuf:"bytes,105,opt,name=asset_status,json=assetStatus,proto3" json:"asset_status,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Zone) Reset() {
	*x = Zone{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Zone) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Zone) ProtoMessage() {}

func (x *Zone) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Zone.ProtoReflect.Descriptor instead.
func (*Zone) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{2}
}

func (x *Zone) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *Zone) GetDisplayName() string {
	if x != nil {
		return x.DisplayName
	}
	return ""
}

func (x *Zone) GetUid() string {
	if x != nil {
		return x.Uid
	}
	return ""
}

func (x *Zone) GetCreateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.CreateTime
	}
	return nil
}

func (x *Zone) GetUpdateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.UpdateTime
	}
	return nil
}

func (x *Zone) GetLabels() map[string]string {
	if x != nil {
		return x.Labels
	}
	return nil
}

func (x *Zone) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *Zone) GetState() State {
	if x != nil {
		return x.State
	}
	return State_STATE_UNSPECIFIED
}

func (x *Zone) GetType() Zone_Type {
	if x != nil {
		return x.Type
	}
	return Zone_TYPE_UNSPECIFIED
}

func (x *Zone) GetDiscoverySpec() *Zone_DiscoverySpec {
	if x != nil {
		return x.DiscoverySpec
	}
	return nil
}

func (x *Zone) GetResourceSpec() *Zone_ResourceSpec {
	if x != nil {
		return x.ResourceSpec
	}
	return nil
}

func (x *Zone) GetAssetStatus() *AssetStatus {
	if x != nil {
		return x.AssetStatus
	}
	return nil
}

// An asset represents a cloud resource that is being managed within a lake as a
// member of a zone.
type Asset struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Output only. The relative resource name of the asset, of the form:
	// `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/assets/{asset_id}`.
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Optional. User friendly display name.
	DisplayName string `protobuf:"bytes,2,opt,name=display_name,json=displayName,proto3" json:"display_name,omitempty"`
	// Output only. System generated globally unique ID for the asset. This ID
	// will be different if the asset is deleted and re-created with the same
	// name.
	Uid string `protobuf:"bytes,3,opt,name=uid,proto3" json:"uid,omitempty"`
	// Output only. The time when the asset was created.
	CreateTime *timestamppb.Timestamp `protobuf:"bytes,4,opt,name=create_time,json=createTime,proto3" json:"create_time,omitempty"`
	// Output only. The time when the asset was last updated.
	UpdateTime *timestamppb.Timestamp `protobuf:"bytes,5,opt,name=update_time,json=updateTime,proto3" json:"update_time,omitempty"`
	// Optional. User defined labels for the asset.
	Labels map[string]string `protobuf:"bytes,6,rep,name=labels,proto3" json:"labels,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	// Optional. Description of the asset.
	Description string `protobuf:"bytes,7,opt,name=description,proto3" json:"description,omitempty"`
	// Output only. Current state of the asset.
	State State `protobuf:"varint,8,opt,name=state,proto3,enum=google.events.cloud.dataplex.v1.State" json:"state,omitempty"`
	// Required. Specification of the resource that is referenced by this asset.
	ResourceSpec *Asset_ResourceSpec `protobuf:"bytes,100,opt,name=resource_spec,json=resourceSpec,proto3" json:"resource_spec,omitempty"`
	// Output only. Status of the resource referenced by this asset.
	ResourceStatus *Asset_ResourceStatus `protobuf:"bytes,101,opt,name=resource_status,json=resourceStatus,proto3" json:"resource_status,omitempty"`
	// Output only. Status of the security policy applied to resource referenced
	// by this asset.
	SecurityStatus *Asset_SecurityStatus `protobuf:"bytes,103,opt,name=security_status,json=securityStatus,proto3" json:"security_status,omitempty"`
	// Optional. Specification of the discovery feature applied to data referenced
	// by this asset. When this spec is left unset, the asset will use the spec
	// set on the parent zone.
	DiscoverySpec *Asset_DiscoverySpec `protobuf:"bytes,106,opt,name=discovery_spec,json=discoverySpec,proto3" json:"discovery_spec,omitempty"`
	// Output only. Status of the discovery feature applied to data referenced by
	// this asset.
	DiscoveryStatus *Asset_DiscoveryStatus `protobuf:"bytes,107,opt,name=discovery_status,json=discoveryStatus,proto3" json:"discovery_status,omitempty"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *Asset) Reset() {
	*x = Asset{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Asset) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Asset) ProtoMessage() {}

func (x *Asset) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Asset.ProtoReflect.Descriptor instead.
func (*Asset) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{3}
}

func (x *Asset) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *Asset) GetDisplayName() string {
	if x != nil {
		return x.DisplayName
	}
	return ""
}

func (x *Asset) GetUid() string {
	if x != nil {
		return x.Uid
	}
	return ""
}

func (x *Asset) GetCreateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.CreateTime
	}
	return nil
}

func (x *Asset) GetUpdateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.UpdateTime
	}
	return nil
}

func (x *Asset) GetLabels() map[string]string {
	if x != nil {
		return x.Labels
	}
	return nil
}

func (x *Asset) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *Asset) GetState() State {
	if x != nil {
		return x.State
	}
	return State_STATE_UNSPECIFIED
}

func (x *Asset) GetResourceSpec() *Asset_ResourceSpec {
	if x != nil {
		return x.ResourceSpec
	}
	return nil
}

func (x *Asset) GetResourceStatus() *Asset_ResourceStatus {
	if x != nil {
		return x.ResourceStatus
	}
	return nil
}

func (x *Asset) GetSecurityStatus() *Asset_SecurityStatus {
	if x != nil {
		return x.SecurityStatus
	}
	return nil
}

func (x *Asset) GetDiscoverySpec() *Asset_DiscoverySpec {
	if x != nil {
		return x.DiscoverySpec
	}
	return nil
}

func (x *Asset) GetDiscoveryStatus() *Asset_DiscoveryStatus {
	if x != nil {
		return x.DiscoveryStatus
	}
	return nil
}

// Environment represents a user-visible compute infrastructure for analytics
// within a lake.
type Environment struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Output only. The relative resource name of the environment, of the form:
	// projects/{project_id}/locations/{location_id}/lakes/{lake_id}/environment/{environment_id}
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Optional. User friendly display name.
	DisplayName string `protobuf:"bytes,2,opt,name=display_name,json=displayName,proto3" json:"display_name,omitempty"`
	// Output only. System generated globally unique ID for the environment. This
	// ID will be different if the environment is deleted and re-created with the
	// same name.
	Uid string `protobuf:"bytes,3,opt,name=uid,proto3" json:"uid,omitempty"`
	// Output only. Environment creation time.
	CreateTime *timestamppb.Timestamp `protobuf:"bytes,4,opt,name=create_time,json=createTime,proto3" json:"create_time,omitempty"`
	// Output only. The time when the environment was last updated.
	UpdateTime *timestamppb.Timestamp `protobuf:"bytes,5,opt,name=update_time,json=updateTime,proto3" json:"update_time,omitempty"`
	// Optional. User defined labels for the environment.
	Labels map[string]string `protobuf:"bytes,6,rep,name=labels,proto3" json:"labels,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	// Optional. Description of the environment.
	Description string `protobuf:"bytes,7,opt,name=description,proto3" json:"description,omitempty"`
	// Output only. Current state of the environment.
	State State `protobuf:"varint,8,opt,name=state,proto3,enum=google.events.cloud.dataplex.v1.State" json:"state,omitempty"`
	// Required. Infrastructure specification for the Environment.
	InfrastructureSpec *Environment_InfrastructureSpec `protobuf:"bytes,100,opt,name=infrastructure_spec,json=infrastructureSpec,proto3" json:"infrastructure_spec,omitempty"`
	// Optional. Configuration for sessions created for this environment.
	SessionSpec *Environment_SessionSpec `protobuf:"bytes,101,opt,name=session_spec,json=sessionSpec,proto3" json:"session_spec,omitempty"`
	// Output only. Status of sessions created for this environment.
	SessionStatus *Environment_SessionStatus `protobuf:"bytes,102,opt,name=session_status,json=sessionStatus,proto3" json:"session_status,omitempty"`
	// Output only. URI Endpoints to access sessions associated with the
	// Environment.
	Endpoints     *Environment_Endpoints `protobuf:"bytes,200,opt,name=endpoints,proto3" json:"endpoints,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Environment) Reset() {
	*x = Environment{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Environment) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Environment) ProtoMessage() {}

func (x *Environment) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Environment.ProtoReflect.Descriptor instead.
func (*Environment) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{4}
}

func (x *Environment) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *Environment) GetDisplayName() string {
	if x != nil {
		return x.DisplayName
	}
	return ""
}

func (x *Environment) GetUid() string {
	if x != nil {
		return x.Uid
	}
	return ""
}

func (x *Environment) GetCreateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.CreateTime
	}
	return nil
}

func (x *Environment) GetUpdateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.UpdateTime
	}
	return nil
}

func (x *Environment) GetLabels() map[string]string {
	if x != nil {
		return x.Labels
	}
	return nil
}

func (x *Environment) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *Environment) GetState() State {
	if x != nil {
		return x.State
	}
	return State_STATE_UNSPECIFIED
}

func (x *Environment) GetInfrastructureSpec() *Environment_InfrastructureSpec {
	if x != nil {
		return x.InfrastructureSpec
	}
	return nil
}

func (x *Environment) GetSessionSpec() *Environment_SessionSpec {
	if x != nil {
		return x.SessionSpec
	}
	return nil
}

func (x *Environment) GetSessionStatus() *Environment_SessionStatus {
	if x != nil {
		return x.SessionStatus
	}
	return nil
}

func (x *Environment) GetEndpoints() *Environment_Endpoints {
	if x != nil {
		return x.Endpoints
	}
	return nil
}

// DataScan scheduling and trigger settings.
type Trigger struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// DataScan scheduling and trigger settings.
	//
	// If not specified, the default is `onDemand`.
	//
	// Types that are valid to be assigned to Mode:
	//
	//	*Trigger_OnDemand_
	//	*Trigger_Schedule_
	Mode          isTrigger_Mode `protobuf_oneof:"mode"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Trigger) Reset() {
	*x = Trigger{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Trigger) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Trigger) ProtoMessage() {}

func (x *Trigger) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Trigger.ProtoReflect.Descriptor instead.
func (*Trigger) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{5}
}

func (x *Trigger) GetMode() isTrigger_Mode {
	if x != nil {
		return x.Mode
	}
	return nil
}

func (x *Trigger) GetOnDemand() *Trigger_OnDemand {
	if x != nil {
		if x, ok := x.Mode.(*Trigger_OnDemand_); ok {
			return x.OnDemand
		}
	}
	return nil
}

func (x *Trigger) GetSchedule() *Trigger_Schedule {
	if x != nil {
		if x, ok := x.Mode.(*Trigger_Schedule_); ok {
			return x.Schedule
		}
	}
	return nil
}

type isTrigger_Mode interface {
	isTrigger_Mode()
}

type Trigger_OnDemand_ struct {
	// The scan runs once via `RunDataScan` API.
	OnDemand *Trigger_OnDemand `protobuf:"bytes,100,opt,name=on_demand,json=onDemand,proto3,oneof"`
}

type Trigger_Schedule_ struct {
	// The scan is scheduled to run periodically.
	Schedule *Trigger_Schedule `protobuf:"bytes,101,opt,name=schedule,proto3,oneof"`
}

func (*Trigger_OnDemand_) isTrigger_Mode() {}

func (*Trigger_Schedule_) isTrigger_Mode() {}

// The data source for DataScan.
type DataSource struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The source is required and immutable. Once it is set, it cannot be change
	// to others.
	//
	// Types that are valid to be assigned to Source:
	//
	//	*DataSource_Entity
	Source        isDataSource_Source `protobuf_oneof:"source"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataSource) Reset() {
	*x = DataSource{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataSource) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataSource) ProtoMessage() {}

func (x *DataSource) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataSource.ProtoReflect.Descriptor instead.
func (*DataSource) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{6}
}

func (x *DataSource) GetSource() isDataSource_Source {
	if x != nil {
		return x.Source
	}
	return nil
}

func (x *DataSource) GetEntity() string {
	if x != nil {
		if x, ok := x.Source.(*DataSource_Entity); ok {
			return x.Entity
		}
	}
	return ""
}

type isDataSource_Source interface {
	isDataSource_Source()
}

type DataSource_Entity struct {
	// Immutable. The Dataplex entity that represents the data source (e.g.
	// BigQuery table) for DataScan, of the form:
	// `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}`.
	Entity string `protobuf:"bytes,100,opt,name=entity,proto3,oneof"`
}

func (*DataSource_Entity) isDataSource_Source() {}

// The data scanned during processing (e.g. in incremental DataScan)
type ScannedData struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The range of scanned data
	//
	// Types that are valid to be assigned to DataRange:
	//
	//	*ScannedData_IncrementalField_
	DataRange     isScannedData_DataRange `protobuf_oneof:"data_range"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ScannedData) Reset() {
	*x = ScannedData{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ScannedData) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ScannedData) ProtoMessage() {}

func (x *ScannedData) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ScannedData.ProtoReflect.Descriptor instead.
func (*ScannedData) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{7}
}

func (x *ScannedData) GetDataRange() isScannedData_DataRange {
	if x != nil {
		return x.DataRange
	}
	return nil
}

func (x *ScannedData) GetIncrementalField() *ScannedData_IncrementalField {
	if x != nil {
		if x, ok := x.DataRange.(*ScannedData_IncrementalField_); ok {
			return x.IncrementalField
		}
	}
	return nil
}

type isScannedData_DataRange interface {
	isScannedData_DataRange()
}

type ScannedData_IncrementalField_ struct {
	// The range denoted by values of an incremental field
	IncrementalField *ScannedData_IncrementalField `protobuf:"bytes,1,opt,name=incremental_field,json=incrementalField,proto3,oneof"`
}

func (*ScannedData_IncrementalField_) isScannedData_DataRange() {}

// DataProfileScan related setting.
type DataProfileSpec struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataProfileSpec) Reset() {
	*x = DataProfileSpec{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataProfileSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataProfileSpec) ProtoMessage() {}

func (x *DataProfileSpec) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataProfileSpec.ProtoReflect.Descriptor instead.
func (*DataProfileSpec) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{8}
}

// DataProfileResult defines the output of DataProfileScan. Each field of the
// table will have field type specific profile result.
type DataProfileResult struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The count of rows scanned.
	RowCount int64 `protobuf:"varint,3,opt,name=row_count,json=rowCount,proto3" json:"row_count,omitempty"`
	// The profile information per field.
	Profile *DataProfileResult_Profile `protobuf:"bytes,4,opt,name=profile,proto3" json:"profile,omitempty"`
	// The data scanned for this result.
	ScannedData   *ScannedData `protobuf:"bytes,5,opt,name=scanned_data,json=scannedData,proto3" json:"scanned_data,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataProfileResult) Reset() {
	*x = DataProfileResult{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataProfileResult) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataProfileResult) ProtoMessage() {}

func (x *DataProfileResult) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataProfileResult.ProtoReflect.Descriptor instead.
func (*DataProfileResult) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{9}
}

func (x *DataProfileResult) GetRowCount() int64 {
	if x != nil {
		return x.RowCount
	}
	return 0
}

func (x *DataProfileResult) GetProfile() *DataProfileResult_Profile {
	if x != nil {
		return x.Profile
	}
	return nil
}

func (x *DataProfileResult) GetScannedData() *ScannedData {
	if x != nil {
		return x.ScannedData
	}
	return nil
}

// DataQualityScan related setting.
type DataQualitySpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The list of rules to evaluate against a data source. At least one rule is
	// required.
	Rules         []*DataQualityRule `protobuf:"bytes,1,rep,name=rules,proto3" json:"rules,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataQualitySpec) Reset() {
	*x = DataQualitySpec{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataQualitySpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataQualitySpec) ProtoMessage() {}

func (x *DataQualitySpec) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataQualitySpec.ProtoReflect.Descriptor instead.
func (*DataQualitySpec) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{10}
}

func (x *DataQualitySpec) GetRules() []*DataQualityRule {
	if x != nil {
		return x.Rules
	}
	return nil
}

// The output of a DataQualityScan.
type DataQualityResult struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Overall data quality result -- `true` if all rules passed.
	Passed bool `protobuf:"varint,5,opt,name=passed,proto3" json:"passed,omitempty"`
	// A list of results at the dimension level.
	Dimensions []*DataQualityDimensionResult `protobuf:"bytes,2,rep,name=dimensions,proto3" json:"dimensions,omitempty"`
	// A list of all the rules in a job, and their results.
	Rules []*DataQualityRuleResult `protobuf:"bytes,3,rep,name=rules,proto3" json:"rules,omitempty"`
	// The count of rows processed.
	RowCount int64 `protobuf:"varint,4,opt,name=row_count,json=rowCount,proto3" json:"row_count,omitempty"`
	// The data scanned for this result.
	ScannedData   *ScannedData `protobuf:"bytes,7,opt,name=scanned_data,json=scannedData,proto3" json:"scanned_data,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataQualityResult) Reset() {
	*x = DataQualityResult{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataQualityResult) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataQualityResult) ProtoMessage() {}

func (x *DataQualityResult) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataQualityResult.ProtoReflect.Descriptor instead.
func (*DataQualityResult) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{11}
}

func (x *DataQualityResult) GetPassed() bool {
	if x != nil {
		return x.Passed
	}
	return false
}

func (x *DataQualityResult) GetDimensions() []*DataQualityDimensionResult {
	if x != nil {
		return x.Dimensions
	}
	return nil
}

func (x *DataQualityResult) GetRules() []*DataQualityRuleResult {
	if x != nil {
		return x.Rules
	}
	return nil
}

func (x *DataQualityResult) GetRowCount() int64 {
	if x != nil {
		return x.RowCount
	}
	return 0
}

func (x *DataQualityResult) GetScannedData() *ScannedData {
	if x != nil {
		return x.ScannedData
	}
	return nil
}

// DataQualityRuleResult provides a more detailed, per-rule view of the results.
type DataQualityRuleResult struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The rule specified in the DataQualitySpec, as is.
	Rule *DataQualityRule `protobuf:"bytes,1,opt,name=rule,proto3" json:"rule,omitempty"`
	// Whether the rule passed or failed.
	Passed bool `protobuf:"varint,7,opt,name=passed,proto3" json:"passed,omitempty"`
	// The number of rows a rule was evaluated against. This field is only valid
	// for ColumnMap type rules.
	//
	// # Evaluated count can be configured to either
	//
	// * include all rows (default) - with `null` rows automatically failing rule
	// evaluation, or
	// * exclude `null` rows from the `evaluated_count`, by setting
	// `ignore_nulls = true`.
	EvaluatedCount int64 `protobuf:"varint,9,opt,name=evaluated_count,json=evaluatedCount,proto3" json:"evaluated_count,omitempty"`
	// The number of rows which passed a rule evaluation.
	// This field is only valid for ColumnMap type rules.
	PassedCount int64 `protobuf:"varint,8,opt,name=passed_count,json=passedCount,proto3" json:"passed_count,omitempty"`
	// The number of rows with null values in the specified column.
	NullCount int64 `protobuf:"varint,5,opt,name=null_count,json=nullCount,proto3" json:"null_count,omitempty"`
	// The ratio of **passed_count / evaluated_count**.
	// This field is only valid for ColumnMap type rules.
	PassRatio float64 `protobuf:"fixed64,6,opt,name=pass_ratio,json=passRatio,proto3" json:"pass_ratio,omitempty"`
	// The query to find rows that did not pass this rule.
	// Only applies to ColumnMap and RowCondition rules.
	FailingRowsQuery string `protobuf:"bytes,10,opt,name=failing_rows_query,json=failingRowsQuery,proto3" json:"failing_rows_query,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *DataQualityRuleResult) Reset() {
	*x = DataQualityRuleResult{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataQualityRuleResult) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataQualityRuleResult) ProtoMessage() {}

func (x *DataQualityRuleResult) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataQualityRuleResult.ProtoReflect.Descriptor instead.
func (*DataQualityRuleResult) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{12}
}

func (x *DataQualityRuleResult) GetRule() *DataQualityRule {
	if x != nil {
		return x.Rule
	}
	return nil
}

func (x *DataQualityRuleResult) GetPassed() bool {
	if x != nil {
		return x.Passed
	}
	return false
}

func (x *DataQualityRuleResult) GetEvaluatedCount() int64 {
	if x != nil {
		return x.EvaluatedCount
	}
	return 0
}

func (x *DataQualityRuleResult) GetPassedCount() int64 {
	if x != nil {
		return x.PassedCount
	}
	return 0
}

func (x *DataQualityRuleResult) GetNullCount() int64 {
	if x != nil {
		return x.NullCount
	}
	return 0
}

func (x *DataQualityRuleResult) GetPassRatio() float64 {
	if x != nil {
		return x.PassRatio
	}
	return 0
}

func (x *DataQualityRuleResult) GetFailingRowsQuery() string {
	if x != nil {
		return x.FailingRowsQuery
	}
	return ""
}

// DataQualityDimensionResult provides a more detailed, per-dimension view of
// the results.
type DataQualityDimensionResult struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Whether the dimension passed or failed.
	Passed        bool `protobuf:"varint,3,opt,name=passed,proto3" json:"passed,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataQualityDimensionResult) Reset() {
	*x = DataQualityDimensionResult{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataQualityDimensionResult) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataQualityDimensionResult) ProtoMessage() {}

func (x *DataQualityDimensionResult) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataQualityDimensionResult.ProtoReflect.Descriptor instead.
func (*DataQualityDimensionResult) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{13}
}

func (x *DataQualityDimensionResult) GetPassed() bool {
	if x != nil {
		return x.Passed
	}
	return false
}

// A rule captures data quality intent about a data source.
type DataQualityRule struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to RuleType:
	//
	//	*DataQualityRule_RangeExpectation_
	//	*DataQualityRule_NonNullExpectation_
	//	*DataQualityRule_SetExpectation_
	//	*DataQualityRule_RegexExpectation_
	//	*DataQualityRule_UniquenessExpectation_
	//	*DataQualityRule_StatisticRangeExpectation_
	//	*DataQualityRule_RowConditionExpectation_
	//	*DataQualityRule_TableConditionExpectation_
	RuleType isDataQualityRule_RuleType `protobuf_oneof:"rule_type"`
	// Optional. The unnested column which this rule is evaluated against.
	Column string `protobuf:"bytes,500,opt,name=column,proto3" json:"column,omitempty"`
	// Optional. Rows with `null` values will automatically fail a rule, unless
	// `ignore_null` is `true`. In that case, such `null` rows are trivially
	// considered passing.
	//
	// Only applicable to ColumnMap rules.
	IgnoreNull bool `protobuf:"varint,501,opt,name=ignore_null,json=ignoreNull,proto3" json:"ignore_null,omitempty"`
	// Required. The dimension a rule belongs to. Results are also aggregated at
	// the dimension level. Supported dimensions are **["COMPLETENESS",
	// "ACCURACY", "CONSISTENCY", "VALIDITY", "UNIQUENESS", "INTEGRITY"]**
	Dimension string `protobuf:"bytes,502,opt,name=dimension,proto3" json:"dimension,omitempty"`
	// Optional. The minimum ratio of **passing_rows / total_rows** required to
	// pass this rule, with a range of [0.0, 1.0].
	//
	// 0 indicates default value (i.e. 1.0).
	Threshold     float64 `protobuf:"fixed64,503,opt,name=threshold,proto3" json:"threshold,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataQualityRule) Reset() {
	*x = DataQualityRule{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[14]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataQualityRule) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataQualityRule) ProtoMessage() {}

func (x *DataQualityRule) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[14]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataQualityRule.ProtoReflect.Descriptor instead.
func (*DataQualityRule) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{14}
}

func (x *DataQualityRule) GetRuleType() isDataQualityRule_RuleType {
	if x != nil {
		return x.RuleType
	}
	return nil
}

func (x *DataQualityRule) GetRangeExpectation() *DataQualityRule_RangeExpectation {
	if x != nil {
		if x, ok := x.RuleType.(*DataQualityRule_RangeExpectation_); ok {
			return x.RangeExpectation
		}
	}
	return nil
}

func (x *DataQualityRule) GetNonNullExpectation() *DataQualityRule_NonNullExpectation {
	if x != nil {
		if x, ok := x.RuleType.(*DataQualityRule_NonNullExpectation_); ok {
			return x.NonNullExpectation
		}
	}
	return nil
}

func (x *DataQualityRule) GetSetExpectation() *DataQualityRule_SetExpectation {
	if x != nil {
		if x, ok := x.RuleType.(*DataQualityRule_SetExpectation_); ok {
			return x.SetExpectation
		}
	}
	return nil
}

func (x *DataQualityRule) GetRegexExpectation() *DataQualityRule_RegexExpectation {
	if x != nil {
		if x, ok := x.RuleType.(*DataQualityRule_RegexExpectation_); ok {
			return x.RegexExpectation
		}
	}
	return nil
}

func (x *DataQualityRule) GetUniquenessExpectation() *DataQualityRule_UniquenessExpectation {
	if x != nil {
		if x, ok := x.RuleType.(*DataQualityRule_UniquenessExpectation_); ok {
			return x.UniquenessExpectation
		}
	}
	return nil
}

func (x *DataQualityRule) GetStatisticRangeExpectation() *DataQualityRule_StatisticRangeExpectation {
	if x != nil {
		if x, ok := x.RuleType.(*DataQualityRule_StatisticRangeExpectation_); ok {
			return x.StatisticRangeExpectation
		}
	}
	return nil
}

func (x *DataQualityRule) GetRowConditionExpectation() *DataQualityRule_RowConditionExpectation {
	if x != nil {
		if x, ok := x.RuleType.(*DataQualityRule_RowConditionExpectation_); ok {
			return x.RowConditionExpectation
		}
	}
	return nil
}

func (x *DataQualityRule) GetTableConditionExpectation() *DataQualityRule_TableConditionExpectation {
	if x != nil {
		if x, ok := x.RuleType.(*DataQualityRule_TableConditionExpectation_); ok {
			return x.TableConditionExpectation
		}
	}
	return nil
}

func (x *DataQualityRule) GetColumn() string {
	if x != nil {
		return x.Column
	}
	return ""
}

func (x *DataQualityRule) GetIgnoreNull() bool {
	if x != nil {
		return x.IgnoreNull
	}
	return false
}

func (x *DataQualityRule) GetDimension() string {
	if x != nil {
		return x.Dimension
	}
	return ""
}

func (x *DataQualityRule) GetThreshold() float64 {
	if x != nil {
		return x.Threshold
	}
	return 0
}

type isDataQualityRule_RuleType interface {
	isDataQualityRule_RuleType()
}

type DataQualityRule_RangeExpectation_ struct {
	// ColumnMap rule which evaluates whether each column value lies between a
	// specified range.
	RangeExpectation *DataQualityRule_RangeExpectation `protobuf:"bytes,1,opt,name=range_expectation,json=rangeExpectation,proto3,oneof"`
}

type DataQualityRule_NonNullExpectation_ struct {
	// ColumnMap rule which evaluates whether each column value is null.
	NonNullExpectation *DataQualityRule_NonNullExpectation `protobuf:"bytes,2,opt,name=non_null_expectation,json=nonNullExpectation,proto3,oneof"`
}

type DataQualityRule_SetExpectation_ struct {
	// ColumnMap rule which evaluates whether each column value is contained by
	// a specified set.
	SetExpectation *DataQualityRule_SetExpectation `protobuf:"bytes,3,opt,name=set_expectation,json=setExpectation,proto3,oneof"`
}

type DataQualityRule_RegexExpectation_ struct {
	// ColumnMap rule which evaluates whether each column value matches a
	// specified regex.
	RegexExpectation *DataQualityRule_RegexExpectation `protobuf:"bytes,4,opt,name=regex_expectation,json=regexExpectation,proto3,oneof"`
}

type DataQualityRule_UniquenessExpectation_ struct {
	// ColumnAggregate rule which evaluates whether the column has duplicates.
	UniquenessExpectation *DataQualityRule_UniquenessExpectation `protobuf:"bytes,100,opt,name=uniqueness_expectation,json=uniquenessExpectation,proto3,oneof"`
}

type DataQualityRule_StatisticRangeExpectation_ struct {
	// ColumnAggregate rule which evaluates whether the column aggregate
	// statistic lies between a specified range.
	StatisticRangeExpectation *DataQualityRule_StatisticRangeExpectation `protobuf:"bytes,101,opt,name=statistic_range_expectation,json=statisticRangeExpectation,proto3,oneof"`
}

type DataQualityRule_RowConditionExpectation_ struct {
	// Table rule which evaluates whether each row passes the specified
	// condition.
	RowConditionExpectation *DataQualityRule_RowConditionExpectation `protobuf:"bytes,200,opt,name=row_condition_expectation,json=rowConditionExpectation,proto3,oneof"`
}

type DataQualityRule_TableConditionExpectation_ struct {
	// Table rule which evaluates whether the provided expression is true.
	TableConditionExpectation *DataQualityRule_TableConditionExpectation `protobuf:"bytes,201,opt,name=table_condition_expectation,json=tableConditionExpectation,proto3,oneof"`
}

func (*DataQualityRule_RangeExpectation_) isDataQualityRule_RuleType() {}

func (*DataQualityRule_NonNullExpectation_) isDataQualityRule_RuleType() {}

func (*DataQualityRule_SetExpectation_) isDataQualityRule_RuleType() {}

func (*DataQualityRule_RegexExpectation_) isDataQualityRule_RuleType() {}

func (*DataQualityRule_UniquenessExpectation_) isDataQualityRule_RuleType() {}

func (*DataQualityRule_StatisticRangeExpectation_) isDataQualityRule_RuleType() {}

func (*DataQualityRule_RowConditionExpectation_) isDataQualityRule_RuleType() {}

func (*DataQualityRule_TableConditionExpectation_) isDataQualityRule_RuleType() {}

// ResourceAccessSpec holds the access control configuration to be enforced
// on the resources, for example, Cloud Storage bucket, BigQuery dataset,
// BigQuery table.
type ResourceAccessSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The format of strings follows the pattern followed by IAM in the
	// bindings. user:{email}, serviceAccount:{email} group:{email}.
	// The set of principals to be granted reader role on the resource.
	Readers []string `protobuf:"bytes,1,rep,name=readers,proto3" json:"readers,omitempty"`
	// Optional. The set of principals to be granted writer role on the resource.
	Writers []string `protobuf:"bytes,2,rep,name=writers,proto3" json:"writers,omitempty"`
	// Optional. The set of principals to be granted owner role on the resource.
	Owners        []string `protobuf:"bytes,3,rep,name=owners,proto3" json:"owners,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ResourceAccessSpec) Reset() {
	*x = ResourceAccessSpec{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[15]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ResourceAccessSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ResourceAccessSpec) ProtoMessage() {}

func (x *ResourceAccessSpec) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[15]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ResourceAccessSpec.ProtoReflect.Descriptor instead.
func (*ResourceAccessSpec) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{15}
}

func (x *ResourceAccessSpec) GetReaders() []string {
	if x != nil {
		return x.Readers
	}
	return nil
}

func (x *ResourceAccessSpec) GetWriters() []string {
	if x != nil {
		return x.Writers
	}
	return nil
}

func (x *ResourceAccessSpec) GetOwners() []string {
	if x != nil {
		return x.Owners
	}
	return nil
}

// DataAccessSpec holds the access control configuration to be enforced on data
// stored within resources (eg: rows, columns in BigQuery Tables). When
// associated with data, the data is only accessible to
// principals explicitly granted access through the DataAccessSpec. Principals
// with access to the containing resource are not implicitly granted access.
type DataAccessSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The format of strings follows the pattern followed by IAM in the
	// bindings. user:{email}, serviceAccount:{email} group:{email}.
	// The set of principals to be granted reader role on data
	// stored within resources.
	Readers       []string `protobuf:"bytes,1,rep,name=readers,proto3" json:"readers,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataAccessSpec) Reset() {
	*x = DataAccessSpec{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[16]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataAccessSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataAccessSpec) ProtoMessage() {}

func (x *DataAccessSpec) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[16]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataAccessSpec.ProtoReflect.Descriptor instead.
func (*DataAccessSpec) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{16}
}

func (x *DataAccessSpec) GetReaders() []string {
	if x != nil {
		return x.Readers
	}
	return nil
}

// DataTaxonomy represents a set of hierarchical DataAttributes resources,
// grouped with a common theme Eg: 'SensitiveDataTaxonomy' can have attributes
// to manage PII data. It is defined at project level.
type DataTaxonomy struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Output only. The relative resource name of the DataTaxonomy, of the form:
	// projects/{project_number}/locations/{location_id}/dataTaxonomies/{data_taxonomy_id}.
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Output only. System generated globally unique ID for the dataTaxonomy. This
	// ID will be different if the DataTaxonomy is deleted and re-created with the
	// same name.
	Uid string `protobuf:"bytes,2,opt,name=uid,proto3" json:"uid,omitempty"`
	// Output only. The time when the DataTaxonomy was created.
	CreateTime *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=create_time,json=createTime,proto3" json:"create_time,omitempty"`
	// Output only. The time when the DataTaxonomy was last updated.
	UpdateTime *timestamppb.Timestamp `protobuf:"bytes,4,opt,name=update_time,json=updateTime,proto3" json:"update_time,omitempty"`
	// Optional. Description of the DataTaxonomy.
	Description string `protobuf:"bytes,5,opt,name=description,proto3" json:"description,omitempty"`
	// Optional. User friendly display name.
	DisplayName string `protobuf:"bytes,6,opt,name=display_name,json=displayName,proto3" json:"display_name,omitempty"`
	// Optional. User-defined labels for the DataTaxonomy.
	Labels map[string]string `protobuf:"bytes,8,rep,name=labels,proto3" json:"labels,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	// Output only. The number of attributes in the DataTaxonomy.
	AttributeCount int32 `protobuf:"varint,9,opt,name=attribute_count,json=attributeCount,proto3" json:"attribute_count,omitempty"`
	// This checksum is computed by the server based on the value of other
	// fields, and may be sent on update and delete requests to ensure the
	// client has an up-to-date value before proceeding.
	Etag          string `protobuf:"bytes,10,opt,name=etag,proto3" json:"etag,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataTaxonomy) Reset() {
	*x = DataTaxonomy{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[17]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataTaxonomy) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataTaxonomy) ProtoMessage() {}

func (x *DataTaxonomy) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[17]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataTaxonomy.ProtoReflect.Descriptor instead.
func (*DataTaxonomy) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{17}
}

func (x *DataTaxonomy) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *DataTaxonomy) GetUid() string {
	if x != nil {
		return x.Uid
	}
	return ""
}

func (x *DataTaxonomy) GetCreateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.CreateTime
	}
	return nil
}

func (x *DataTaxonomy) GetUpdateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.UpdateTime
	}
	return nil
}

func (x *DataTaxonomy) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *DataTaxonomy) GetDisplayName() string {
	if x != nil {
		return x.DisplayName
	}
	return ""
}

func (x *DataTaxonomy) GetLabels() map[string]string {
	if x != nil {
		return x.Labels
	}
	return nil
}

func (x *DataTaxonomy) GetAttributeCount() int32 {
	if x != nil {
		return x.AttributeCount
	}
	return 0
}

func (x *DataTaxonomy) GetEtag() string {
	if x != nil {
		return x.Etag
	}
	return ""
}

// Denotes one dataAttribute in a dataTaxonomy, for example, PII.
// DataAttribute resources can be defined in a hierarchy.
// A single dataAttribute resource can contain specs of multiple types
//
// ```
// PII
//   - ResourceAccessSpec :
//   - readers :foo@bar.com
//   - DataAccessSpec :
//   - readers :bar@foo.com
//
// ```
type DataAttribute struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Output only. The relative resource name of the dataAttribute, of the form:
	// projects/{project_number}/locations/{location_id}/dataTaxonomies/{dataTaxonomy}/attributes/{data_attribute_id}.
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Output only. System generated globally unique ID for the DataAttribute.
	// This ID will be different if the DataAttribute is deleted and re-created
	// with the same name.
	Uid string `protobuf:"bytes,2,opt,name=uid,proto3" json:"uid,omitempty"`
	// Output only. The time when the DataAttribute was created.
	CreateTime *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=create_time,json=createTime,proto3" json:"create_time,omitempty"`
	// Output only. The time when the DataAttribute was last updated.
	UpdateTime *timestamppb.Timestamp `protobuf:"bytes,4,opt,name=update_time,json=updateTime,proto3" json:"update_time,omitempty"`
	// Optional. Description of the DataAttribute.
	Description string `protobuf:"bytes,5,opt,name=description,proto3" json:"description,omitempty"`
	// Optional. User friendly display name.
	DisplayName string `protobuf:"bytes,6,opt,name=display_name,json=displayName,proto3" json:"display_name,omitempty"`
	// Optional. User-defined labels for the DataAttribute.
	Labels map[string]string `protobuf:"bytes,7,rep,name=labels,proto3" json:"labels,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	// Optional. The ID of the parent DataAttribute resource, should belong to the
	// same data taxonomy. Circular dependency in parent chain is not valid.
	// Maximum depth of the hierarchy allowed is 4.
	// [a -> b -> c -> d -> e, depth = 4]
	ParentId string `protobuf:"bytes,8,opt,name=parent_id,json=parentId,proto3" json:"parent_id,omitempty"`
	// Output only. The number of child attributes present for this attribute.
	AttributeCount int32 `protobuf:"varint,9,opt,name=attribute_count,json=attributeCount,proto3" json:"attribute_count,omitempty"`
	// This checksum is computed by the server based on the value of other
	// fields, and may be sent on update and delete requests to ensure the
	// client has an up-to-date value before proceeding.
	Etag string `protobuf:"bytes,10,opt,name=etag,proto3" json:"etag,omitempty"`
	// Optional. Specified when applied to a resource (eg: Cloud Storage bucket,
	// BigQuery dataset, BigQuery table).
	ResourceAccessSpec *ResourceAccessSpec `protobuf:"bytes,100,opt,name=resource_access_spec,json=resourceAccessSpec,proto3" json:"resource_access_spec,omitempty"`
	// Optional. Specified when applied to data stored on the resource (eg: rows,
	// columns in BigQuery Tables).
	DataAccessSpec *DataAccessSpec `protobuf:"bytes,101,opt,name=data_access_spec,json=dataAccessSpec,proto3" json:"data_access_spec,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *DataAttribute) Reset() {
	*x = DataAttribute{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[18]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataAttribute) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataAttribute) ProtoMessage() {}

func (x *DataAttribute) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[18]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataAttribute.ProtoReflect.Descriptor instead.
func (*DataAttribute) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{18}
}

func (x *DataAttribute) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *DataAttribute) GetUid() string {
	if x != nil {
		return x.Uid
	}
	return ""
}

func (x *DataAttribute) GetCreateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.CreateTime
	}
	return nil
}

func (x *DataAttribute) GetUpdateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.UpdateTime
	}
	return nil
}

func (x *DataAttribute) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *DataAttribute) GetDisplayName() string {
	if x != nil {
		return x.DisplayName
	}
	return ""
}

func (x *DataAttribute) GetLabels() map[string]string {
	if x != nil {
		return x.Labels
	}
	return nil
}

func (x *DataAttribute) GetParentId() string {
	if x != nil {
		return x.ParentId
	}
	return ""
}

func (x *DataAttribute) GetAttributeCount() int32 {
	if x != nil {
		return x.AttributeCount
	}
	return 0
}

func (x *DataAttribute) GetEtag() string {
	if x != nil {
		return x.Etag
	}
	return ""
}

func (x *DataAttribute) GetResourceAccessSpec() *ResourceAccessSpec {
	if x != nil {
		return x.ResourceAccessSpec
	}
	return nil
}

func (x *DataAttribute) GetDataAccessSpec() *DataAccessSpec {
	if x != nil {
		return x.DataAccessSpec
	}
	return nil
}

// DataAttributeBinding represents binding of attributes to resources. Eg: Bind
// 'CustomerInfo' entity with 'PII' attribute.
type DataAttributeBinding struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Output only. The relative resource name of the Data Attribute Binding, of
	// the form:
	// projects/{project_number}/locations/{location}/dataAttributeBindings/{data_attribute_binding_id}
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Output only. System generated globally unique ID for the
	// DataAttributeBinding. This ID will be different if the DataAttributeBinding
	// is deleted and re-created with the same name.
	Uid string `protobuf:"bytes,2,opt,name=uid,proto3" json:"uid,omitempty"`
	// Output only. The time when the DataAttributeBinding was created.
	CreateTime *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=create_time,json=createTime,proto3" json:"create_time,omitempty"`
	// Output only. The time when the DataAttributeBinding was last updated.
	UpdateTime *timestamppb.Timestamp `protobuf:"bytes,4,opt,name=update_time,json=updateTime,proto3" json:"update_time,omitempty"`
	// Optional. Description of the DataAttributeBinding.
	Description string `protobuf:"bytes,5,opt,name=description,proto3" json:"description,omitempty"`
	// Optional. User friendly display name.
	DisplayName string `protobuf:"bytes,6,opt,name=display_name,json=displayName,proto3" json:"display_name,omitempty"`
	// Optional. User-defined labels for the DataAttributeBinding.
	Labels map[string]string `protobuf:"bytes,7,rep,name=labels,proto3" json:"labels,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	// This checksum is computed by the server based on the value of other
	// fields, and may be sent on update and delete requests to ensure the
	// client has an up-to-date value before proceeding.
	// Etags must be used when calling the DeleteDataAttributeBinding and the
	// UpdateDataAttributeBinding method.
	Etag string `protobuf:"bytes,8,opt,name=etag,proto3" json:"etag,omitempty"`
	// The reference to the resource that is associated to attributes.
	//
	// Types that are valid to be assigned to ResourceReference:
	//
	//	*DataAttributeBinding_Resource
	ResourceReference isDataAttributeBinding_ResourceReference `protobuf_oneof:"resource_reference"`
	// Optional. List of attributes to be associated with the resource, provided
	// in the form:
	// projects/{project}/locations/{location}/dataTaxonomies/{dataTaxonomy}/attributes/{data_attribute_id}
	Attributes []string `protobuf:"bytes,110,rep,name=attributes,proto3" json:"attributes,omitempty"`
	// Optional. The list of paths for items within the associated resource (eg.
	// columns within a table) along with attribute bindings.
	Paths         []*DataAttributeBinding_Path `protobuf:"bytes,120,rep,name=paths,proto3" json:"paths,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataAttributeBinding) Reset() {
	*x = DataAttributeBinding{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[19]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataAttributeBinding) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataAttributeBinding) ProtoMessage() {}

func (x *DataAttributeBinding) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[19]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataAttributeBinding.ProtoReflect.Descriptor instead.
func (*DataAttributeBinding) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{19}
}

func (x *DataAttributeBinding) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *DataAttributeBinding) GetUid() string {
	if x != nil {
		return x.Uid
	}
	return ""
}

func (x *DataAttributeBinding) GetCreateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.CreateTime
	}
	return nil
}

func (x *DataAttributeBinding) GetUpdateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.UpdateTime
	}
	return nil
}

func (x *DataAttributeBinding) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *DataAttributeBinding) GetDisplayName() string {
	if x != nil {
		return x.DisplayName
	}
	return ""
}

func (x *DataAttributeBinding) GetLabels() map[string]string {
	if x != nil {
		return x.Labels
	}
	return nil
}

func (x *DataAttributeBinding) GetEtag() string {
	if x != nil {
		return x.Etag
	}
	return ""
}

func (x *DataAttributeBinding) GetResourceReference() isDataAttributeBinding_ResourceReference {
	if x != nil {
		return x.ResourceReference
	}
	return nil
}

func (x *DataAttributeBinding) GetResource() string {
	if x != nil {
		if x, ok := x.ResourceReference.(*DataAttributeBinding_Resource); ok {
			return x.Resource
		}
	}
	return ""
}

func (x *DataAttributeBinding) GetAttributes() []string {
	if x != nil {
		return x.Attributes
	}
	return nil
}

func (x *DataAttributeBinding) GetPaths() []*DataAttributeBinding_Path {
	if x != nil {
		return x.Paths
	}
	return nil
}

type isDataAttributeBinding_ResourceReference interface {
	isDataAttributeBinding_ResourceReference()
}

type DataAttributeBinding_Resource struct {
	// Optional. Immutable. The resource name of the resource that is associated
	// to attributes. Presently, only entity resource is supported in the form:
	// projects/{project}/locations/{location}/lakes/{lake}/zones/{zone}/entities/{entity_id}
	// Must belong in the same project and region as the attribute binding, and
	// there can only exist one active binding for a resource.
	Resource string `protobuf:"bytes,100,opt,name=resource,proto3,oneof"`
}

func (*DataAttributeBinding_Resource) isDataAttributeBinding_ResourceReference() {}

// Represents a user-visible job which provides the insights for the related
// data source.
//
// For example:
//
//   - Data Quality: generates queries based on the rules and runs against the
//     data to get data quality check results.
//   - Data Profile: analyzes the data in table(s) and generates insights about
//     the structure, content and relationships (such as null percent,
//     cardinality, min/max/mean, etc).
type DataScan struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Output only. The relative resource name of the scan, of the form:
	// `projects/{project}/locations/{location_id}/dataScans/{datascan_id}`,
	// where `project` refers to a *project_id* or *project_number* and
	// `location_id` refers to a GCP region.
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Output only. System generated globally unique ID for the scan. This ID will
	// be different if the scan is deleted and re-created with the same name.
	Uid string `protobuf:"bytes,2,opt,name=uid,proto3" json:"uid,omitempty"`
	// Optional. Description of the scan.
	//
	// * Must be between 1-1024 characters.
	Description string `protobuf:"bytes,3,opt,name=description,proto3" json:"description,omitempty"`
	// Optional. User friendly display name.
	//
	// * Must be between 1-256 characters.
	DisplayName string `protobuf:"bytes,4,opt,name=display_name,json=displayName,proto3" json:"display_name,omitempty"`
	// Optional. User-defined labels for the scan.
	Labels map[string]string `protobuf:"bytes,5,rep,name=labels,proto3" json:"labels,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	// Output only. Current state of the DataScan.
	State State `protobuf:"varint,6,opt,name=state,proto3,enum=google.events.cloud.dataplex.v1.State" json:"state,omitempty"`
	// Output only. The time when the scan was created.
	CreateTime *timestamppb.Timestamp `protobuf:"bytes,7,opt,name=create_time,json=createTime,proto3" json:"create_time,omitempty"`
	// Output only. The time when the scan was last updated.
	UpdateTime *timestamppb.Timestamp `protobuf:"bytes,8,opt,name=update_time,json=updateTime,proto3" json:"update_time,omitempty"`
	// Required. The data source for DataScan.
	Data *DataSource `protobuf:"bytes,9,opt,name=data,proto3" json:"data,omitempty"`
	// Optional. DataScan execution settings.
	//
	// If not specified, the fields in it will use their default values.
	ExecutionSpec *DataScan_ExecutionSpec `protobuf:"bytes,10,opt,name=execution_spec,json=executionSpec,proto3" json:"execution_spec,omitempty"`
	// Output only. Status of the data scan execution.
	ExecutionStatus *DataScan_ExecutionStatus `protobuf:"bytes,11,opt,name=execution_status,json=executionStatus,proto3" json:"execution_status,omitempty"`
	// Output only. The type of DataScan.
	Type DataScanType `protobuf:"varint,12,opt,name=type,proto3,enum=google.events.cloud.dataplex.v1.DataScanType" json:"type,omitempty"`
	// Data Scan related setting.
	// It is required and immutable which means once data_quality_spec is set, it
	// cannot be changed to data_profile_spec.
	//
	// Types that are valid to be assigned to Spec:
	//
	//	*DataScan_DataQualitySpec
	//	*DataScan_DataProfileSpec
	Spec isDataScan_Spec `protobuf_oneof:"spec"`
	// The result of the data scan.
	//
	// Types that are valid to be assigned to Result:
	//
	//	*DataScan_DataQualityResult
	//	*DataScan_DataProfileResult
	Result        isDataScan_Result `protobuf_oneof:"result"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataScan) Reset() {
	*x = DataScan{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[20]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataScan) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataScan) ProtoMessage() {}

func (x *DataScan) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[20]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataScan.ProtoReflect.Descriptor instead.
func (*DataScan) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{20}
}

func (x *DataScan) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *DataScan) GetUid() string {
	if x != nil {
		return x.Uid
	}
	return ""
}

func (x *DataScan) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *DataScan) GetDisplayName() string {
	if x != nil {
		return x.DisplayName
	}
	return ""
}

func (x *DataScan) GetLabels() map[string]string {
	if x != nil {
		return x.Labels
	}
	return nil
}

func (x *DataScan) GetState() State {
	if x != nil {
		return x.State
	}
	return State_STATE_UNSPECIFIED
}

func (x *DataScan) GetCreateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.CreateTime
	}
	return nil
}

func (x *DataScan) GetUpdateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.UpdateTime
	}
	return nil
}

func (x *DataScan) GetData() *DataSource {
	if x != nil {
		return x.Data
	}
	return nil
}

func (x *DataScan) GetExecutionSpec() *DataScan_ExecutionSpec {
	if x != nil {
		return x.ExecutionSpec
	}
	return nil
}

func (x *DataScan) GetExecutionStatus() *DataScan_ExecutionStatus {
	if x != nil {
		return x.ExecutionStatus
	}
	return nil
}

func (x *DataScan) GetType() DataScanType {
	if x != nil {
		return x.Type
	}
	return DataScanType_DATA_SCAN_TYPE_UNSPECIFIED
}

func (x *DataScan) GetSpec() isDataScan_Spec {
	if x != nil {
		return x.Spec
	}
	return nil
}

func (x *DataScan) GetDataQualitySpec() *DataQualitySpec {
	if x != nil {
		if x, ok := x.Spec.(*DataScan_DataQualitySpec); ok {
			return x.DataQualitySpec
		}
	}
	return nil
}

func (x *DataScan) GetDataProfileSpec() *DataProfileSpec {
	if x != nil {
		if x, ok := x.Spec.(*DataScan_DataProfileSpec); ok {
			return x.DataProfileSpec
		}
	}
	return nil
}

func (x *DataScan) GetResult() isDataScan_Result {
	if x != nil {
		return x.Result
	}
	return nil
}

func (x *DataScan) GetDataQualityResult() *DataQualityResult {
	if x != nil {
		if x, ok := x.Result.(*DataScan_DataQualityResult); ok {
			return x.DataQualityResult
		}
	}
	return nil
}

func (x *DataScan) GetDataProfileResult() *DataProfileResult {
	if x != nil {
		if x, ok := x.Result.(*DataScan_DataProfileResult); ok {
			return x.DataProfileResult
		}
	}
	return nil
}

type isDataScan_Spec interface {
	isDataScan_Spec()
}

type DataScan_DataQualitySpec struct {
	// DataQualityScan related setting.
	DataQualitySpec *DataQualitySpec `protobuf:"bytes,100,opt,name=data_quality_spec,json=dataQualitySpec,proto3,oneof"`
}

type DataScan_DataProfileSpec struct {
	// DataProfileScan related setting.
	DataProfileSpec *DataProfileSpec `protobuf:"bytes,101,opt,name=data_profile_spec,json=dataProfileSpec,proto3,oneof"`
}

func (*DataScan_DataQualitySpec) isDataScan_Spec() {}

func (*DataScan_DataProfileSpec) isDataScan_Spec() {}

type isDataScan_Result interface {
	isDataScan_Result()
}

type DataScan_DataQualityResult struct {
	// Output only. The result of the data quality scan.
	DataQualityResult *DataQualityResult `protobuf:"bytes,200,opt,name=data_quality_result,json=dataQualityResult,proto3,oneof"`
}

type DataScan_DataProfileResult struct {
	// Output only. The result of the data profile scan.
	DataProfileResult *DataProfileResult `protobuf:"bytes,201,opt,name=data_profile_result,json=dataProfileResult,proto3,oneof"`
}

func (*DataScan_DataQualityResult) isDataScan_Result() {}

func (*DataScan_DataProfileResult) isDataScan_Result() {}

// A task represents a user-visible job.
type Task struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Output only. The relative resource name of the task, of the form:
	// projects/{project_number}/locations/{location_id}/lakes/{lake_id}/
	// tasks/{task_id}.
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Output only. System generated globally unique ID for the task. This ID will
	// be different if the task is deleted and re-created with the same name.
	Uid string `protobuf:"bytes,2,opt,name=uid,proto3" json:"uid,omitempty"`
	// Output only. The time when the task was created.
	CreateTime *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=create_time,json=createTime,proto3" json:"create_time,omitempty"`
	// Output only. The time when the task was last updated.
	UpdateTime *timestamppb.Timestamp `protobuf:"bytes,4,opt,name=update_time,json=updateTime,proto3" json:"update_time,omitempty"`
	// Optional. Description of the task.
	Description string `protobuf:"bytes,5,opt,name=description,proto3" json:"description,omitempty"`
	// Optional. User friendly display name.
	DisplayName string `protobuf:"bytes,6,opt,name=display_name,json=displayName,proto3" json:"display_name,omitempty"`
	// Output only. Current state of the task.
	State State `protobuf:"varint,7,opt,name=state,proto3,enum=google.events.cloud.dataplex.v1.State" json:"state,omitempty"`
	// Optional. User-defined labels for the task.
	Labels map[string]string `protobuf:"bytes,8,rep,name=labels,proto3" json:"labels,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	// Required. Spec related to how often and when a task should be triggered.
	TriggerSpec *Task_TriggerSpec `protobuf:"bytes,100,opt,name=trigger_spec,json=triggerSpec,proto3" json:"trigger_spec,omitempty"`
	// Required. Spec related to how a task is executed.
	ExecutionSpec *Task_ExecutionSpec `protobuf:"bytes,101,opt,name=execution_spec,json=executionSpec,proto3" json:"execution_spec,omitempty"`
	// Output only. Status of the latest task executions.
	ExecutionStatus *Task_ExecutionStatus `protobuf:"bytes,201,opt,name=execution_status,json=executionStatus,proto3" json:"execution_status,omitempty"`
	// Task template specific user-specified config.
	//
	// Types that are valid to be assigned to Config:
	//
	//	*Task_Spark
	//	*Task_Notebook
	Config        isTask_Config `protobuf_oneof:"config"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Task) Reset() {
	*x = Task{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[21]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Task) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Task) ProtoMessage() {}

func (x *Task) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[21]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Task.ProtoReflect.Descriptor instead.
func (*Task) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{21}
}

func (x *Task) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *Task) GetUid() string {
	if x != nil {
		return x.Uid
	}
	return ""
}

func (x *Task) GetCreateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.CreateTime
	}
	return nil
}

func (x *Task) GetUpdateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.UpdateTime
	}
	return nil
}

func (x *Task) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *Task) GetDisplayName() string {
	if x != nil {
		return x.DisplayName
	}
	return ""
}

func (x *Task) GetState() State {
	if x != nil {
		return x.State
	}
	return State_STATE_UNSPECIFIED
}

func (x *Task) GetLabels() map[string]string {
	if x != nil {
		return x.Labels
	}
	return nil
}

func (x *Task) GetTriggerSpec() *Task_TriggerSpec {
	if x != nil {
		return x.TriggerSpec
	}
	return nil
}

func (x *Task) GetExecutionSpec() *Task_ExecutionSpec {
	if x != nil {
		return x.ExecutionSpec
	}
	return nil
}

func (x *Task) GetExecutionStatus() *Task_ExecutionStatus {
	if x != nil {
		return x.ExecutionStatus
	}
	return nil
}

func (x *Task) GetConfig() isTask_Config {
	if x != nil {
		return x.Config
	}
	return nil
}

func (x *Task) GetSpark() *Task_SparkTaskConfig {
	if x != nil {
		if x, ok := x.Config.(*Task_Spark); ok {
			return x.Spark
		}
	}
	return nil
}

func (x *Task) GetNotebook() *Task_NotebookTaskConfig {
	if x != nil {
		if x, ok := x.Config.(*Task_Notebook); ok {
			return x.Notebook
		}
	}
	return nil
}

type isTask_Config interface {
	isTask_Config()
}

type Task_Spark struct {
	// Config related to running custom Spark tasks.
	Spark *Task_SparkTaskConfig `protobuf:"bytes,300,opt,name=spark,proto3,oneof"`
}

type Task_Notebook struct {
	// Config related to running scheduled Notebooks.
	Notebook *Task_NotebookTaskConfig `protobuf:"bytes,302,opt,name=notebook,proto3,oneof"`
}

func (*Task_Spark) isTask_Config() {}

func (*Task_Notebook) isTask_Config() {}

// A job represents an instance of a task.
type Job struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Output only. The relative resource name of the job, of the form:
	// `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/tasks/{task_id}/jobs/{job_id}`.
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Output only. System generated globally unique ID for the job.
	Uid string `protobuf:"bytes,2,opt,name=uid,proto3" json:"uid,omitempty"`
	// Output only. The time when the job was started.
	StartTime *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=start_time,json=startTime,proto3" json:"start_time,omitempty"`
	// Output only. The time when the job ended.
	EndTime *timestamppb.Timestamp `protobuf:"bytes,4,opt,name=end_time,json=endTime,proto3" json:"end_time,omitempty"`
	// Output only. Execution state for the job.
	State Job_State `protobuf:"varint,5,opt,name=state,proto3,enum=google.events.cloud.dataplex.v1.Job_State" json:"state,omitempty"`
	// Output only. The number of times the job has been retried (excluding the
	// initial attempt).
	RetryCount uint32 `protobuf:"varint,6,opt,name=retry_count,json=retryCount,proto3" json:"retry_count,omitempty"`
	// Output only. The underlying service running a job.
	Service Job_Service `protobuf:"varint,7,opt,name=service,proto3,enum=google.events.cloud.dataplex.v1.Job_Service" json:"service,omitempty"`
	// Output only. The full resource name for the job run under a particular
	// service.
	ServiceJob string `protobuf:"bytes,8,opt,name=service_job,json=serviceJob,proto3" json:"service_job,omitempty"`
	// Output only. Additional information about the current state.
	Message       string `protobuf:"bytes,9,opt,name=message,proto3" json:"message,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Job) Reset() {
	*x = Job{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[22]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Job) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Job) ProtoMessage() {}

func (x *Job) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[22]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Job.ProtoReflect.Descriptor instead.
func (*Job) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{22}
}

func (x *Job) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *Job) GetUid() string {
	if x != nil {
		return x.Uid
	}
	return ""
}

func (x *Job) GetStartTime() *timestamppb.Timestamp {
	if x != nil {
		return x.StartTime
	}
	return nil
}

func (x *Job) GetEndTime() *timestamppb.Timestamp {
	if x != nil {
		return x.EndTime
	}
	return nil
}

func (x *Job) GetState() Job_State {
	if x != nil {
		return x.State
	}
	return Job_STATE_UNSPECIFIED
}

func (x *Job) GetRetryCount() uint32 {
	if x != nil {
		return x.RetryCount
	}
	return 0
}

func (x *Job) GetService() Job_Service {
	if x != nil {
		return x.Service
	}
	return Job_SERVICE_UNSPECIFIED
}

func (x *Job) GetServiceJob() string {
	if x != nil {
		return x.ServiceJob
	}
	return ""
}

func (x *Job) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

// The data within all Task events.
type TaskEventData struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The Task event payload. Unset for deletion events.
	Payload       *Task `protobuf:"bytes,1,opt,name=payload,proto3,oneof" json:"payload,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TaskEventData) Reset() {
	*x = TaskEventData{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[23]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TaskEventData) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TaskEventData) ProtoMessage() {}

func (x *TaskEventData) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[23]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TaskEventData.ProtoReflect.Descriptor instead.
func (*TaskEventData) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{23}
}

func (x *TaskEventData) GetPayload() *Task {
	if x != nil {
		return x.Payload
	}
	return nil
}

// The data within all Zone events.
type ZoneEventData struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The Zone event payload. Unset for deletion events.
	Payload       *Zone `protobuf:"bytes,1,opt,name=payload,proto3,oneof" json:"payload,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ZoneEventData) Reset() {
	*x = ZoneEventData{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[24]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ZoneEventData) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ZoneEventData) ProtoMessage() {}

func (x *ZoneEventData) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[24]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ZoneEventData.ProtoReflect.Descriptor instead.
func (*ZoneEventData) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{24}
}

func (x *ZoneEventData) GetPayload() *Zone {
	if x != nil {
		return x.Payload
	}
	return nil
}

// The data within all Asset events.
type AssetEventData struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The Asset event payload. Unset for deletion events.
	Payload       *Asset `protobuf:"bytes,1,opt,name=payload,proto3,oneof" json:"payload,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AssetEventData) Reset() {
	*x = AssetEventData{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[25]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AssetEventData) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AssetEventData) ProtoMessage() {}

func (x *AssetEventData) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[25]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AssetEventData.ProtoReflect.Descriptor instead.
func (*AssetEventData) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{25}
}

func (x *AssetEventData) GetPayload() *Asset {
	if x != nil {
		return x.Payload
	}
	return nil
}

// The data within all Environment events.
type EnvironmentEventData struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The Environment event payload. Unset for deletion events.
	Payload       *Environment `protobuf:"bytes,1,opt,name=payload,proto3,oneof" json:"payload,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *EnvironmentEventData) Reset() {
	*x = EnvironmentEventData{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[26]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *EnvironmentEventData) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*EnvironmentEventData) ProtoMessage() {}

func (x *EnvironmentEventData) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[26]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use EnvironmentEventData.ProtoReflect.Descriptor instead.
func (*EnvironmentEventData) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{26}
}

func (x *EnvironmentEventData) GetPayload() *Environment {
	if x != nil {
		return x.Payload
	}
	return nil
}

// The data within all DataTaxonomy events.
type DataTaxonomyEventData struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The DataTaxonomy event payload. Unset for deletion events.
	Payload       *DataTaxonomy `protobuf:"bytes,1,opt,name=payload,proto3,oneof" json:"payload,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataTaxonomyEventData) Reset() {
	*x = DataTaxonomyEventData{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[27]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataTaxonomyEventData) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataTaxonomyEventData) ProtoMessage() {}

func (x *DataTaxonomyEventData) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[27]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataTaxonomyEventData.ProtoReflect.Descriptor instead.
func (*DataTaxonomyEventData) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{27}
}

func (x *DataTaxonomyEventData) GetPayload() *DataTaxonomy {
	if x != nil {
		return x.Payload
	}
	return nil
}

// The data within all DataAttributeBinding events.
type DataAttributeBindingEventData struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The DataAttributeBinding event payload. Unset for deletion
	// events.
	Payload       *DataAttributeBinding `protobuf:"bytes,1,opt,name=payload,proto3,oneof" json:"payload,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataAttributeBindingEventData) Reset() {
	*x = DataAttributeBindingEventData{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[28]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataAttributeBindingEventData) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataAttributeBindingEventData) ProtoMessage() {}

func (x *DataAttributeBindingEventData) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[28]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataAttributeBindingEventData.ProtoReflect.Descriptor instead.
func (*DataAttributeBindingEventData) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{28}
}

func (x *DataAttributeBindingEventData) GetPayload() *DataAttributeBinding {
	if x != nil {
		return x.Payload
	}
	return nil
}

// The data within all DataScan events.
type DataScanEventData struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The DataScan event payload. Unset for deletion events.
	Payload       *DataScan `protobuf:"bytes,1,opt,name=payload,proto3,oneof" json:"payload,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataScanEventData) Reset() {
	*x = DataScanEventData{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[29]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataScanEventData) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataScanEventData) ProtoMessage() {}

func (x *DataScanEventData) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[29]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataScanEventData.ProtoReflect.Descriptor instead.
func (*DataScanEventData) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{29}
}

func (x *DataScanEventData) GetPayload() *DataScan {
	if x != nil {
		return x.Payload
	}
	return nil
}

// The data within all Lake events.
type LakeEventData struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The Lake event payload. Unset for deletion events.
	Payload       *Lake `protobuf:"bytes,1,opt,name=payload,proto3,oneof" json:"payload,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *LakeEventData) Reset() {
	*x = LakeEventData{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[30]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *LakeEventData) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*LakeEventData) ProtoMessage() {}

func (x *LakeEventData) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[30]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use LakeEventData.ProtoReflect.Descriptor instead.
func (*LakeEventData) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{30}
}

func (x *LakeEventData) GetPayload() *Lake {
	if x != nil {
		return x.Payload
	}
	return nil
}

// The data within all DataAttribute events.
type DataAttributeEventData struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The DataAttribute event payload. Unset for deletion events.
	Payload       *DataAttribute `protobuf:"bytes,1,opt,name=payload,proto3,oneof" json:"payload,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataAttributeEventData) Reset() {
	*x = DataAttributeEventData{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[31]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataAttributeEventData) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataAttributeEventData) ProtoMessage() {}

func (x *DataAttributeEventData) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[31]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataAttributeEventData.ProtoReflect.Descriptor instead.
func (*DataAttributeEventData) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{31}
}

func (x *DataAttributeEventData) GetPayload() *DataAttribute {
	if x != nil {
		return x.Payload
	}
	return nil
}

// Settings to manage association of Dataproc Metastore with a lake.
type Lake_Metastore struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. A relative reference to the Dataproc Metastore
	// (https://cloud.google.com/dataproc-metastore/docs) service associated
	// with the lake:
	// `projects/{project_id}/locations/{location_id}/services/{service_id}`
	Service       string `protobuf:"bytes,1,opt,name=service,proto3" json:"service,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Lake_Metastore) Reset() {
	*x = Lake_Metastore{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[32]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Lake_Metastore) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Lake_Metastore) ProtoMessage() {}

func (x *Lake_Metastore) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[32]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Lake_Metastore.ProtoReflect.Descriptor instead.
func (*Lake_Metastore) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{0, 0}
}

func (x *Lake_Metastore) GetService() string {
	if x != nil {
		return x.Service
	}
	return ""
}

// Status of Lake and Dataproc Metastore service instance association.
type Lake_MetastoreStatus struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Current state of association.
	State Lake_MetastoreStatus_State `protobuf:"varint,1,opt,name=state,proto3,enum=google.events.cloud.dataplex.v1.Lake_MetastoreStatus_State" json:"state,omitempty"`
	// Additional information about the current status.
	Message string `protobuf:"bytes,2,opt,name=message,proto3" json:"message,omitempty"`
	// Last update time of the metastore status of the lake.
	UpdateTime *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=update_time,json=updateTime,proto3" json:"update_time,omitempty"`
	// The URI of the endpoint used to access the Metastore service.
	Endpoint      string `protobuf:"bytes,4,opt,name=endpoint,proto3" json:"endpoint,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Lake_MetastoreStatus) Reset() {
	*x = Lake_MetastoreStatus{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[33]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Lake_MetastoreStatus) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Lake_MetastoreStatus) ProtoMessage() {}

func (x *Lake_MetastoreStatus) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[33]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Lake_MetastoreStatus.ProtoReflect.Descriptor instead.
func (*Lake_MetastoreStatus) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{0, 1}
}

func (x *Lake_MetastoreStatus) GetState() Lake_MetastoreStatus_State {
	if x != nil {
		return x.State
	}
	return Lake_MetastoreStatus_STATE_UNSPECIFIED
}

func (x *Lake_MetastoreStatus) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

func (x *Lake_MetastoreStatus) GetUpdateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.UpdateTime
	}
	return nil
}

func (x *Lake_MetastoreStatus) GetEndpoint() string {
	if x != nil {
		return x.Endpoint
	}
	return ""
}

// Settings for resources attached as assets within a zone.
type Zone_ResourceSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Required. Immutable. The location type of the resources that are allowed
	// to be attached to the assets within this zone.
	LocationType  Zone_ResourceSpec_LocationType `protobuf:"varint,1,opt,name=location_type,json=locationType,proto3,enum=google.events.cloud.dataplex.v1.Zone_ResourceSpec_LocationType" json:"location_type,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Zone_ResourceSpec) Reset() {
	*x = Zone_ResourceSpec{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[35]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Zone_ResourceSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Zone_ResourceSpec) ProtoMessage() {}

func (x *Zone_ResourceSpec) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[35]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Zone_ResourceSpec.ProtoReflect.Descriptor instead.
func (*Zone_ResourceSpec) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{2, 0}
}

func (x *Zone_ResourceSpec) GetLocationType() Zone_ResourceSpec_LocationType {
	if x != nil {
		return x.LocationType
	}
	return Zone_ResourceSpec_LOCATION_TYPE_UNSPECIFIED
}

// Settings to manage the metadata discovery and publishing in a zone.
type Zone_DiscoverySpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Required. Whether discovery is enabled.
	Enabled bool `protobuf:"varint,1,opt,name=enabled,proto3" json:"enabled,omitempty"`
	// Optional. The list of patterns to apply for selecting data to include
	// during discovery if only a subset of the data should considered. For
	// Cloud Storage bucket assets, these are interpreted as glob patterns used
	// to match object names. For BigQuery dataset assets, these are interpreted
	// as patterns to match table names.
	IncludePatterns []string `protobuf:"bytes,2,rep,name=include_patterns,json=includePatterns,proto3" json:"include_patterns,omitempty"`
	// Optional. The list of patterns to apply for selecting data to exclude
	// during discovery.  For Cloud Storage bucket assets, these are interpreted
	// as glob patterns used to match object names. For BigQuery dataset assets,
	// these are interpreted as patterns to match table names.
	ExcludePatterns []string `protobuf:"bytes,3,rep,name=exclude_patterns,json=excludePatterns,proto3" json:"exclude_patterns,omitempty"`
	// Optional. Configuration for CSV data.
	CsvOptions *Zone_DiscoverySpec_CsvOptions `protobuf:"bytes,4,opt,name=csv_options,json=csvOptions,proto3" json:"csv_options,omitempty"`
	// Optional. Configuration for Json data.
	JsonOptions *Zone_DiscoverySpec_JsonOptions `protobuf:"bytes,5,opt,name=json_options,json=jsonOptions,proto3" json:"json_options,omitempty"`
	// Determines when discovery is triggered.
	//
	// Types that are valid to be assigned to Trigger:
	//
	//	*Zone_DiscoverySpec_Schedule
	Trigger       isZone_DiscoverySpec_Trigger `protobuf_oneof:"trigger"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Zone_DiscoverySpec) Reset() {
	*x = Zone_DiscoverySpec{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[36]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Zone_DiscoverySpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Zone_DiscoverySpec) ProtoMessage() {}

func (x *Zone_DiscoverySpec) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[36]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Zone_DiscoverySpec.ProtoReflect.Descriptor instead.
func (*Zone_DiscoverySpec) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{2, 1}
}

func (x *Zone_DiscoverySpec) GetEnabled() bool {
	if x != nil {
		return x.Enabled
	}
	return false
}

func (x *Zone_DiscoverySpec) GetIncludePatterns() []string {
	if x != nil {
		return x.IncludePatterns
	}
	return nil
}

func (x *Zone_DiscoverySpec) GetExcludePatterns() []string {
	if x != nil {
		return x.ExcludePatterns
	}
	return nil
}

func (x *Zone_DiscoverySpec) GetCsvOptions() *Zone_DiscoverySpec_CsvOptions {
	if x != nil {
		return x.CsvOptions
	}
	return nil
}

func (x *Zone_DiscoverySpec) GetJsonOptions() *Zone_DiscoverySpec_JsonOptions {
	if x != nil {
		return x.JsonOptions
	}
	return nil
}

func (x *Zone_DiscoverySpec) GetTrigger() isZone_DiscoverySpec_Trigger {
	if x != nil {
		return x.Trigger
	}
	return nil
}

func (x *Zone_DiscoverySpec) GetSchedule() string {
	if x != nil {
		if x, ok := x.Trigger.(*Zone_DiscoverySpec_Schedule); ok {
			return x.Schedule
		}
	}
	return ""
}

type isZone_DiscoverySpec_Trigger interface {
	isZone_DiscoverySpec_Trigger()
}

type Zone_DiscoverySpec_Schedule struct {
	// Optional. Cron schedule (https://en.wikipedia.org/wiki/Cron) for
	// running discovery periodically. Successive discovery runs must be
	// scheduled at least 60 minutes apart. The default value is to run
	// discovery every 60 minutes. To explicitly set a timezone to the cron
	// tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or
	// TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string
	// from IANA time zone database. For example, `CRON_TZ=America/New_York 1
	// * * * *`, or `TZ=America/New_York 1 * * * *`.
	Schedule string `protobuf:"bytes,10,opt,name=schedule,proto3,oneof"`
}

func (*Zone_DiscoverySpec_Schedule) isZone_DiscoverySpec_Trigger() {}

// Describe CSV and similar semi-structured data formats.
type Zone_DiscoverySpec_CsvOptions struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The number of rows to interpret as header rows that should be
	// skipped when reading data rows.
	HeaderRows int32 `protobuf:"varint,1,opt,name=header_rows,json=headerRows,proto3" json:"header_rows,omitempty"`
	// Optional. The delimiter being used to separate values. This defaults to
	// ','.
	Delimiter string `protobuf:"bytes,2,opt,name=delimiter,proto3" json:"delimiter,omitempty"`
	// Optional. The character encoding of the data. The default is UTF-8.
	Encoding string `protobuf:"bytes,3,opt,name=encoding,proto3" json:"encoding,omitempty"`
	// Optional. Whether to disable the inference of data type for CSV data.
	// If true, all columns will be registered as strings.
	DisableTypeInference bool `protobuf:"varint,4,opt,name=disable_type_inference,json=disableTypeInference,proto3" json:"disable_type_inference,omitempty"`
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

func (x *Zone_DiscoverySpec_CsvOptions) Reset() {
	*x = Zone_DiscoverySpec_CsvOptions{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[38]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Zone_DiscoverySpec_CsvOptions) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Zone_DiscoverySpec_CsvOptions) ProtoMessage() {}

func (x *Zone_DiscoverySpec_CsvOptions) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[38]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Zone_DiscoverySpec_CsvOptions.ProtoReflect.Descriptor instead.
func (*Zone_DiscoverySpec_CsvOptions) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{2, 1, 0}
}

func (x *Zone_DiscoverySpec_CsvOptions) GetHeaderRows() int32 {
	if x != nil {
		return x.HeaderRows
	}
	return 0
}

func (x *Zone_DiscoverySpec_CsvOptions) GetDelimiter() string {
	if x != nil {
		return x.Delimiter
	}
	return ""
}

func (x *Zone_DiscoverySpec_CsvOptions) GetEncoding() string {
	if x != nil {
		return x.Encoding
	}
	return ""
}

func (x *Zone_DiscoverySpec_CsvOptions) GetDisableTypeInference() bool {
	if x != nil {
		return x.DisableTypeInference
	}
	return false
}

// Describe JSON data format.
type Zone_DiscoverySpec_JsonOptions struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The character encoding of the data. The default is UTF-8.
	Encoding string `protobuf:"bytes,1,opt,name=encoding,proto3" json:"encoding,omitempty"`
	// Optional. Whether to disable the inference of data type for Json data.
	// If true, all columns will be registered as their primitive types
	// (strings, number or boolean).
	DisableTypeInference bool `protobuf:"varint,2,opt,name=disable_type_inference,json=disableTypeInference,proto3" json:"disable_type_inference,omitempty"`
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

func (x *Zone_DiscoverySpec_JsonOptions) Reset() {
	*x = Zone_DiscoverySpec_JsonOptions{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[39]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Zone_DiscoverySpec_JsonOptions) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Zone_DiscoverySpec_JsonOptions) ProtoMessage() {}

func (x *Zone_DiscoverySpec_JsonOptions) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[39]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Zone_DiscoverySpec_JsonOptions.ProtoReflect.Descriptor instead.
func (*Zone_DiscoverySpec_JsonOptions) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{2, 1, 1}
}

func (x *Zone_DiscoverySpec_JsonOptions) GetEncoding() string {
	if x != nil {
		return x.Encoding
	}
	return ""
}

func (x *Zone_DiscoverySpec_JsonOptions) GetDisableTypeInference() bool {
	if x != nil {
		return x.DisableTypeInference
	}
	return false
}

// Security policy status of the asset. Data security policy, i.e., readers,
// writers & owners, should be specified in the lake/zone/asset IAM policy.
type Asset_SecurityStatus struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The current state of the security policy applied to the attached
	// resource.
	State Asset_SecurityStatus_State `protobuf:"varint,1,opt,name=state,proto3,enum=google.events.cloud.dataplex.v1.Asset_SecurityStatus_State" json:"state,omitempty"`
	// Additional information about the current state.
	Message string `protobuf:"bytes,2,opt,name=message,proto3" json:"message,omitempty"`
	// Last update time of the status.
	UpdateTime    *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=update_time,json=updateTime,proto3" json:"update_time,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Asset_SecurityStatus) Reset() {
	*x = Asset_SecurityStatus{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[40]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Asset_SecurityStatus) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Asset_SecurityStatus) ProtoMessage() {}

func (x *Asset_SecurityStatus) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[40]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Asset_SecurityStatus.ProtoReflect.Descriptor instead.
func (*Asset_SecurityStatus) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{3, 0}
}

func (x *Asset_SecurityStatus) GetState() Asset_SecurityStatus_State {
	if x != nil {
		return x.State
	}
	return Asset_SecurityStatus_STATE_UNSPECIFIED
}

func (x *Asset_SecurityStatus) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

func (x *Asset_SecurityStatus) GetUpdateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.UpdateTime
	}
	return nil
}

// Settings to manage the metadata discovery and publishing for an asset.
type Asset_DiscoverySpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. Whether discovery is enabled.
	Enabled bool `protobuf:"varint,1,opt,name=enabled,proto3" json:"enabled,omitempty"`
	// Optional. The list of patterns to apply for selecting data to include
	// during discovery if only a subset of the data should considered.  For
	// Cloud Storage bucket assets, these are interpreted as glob patterns used
	// to match object names. For BigQuery dataset assets, these are interpreted
	// as patterns to match table names.
	IncludePatterns []string `protobuf:"bytes,2,rep,name=include_patterns,json=includePatterns,proto3" json:"include_patterns,omitempty"`
	// Optional. The list of patterns to apply for selecting data to exclude
	// during discovery.  For Cloud Storage bucket assets, these are interpreted
	// as glob patterns used to match object names. For BigQuery dataset assets,
	// these are interpreted as patterns to match table names.
	ExcludePatterns []string `protobuf:"bytes,3,rep,name=exclude_patterns,json=excludePatterns,proto3" json:"exclude_patterns,omitempty"`
	// Optional. Configuration for CSV data.
	CsvOptions *Asset_DiscoverySpec_CsvOptions `protobuf:"bytes,4,opt,name=csv_options,json=csvOptions,proto3" json:"csv_options,omitempty"`
	// Optional. Configuration for Json data.
	JsonOptions *Asset_DiscoverySpec_JsonOptions `protobuf:"bytes,5,opt,name=json_options,json=jsonOptions,proto3" json:"json_options,omitempty"`
	// Determines when discovery is triggered.
	//
	// Types that are valid to be assigned to Trigger:
	//
	//	*Asset_DiscoverySpec_Schedule
	Trigger       isAsset_DiscoverySpec_Trigger `protobuf_oneof:"trigger"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Asset_DiscoverySpec) Reset() {
	*x = Asset_DiscoverySpec{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[41]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Asset_DiscoverySpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Asset_DiscoverySpec) ProtoMessage() {}

func (x *Asset_DiscoverySpec) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[41]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Asset_DiscoverySpec.ProtoReflect.Descriptor instead.
func (*Asset_DiscoverySpec) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{3, 1}
}

func (x *Asset_DiscoverySpec) GetEnabled() bool {
	if x != nil {
		return x.Enabled
	}
	return false
}

func (x *Asset_DiscoverySpec) GetIncludePatterns() []string {
	if x != nil {
		return x.IncludePatterns
	}
	return nil
}

func (x *Asset_DiscoverySpec) GetExcludePatterns() []string {
	if x != nil {
		return x.ExcludePatterns
	}
	return nil
}

func (x *Asset_DiscoverySpec) GetCsvOptions() *Asset_DiscoverySpec_CsvOptions {
	if x != nil {
		return x.CsvOptions
	}
	return nil
}

func (x *Asset_DiscoverySpec) GetJsonOptions() *Asset_DiscoverySpec_JsonOptions {
	if x != nil {
		return x.JsonOptions
	}
	return nil
}

func (x *Asset_DiscoverySpec) GetTrigger() isAsset_DiscoverySpec_Trigger {
	if x != nil {
		return x.Trigger
	}
	return nil
}

func (x *Asset_DiscoverySpec) GetSchedule() string {
	if x != nil {
		if x, ok := x.Trigger.(*Asset_DiscoverySpec_Schedule); ok {
			return x.Schedule
		}
	}
	return ""
}

type isAsset_DiscoverySpec_Trigger interface {
	isAsset_DiscoverySpec_Trigger()
}

type Asset_DiscoverySpec_Schedule struct {
	// Optional. Cron schedule (https://en.wikipedia.org/wiki/Cron) for
	// running discovery periodically. Successive discovery runs must be
	// scheduled at least 60 minutes apart. The default value is to run
	// discovery every 60 minutes. To explicitly set a timezone to the cron
	// tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or
	// TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string
	// from IANA time zone database. For example, `CRON_TZ=America/New_York 1
	// * * * *`, or `TZ=America/New_York 1 * * * *`.
	Schedule string `protobuf:"bytes,10,opt,name=schedule,proto3,oneof"`
}

func (*Asset_DiscoverySpec_Schedule) isAsset_DiscoverySpec_Trigger() {}

// Identifies the cloud resource that is referenced by this asset.
type Asset_ResourceSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Immutable. Relative name of the cloud resource that contains the data
	// that is being managed within a lake. For example:
	//
	//	`projects/{project_number}/buckets/{bucket_id}`
	//	`projects/{project_number}/datasets/{dataset_id}`
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Required. Immutable. Type of resource.
	Type Asset_ResourceSpec_Type `protobuf:"varint,2,opt,name=type,proto3,enum=google.events.cloud.dataplex.v1.Asset_ResourceSpec_Type" json:"type,omitempty"`
	// Optional. Determines how read permissions are handled for each asset and
	// their associated tables. Only available to storage buckets assets.
	ReadAccessMode Asset_ResourceSpec_AccessMode `protobuf:"varint,5,opt,name=read_access_mode,json=readAccessMode,proto3,enum=google.events.cloud.dataplex.v1.Asset_ResourceSpec_AccessMode" json:"read_access_mode,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *Asset_ResourceSpec) Reset() {
	*x = Asset_ResourceSpec{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[42]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Asset_ResourceSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Asset_ResourceSpec) ProtoMessage() {}

func (x *Asset_ResourceSpec) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[42]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Asset_ResourceSpec.ProtoReflect.Descriptor instead.
func (*Asset_ResourceSpec) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{3, 2}
}

func (x *Asset_ResourceSpec) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *Asset_ResourceSpec) GetType() Asset_ResourceSpec_Type {
	if x != nil {
		return x.Type
	}
	return Asset_ResourceSpec_TYPE_UNSPECIFIED
}

func (x *Asset_ResourceSpec) GetReadAccessMode() Asset_ResourceSpec_AccessMode {
	if x != nil {
		return x.ReadAccessMode
	}
	return Asset_ResourceSpec_ACCESS_MODE_UNSPECIFIED
}

// Status of the resource referenced by an asset.
type Asset_ResourceStatus struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The current state of the managed resource.
	State Asset_ResourceStatus_State `protobuf:"varint,1,opt,name=state,proto3,enum=google.events.cloud.dataplex.v1.Asset_ResourceStatus_State" json:"state,omitempty"`
	// Additional information about the current state.
	Message string `protobuf:"bytes,2,opt,name=message,proto3" json:"message,omitempty"`
	// Last update time of the status.
	UpdateTime *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=update_time,json=updateTime,proto3" json:"update_time,omitempty"`
	// Output only. Service account associated with the BigQuery Connection.
	ManagedAccessIdentity string `protobuf:"bytes,4,opt,name=managed_access_identity,json=managedAccessIdentity,proto3" json:"managed_access_identity,omitempty"`
	unknownFields         protoimpl.UnknownFields
	sizeCache             protoimpl.SizeCache
}

func (x *Asset_ResourceStatus) Reset() {
	*x = Asset_ResourceStatus{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[43]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Asset_ResourceStatus) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Asset_ResourceStatus) ProtoMessage() {}

func (x *Asset_ResourceStatus) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[43]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Asset_ResourceStatus.ProtoReflect.Descriptor instead.
func (*Asset_ResourceStatus) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{3, 3}
}

func (x *Asset_ResourceStatus) GetState() Asset_ResourceStatus_State {
	if x != nil {
		return x.State
	}
	return Asset_ResourceStatus_STATE_UNSPECIFIED
}

func (x *Asset_ResourceStatus) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

func (x *Asset_ResourceStatus) GetUpdateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.UpdateTime
	}
	return nil
}

func (x *Asset_ResourceStatus) GetManagedAccessIdentity() string {
	if x != nil {
		return x.ManagedAccessIdentity
	}
	return ""
}

// Status of discovery for an asset.
type Asset_DiscoveryStatus struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The current status of the discovery feature.
	State Asset_DiscoveryStatus_State `protobuf:"varint,1,opt,name=state,proto3,enum=google.events.cloud.dataplex.v1.Asset_DiscoveryStatus_State" json:"state,omitempty"`
	// Additional information about the current state.
	Message string `protobuf:"bytes,2,opt,name=message,proto3" json:"message,omitempty"`
	// Last update time of the status.
	UpdateTime *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=update_time,json=updateTime,proto3" json:"update_time,omitempty"`
	// The start time of the last discovery run.
	LastRunTime *timestamppb.Timestamp `protobuf:"bytes,4,opt,name=last_run_time,json=lastRunTime,proto3" json:"last_run_time,omitempty"`
	// Data Stats of the asset reported by discovery.
	Stats *Asset_DiscoveryStatus_Stats `protobuf:"bytes,6,opt,name=stats,proto3" json:"stats,omitempty"`
	// The duration of the last discovery run.
	LastRunDuration *durationpb.Duration `protobuf:"bytes,7,opt,name=last_run_duration,json=lastRunDuration,proto3" json:"last_run_duration,omitempty"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *Asset_DiscoveryStatus) Reset() {
	*x = Asset_DiscoveryStatus{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[44]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Asset_DiscoveryStatus) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Asset_DiscoveryStatus) ProtoMessage() {}

func (x *Asset_DiscoveryStatus) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[44]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Asset_DiscoveryStatus.ProtoReflect.Descriptor instead.
func (*Asset_DiscoveryStatus) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{3, 4}
}

func (x *Asset_DiscoveryStatus) GetState() Asset_DiscoveryStatus_State {
	if x != nil {
		return x.State
	}
	return Asset_DiscoveryStatus_STATE_UNSPECIFIED
}

func (x *Asset_DiscoveryStatus) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

func (x *Asset_DiscoveryStatus) GetUpdateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.UpdateTime
	}
	return nil
}

func (x *Asset_DiscoveryStatus) GetLastRunTime() *timestamppb.Timestamp {
	if x != nil {
		return x.LastRunTime
	}
	return nil
}

func (x *Asset_DiscoveryStatus) GetStats() *Asset_DiscoveryStatus_Stats {
	if x != nil {
		return x.Stats
	}
	return nil
}

func (x *Asset_DiscoveryStatus) GetLastRunDuration() *durationpb.Duration {
	if x != nil {
		return x.LastRunDuration
	}
	return nil
}

// Describe CSV and similar semi-structured data formats.
type Asset_DiscoverySpec_CsvOptions struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The number of rows to interpret as header rows that should be
	// skipped when reading data rows.
	HeaderRows int32 `protobuf:"varint,1,opt,name=header_rows,json=headerRows,proto3" json:"header_rows,omitempty"`
	// Optional. The delimiter being used to separate values. This defaults to
	// ','.
	Delimiter string `protobuf:"bytes,2,opt,name=delimiter,proto3" json:"delimiter,omitempty"`
	// Optional. The character encoding of the data. The default is UTF-8.
	Encoding string `protobuf:"bytes,3,opt,name=encoding,proto3" json:"encoding,omitempty"`
	// Optional. Whether to disable the inference of data type for CSV data.
	// If true, all columns will be registered as strings.
	DisableTypeInference bool `protobuf:"varint,4,opt,name=disable_type_inference,json=disableTypeInference,proto3" json:"disable_type_inference,omitempty"`
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

func (x *Asset_DiscoverySpec_CsvOptions) Reset() {
	*x = Asset_DiscoverySpec_CsvOptions{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[46]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Asset_DiscoverySpec_CsvOptions) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Asset_DiscoverySpec_CsvOptions) ProtoMessage() {}

func (x *Asset_DiscoverySpec_CsvOptions) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[46]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Asset_DiscoverySpec_CsvOptions.ProtoReflect.Descriptor instead.
func (*Asset_DiscoverySpec_CsvOptions) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{3, 1, 0}
}

func (x *Asset_DiscoverySpec_CsvOptions) GetHeaderRows() int32 {
	if x != nil {
		return x.HeaderRows
	}
	return 0
}

func (x *Asset_DiscoverySpec_CsvOptions) GetDelimiter() string {
	if x != nil {
		return x.Delimiter
	}
	return ""
}

func (x *Asset_DiscoverySpec_CsvOptions) GetEncoding() string {
	if x != nil {
		return x.Encoding
	}
	return ""
}

func (x *Asset_DiscoverySpec_CsvOptions) GetDisableTypeInference() bool {
	if x != nil {
		return x.DisableTypeInference
	}
	return false
}

// Describe JSON data format.
type Asset_DiscoverySpec_JsonOptions struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The character encoding of the data. The default is UTF-8.
	Encoding string `protobuf:"bytes,1,opt,name=encoding,proto3" json:"encoding,omitempty"`
	// Optional. Whether to disable the inference of data type for Json data.
	// If true, all columns will be registered as their primitive types
	// (strings, number or boolean).
	DisableTypeInference bool `protobuf:"varint,2,opt,name=disable_type_inference,json=disableTypeInference,proto3" json:"disable_type_inference,omitempty"`
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

func (x *Asset_DiscoverySpec_JsonOptions) Reset() {
	*x = Asset_DiscoverySpec_JsonOptions{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[47]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Asset_DiscoverySpec_JsonOptions) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Asset_DiscoverySpec_JsonOptions) ProtoMessage() {}

func (x *Asset_DiscoverySpec_JsonOptions) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[47]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Asset_DiscoverySpec_JsonOptions.ProtoReflect.Descriptor instead.
func (*Asset_DiscoverySpec_JsonOptions) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{3, 1, 1}
}

func (x *Asset_DiscoverySpec_JsonOptions) GetEncoding() string {
	if x != nil {
		return x.Encoding
	}
	return ""
}

func (x *Asset_DiscoverySpec_JsonOptions) GetDisableTypeInference() bool {
	if x != nil {
		return x.DisableTypeInference
	}
	return false
}

// The aggregated data statistics for the asset reported by discovery.
type Asset_DiscoveryStatus_Stats struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The count of data items within the referenced resource.
	DataItems int64 `protobuf:"varint,1,opt,name=data_items,json=dataItems,proto3" json:"data_items,omitempty"`
	// The number of stored data bytes within the referenced resource.
	DataSize int64 `protobuf:"varint,2,opt,name=data_size,json=dataSize,proto3" json:"data_size,omitempty"`
	// The count of table entities within the referenced resource.
	Tables int64 `protobuf:"varint,3,opt,name=tables,proto3" json:"tables,omitempty"`
	// The count of fileset entities within the referenced resource.
	Filesets      int64 `protobuf:"varint,4,opt,name=filesets,proto3" json:"filesets,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Asset_DiscoveryStatus_Stats) Reset() {
	*x = Asset_DiscoveryStatus_Stats{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[48]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Asset_DiscoveryStatus_Stats) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Asset_DiscoveryStatus_Stats) ProtoMessage() {}

func (x *Asset_DiscoveryStatus_Stats) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[48]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Asset_DiscoveryStatus_Stats.ProtoReflect.Descriptor instead.
func (*Asset_DiscoveryStatus_Stats) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{3, 4, 0}
}

func (x *Asset_DiscoveryStatus_Stats) GetDataItems() int64 {
	if x != nil {
		return x.DataItems
	}
	return 0
}

func (x *Asset_DiscoveryStatus_Stats) GetDataSize() int64 {
	if x != nil {
		return x.DataSize
	}
	return 0
}

func (x *Asset_DiscoveryStatus_Stats) GetTables() int64 {
	if x != nil {
		return x.Tables
	}
	return 0
}

func (x *Asset_DiscoveryStatus_Stats) GetFilesets() int64 {
	if x != nil {
		return x.Filesets
	}
	return 0
}

// Configuration for the underlying infrastructure used to run workloads.
type Environment_InfrastructureSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Hardware config
	//
	// Types that are valid to be assigned to Resources:
	//
	//	*Environment_InfrastructureSpec_Compute
	Resources isEnvironment_InfrastructureSpec_Resources `protobuf_oneof:"resources"`
	// Software config
	//
	// Types that are valid to be assigned to Runtime:
	//
	//	*Environment_InfrastructureSpec_OsImage
	Runtime       isEnvironment_InfrastructureSpec_Runtime `protobuf_oneof:"runtime"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Environment_InfrastructureSpec) Reset() {
	*x = Environment_InfrastructureSpec{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[49]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Environment_InfrastructureSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Environment_InfrastructureSpec) ProtoMessage() {}

func (x *Environment_InfrastructureSpec) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[49]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Environment_InfrastructureSpec.ProtoReflect.Descriptor instead.
func (*Environment_InfrastructureSpec) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{4, 0}
}

func (x *Environment_InfrastructureSpec) GetResources() isEnvironment_InfrastructureSpec_Resources {
	if x != nil {
		return x.Resources
	}
	return nil
}

func (x *Environment_InfrastructureSpec) GetCompute() *Environment_InfrastructureSpec_ComputeResources {
	if x != nil {
		if x, ok := x.Resources.(*Environment_InfrastructureSpec_Compute); ok {
			return x.Compute
		}
	}
	return nil
}

func (x *Environment_InfrastructureSpec) GetRuntime() isEnvironment_InfrastructureSpec_Runtime {
	if x != nil {
		return x.Runtime
	}
	return nil
}

func (x *Environment_InfrastructureSpec) GetOsImage() *Environment_InfrastructureSpec_OsImageRuntime {
	if x != nil {
		if x, ok := x.Runtime.(*Environment_InfrastructureSpec_OsImage); ok {
			return x.OsImage
		}
	}
	return nil
}

type isEnvironment_InfrastructureSpec_Resources interface {
	isEnvironment_InfrastructureSpec_Resources()
}

type Environment_InfrastructureSpec_Compute struct {
	// Optional. Compute resources needed for analyze interactive workloads.
	Compute *Environment_InfrastructureSpec_ComputeResources `protobuf:"bytes,50,opt,name=compute,proto3,oneof"`
}

func (*Environment_InfrastructureSpec_Compute) isEnvironment_InfrastructureSpec_Resources() {}

type isEnvironment_InfrastructureSpec_Runtime interface {
	isEnvironment_InfrastructureSpec_Runtime()
}

type Environment_InfrastructureSpec_OsImage struct {
	// Required. Software Runtime Configuration for analyze interactive
	// workloads.
	OsImage *Environment_InfrastructureSpec_OsImageRuntime `protobuf:"bytes,100,opt,name=os_image,json=osImage,proto3,oneof"`
}

func (*Environment_InfrastructureSpec_OsImage) isEnvironment_InfrastructureSpec_Runtime() {}

// Configuration for sessions created for this environment.
type Environment_SessionSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The idle time configuration of the session. The session will be
	// auto-terminated at the end of this period.
	MaxIdleDuration *durationpb.Duration `protobuf:"bytes,1,opt,name=max_idle_duration,json=maxIdleDuration,proto3" json:"max_idle_duration,omitempty"`
	// Optional. If True, this causes sessions to be pre-created and available
	// for faster startup to enable interactive exploration use-cases. This
	// defaults to False to avoid additional billed charges. These can only be
	// set to True for the environment with name set to "default", and with
	// default configuration.
	EnableFastStartup bool `protobuf:"varint,2,opt,name=enable_fast_startup,json=enableFastStartup,proto3" json:"enable_fast_startup,omitempty"`
	unknownFields     protoimpl.UnknownFields
	sizeCache         protoimpl.SizeCache
}

func (x *Environment_SessionSpec) Reset() {
	*x = Environment_SessionSpec{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[50]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Environment_SessionSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Environment_SessionSpec) ProtoMessage() {}

func (x *Environment_SessionSpec) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[50]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Environment_SessionSpec.ProtoReflect.Descriptor instead.
func (*Environment_SessionSpec) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{4, 1}
}

func (x *Environment_SessionSpec) GetMaxIdleDuration() *durationpb.Duration {
	if x != nil {
		return x.MaxIdleDuration
	}
	return nil
}

func (x *Environment_SessionSpec) GetEnableFastStartup() bool {
	if x != nil {
		return x.EnableFastStartup
	}
	return false
}

// Status of sessions created for this environment.
type Environment_SessionStatus struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Output only. Queries over sessions to mark whether the environment is
	// currently active or not
	Active        bool `protobuf:"varint,1,opt,name=active,proto3" json:"active,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Environment_SessionStatus) Reset() {
	*x = Environment_SessionStatus{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[51]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Environment_SessionStatus) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Environment_SessionStatus) ProtoMessage() {}

func (x *Environment_SessionStatus) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[51]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Environment_SessionStatus.ProtoReflect.Descriptor instead.
func (*Environment_SessionStatus) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{4, 2}
}

func (x *Environment_SessionStatus) GetActive() bool {
	if x != nil {
		return x.Active
	}
	return false
}

// URI Endpoints to access sessions associated with the Environment.
type Environment_Endpoints struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Output only. URI to serve notebook APIs
	Notebooks string `protobuf:"bytes,1,opt,name=notebooks,proto3" json:"notebooks,omitempty"`
	// Output only. URI to serve SQL APIs
	Sql           string `protobuf:"bytes,2,opt,name=sql,proto3" json:"sql,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Environment_Endpoints) Reset() {
	*x = Environment_Endpoints{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[52]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Environment_Endpoints) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Environment_Endpoints) ProtoMessage() {}

func (x *Environment_Endpoints) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[52]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Environment_Endpoints.ProtoReflect.Descriptor instead.
func (*Environment_Endpoints) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{4, 3}
}

func (x *Environment_Endpoints) GetNotebooks() string {
	if x != nil {
		return x.Notebooks
	}
	return ""
}

func (x *Environment_Endpoints) GetSql() string {
	if x != nil {
		return x.Sql
	}
	return ""
}

// Compute resources associated with the analyze interactive workloads.
type Environment_InfrastructureSpec_ComputeResources struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. Size in GB of the disk. Default is 100 GB.
	DiskSizeGb int32 `protobuf:"varint,1,opt,name=disk_size_gb,json=diskSizeGb,proto3" json:"disk_size_gb,omitempty"`
	// Optional. Total number of nodes in the sessions created for this
	// environment.
	NodeCount int32 `protobuf:"varint,2,opt,name=node_count,json=nodeCount,proto3" json:"node_count,omitempty"`
	// Optional. Max configurable nodes.
	// If max_node_count > node_count, then auto-scaling is enabled.
	MaxNodeCount  int32 `protobuf:"varint,3,opt,name=max_node_count,json=maxNodeCount,proto3" json:"max_node_count,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Environment_InfrastructureSpec_ComputeResources) Reset() {
	*x = Environment_InfrastructureSpec_ComputeResources{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[54]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Environment_InfrastructureSpec_ComputeResources) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Environment_InfrastructureSpec_ComputeResources) ProtoMessage() {}

func (x *Environment_InfrastructureSpec_ComputeResources) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[54]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Environment_InfrastructureSpec_ComputeResources.ProtoReflect.Descriptor instead.
func (*Environment_InfrastructureSpec_ComputeResources) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{4, 0, 0}
}

func (x *Environment_InfrastructureSpec_ComputeResources) GetDiskSizeGb() int32 {
	if x != nil {
		return x.DiskSizeGb
	}
	return 0
}

func (x *Environment_InfrastructureSpec_ComputeResources) GetNodeCount() int32 {
	if x != nil {
		return x.NodeCount
	}
	return 0
}

func (x *Environment_InfrastructureSpec_ComputeResources) GetMaxNodeCount() int32 {
	if x != nil {
		return x.MaxNodeCount
	}
	return 0
}

// Software Runtime Configuration to run Analyze.
type Environment_InfrastructureSpec_OsImageRuntime struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Required. Dataplex Image version.
	ImageVersion string `protobuf:"bytes,1,opt,name=image_version,json=imageVersion,proto3" json:"image_version,omitempty"`
	// Optional. List of Java jars to be included in the runtime environment.
	// Valid input includes Cloud Storage URIs to Jar binaries.
	// For example, gs://bucket-name/my/path/to/file.jar
	JavaLibraries []string `protobuf:"bytes,2,rep,name=java_libraries,json=javaLibraries,proto3" json:"java_libraries,omitempty"`
	// Optional. A list of python packages to be installed.
	// Valid formats include Cloud Storage URI to a PIP installable library.
	// For example, gs://bucket-name/my/path/to/lib.tar.gz
	PythonPackages []string `protobuf:"bytes,3,rep,name=python_packages,json=pythonPackages,proto3" json:"python_packages,omitempty"`
	// Optional. Spark properties to provide configuration for use in sessions
	// created for this environment. The properties to set on daemon config
	// files. Property keys are specified in `prefix:property` format. The
	// prefix must be "spark".
	Properties    map[string]string `protobuf:"bytes,4,rep,name=properties,proto3" json:"properties,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Environment_InfrastructureSpec_OsImageRuntime) Reset() {
	*x = Environment_InfrastructureSpec_OsImageRuntime{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[55]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Environment_InfrastructureSpec_OsImageRuntime) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Environment_InfrastructureSpec_OsImageRuntime) ProtoMessage() {}

func (x *Environment_InfrastructureSpec_OsImageRuntime) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[55]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Environment_InfrastructureSpec_OsImageRuntime.ProtoReflect.Descriptor instead.
func (*Environment_InfrastructureSpec_OsImageRuntime) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{4, 0, 1}
}

func (x *Environment_InfrastructureSpec_OsImageRuntime) GetImageVersion() string {
	if x != nil {
		return x.ImageVersion
	}
	return ""
}

func (x *Environment_InfrastructureSpec_OsImageRuntime) GetJavaLibraries() []string {
	if x != nil {
		return x.JavaLibraries
	}
	return nil
}

func (x *Environment_InfrastructureSpec_OsImageRuntime) GetPythonPackages() []string {
	if x != nil {
		return x.PythonPackages
	}
	return nil
}

func (x *Environment_InfrastructureSpec_OsImageRuntime) GetProperties() map[string]string {
	if x != nil {
		return x.Properties
	}
	return nil
}

// The scan runs once via `RunDataScan` API.
type Trigger_OnDemand struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Trigger_OnDemand) Reset() {
	*x = Trigger_OnDemand{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[57]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Trigger_OnDemand) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Trigger_OnDemand) ProtoMessage() {}

func (x *Trigger_OnDemand) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[57]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Trigger_OnDemand.ProtoReflect.Descriptor instead.
func (*Trigger_OnDemand) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{5, 0}
}

// The scan is scheduled to run periodically.
type Trigger_Schedule struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Required. [Cron](https://en.wikipedia.org/wiki/Cron) schedule for running
	// scans periodically.
	//
	// To explicitly set a timezone in the cron tab, apply a prefix in the
	// cron tab: **"CRON_TZ=${IANA_TIME_ZONE}"** or **"TZ=${IANA_TIME_ZONE}"**.
	// The **${IANA_TIME_ZONE}** may only be a valid string from IANA time zone
	// database
	// ([wikipedia](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones#List)).
	// For example, `CRON_TZ=America/New_York 1 * * * *`, or
	// `TZ=America/New_York 1 * * * *`.
	//
	// This field is required for Schedule scans.
	Cron          string `protobuf:"bytes,1,opt,name=cron,proto3" json:"cron,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Trigger_Schedule) Reset() {
	*x = Trigger_Schedule{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[58]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Trigger_Schedule) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Trigger_Schedule) ProtoMessage() {}

func (x *Trigger_Schedule) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[58]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Trigger_Schedule.ProtoReflect.Descriptor instead.
func (*Trigger_Schedule) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{5, 1}
}

func (x *Trigger_Schedule) GetCron() string {
	if x != nil {
		return x.Cron
	}
	return ""
}

// A data range denoted by a pair of start/end values of a field.
type ScannedData_IncrementalField struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The field that contains values which monotonically increases over time
	// (e.g. a timestamp column).
	Field string `protobuf:"bytes,1,opt,name=field,proto3" json:"field,omitempty"`
	// Value that marks the start of the range.
	Start string `protobuf:"bytes,2,opt,name=start,proto3" json:"start,omitempty"`
	// Value that marks the end of the range.
	End           string `protobuf:"bytes,3,opt,name=end,proto3" json:"end,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ScannedData_IncrementalField) Reset() {
	*x = ScannedData_IncrementalField{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[59]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ScannedData_IncrementalField) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ScannedData_IncrementalField) ProtoMessage() {}

func (x *ScannedData_IncrementalField) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[59]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ScannedData_IncrementalField.ProtoReflect.Descriptor instead.
func (*ScannedData_IncrementalField) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{7, 0}
}

func (x *ScannedData_IncrementalField) GetField() string {
	if x != nil {
		return x.Field
	}
	return ""
}

func (x *ScannedData_IncrementalField) GetStart() string {
	if x != nil {
		return x.Start
	}
	return ""
}

func (x *ScannedData_IncrementalField) GetEnd() string {
	if x != nil {
		return x.End
	}
	return ""
}

// Contains name, type, mode and field type specific profile information.
type DataProfileResult_Profile struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// List of fields with structural and profile information for each field.
	Fields        []*DataProfileResult_Profile_Field `protobuf:"bytes,2,rep,name=fields,proto3" json:"fields,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataProfileResult_Profile) Reset() {
	*x = DataProfileResult_Profile{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[60]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataProfileResult_Profile) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataProfileResult_Profile) ProtoMessage() {}

func (x *DataProfileResult_Profile) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[60]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataProfileResult_Profile.ProtoReflect.Descriptor instead.
func (*DataProfileResult_Profile) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{9, 0}
}

func (x *DataProfileResult_Profile) GetFields() []*DataProfileResult_Profile_Field {
	if x != nil {
		return x.Fields
	}
	return nil
}

// A field within a table.
type DataProfileResult_Profile_Field struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The name of the field.
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// The field data type. Possible values include:
	//
	// * STRING
	// * BYTE
	// * INT64
	// * INT32
	// * INT16
	// * DOUBLE
	// * FLOAT
	// * DECIMAL
	// * BOOLEAN
	// * BINARY
	// * TIMESTAMP
	// * DATE
	// * TIME
	// * NULL
	// * RECORD
	Type string `protobuf:"bytes,2,opt,name=type,proto3" json:"type,omitempty"`
	// The mode of the field. Possible values include:
	//
	// * REQUIRED, if it is a required field.
	// * NULLABLE, if it is an optional field.
	// * REPEATED, if it is a repeated field.
	Mode string `protobuf:"bytes,3,opt,name=mode,proto3" json:"mode,omitempty"`
	// Profile information for the corresponding field.
	Profile       *DataProfileResult_Profile_Field_ProfileInfo `protobuf:"bytes,4,opt,name=profile,proto3" json:"profile,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataProfileResult_Profile_Field) Reset() {
	*x = DataProfileResult_Profile_Field{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[61]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataProfileResult_Profile_Field) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataProfileResult_Profile_Field) ProtoMessage() {}

func (x *DataProfileResult_Profile_Field) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[61]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataProfileResult_Profile_Field.ProtoReflect.Descriptor instead.
func (*DataProfileResult_Profile_Field) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{9, 0, 0}
}

func (x *DataProfileResult_Profile_Field) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *DataProfileResult_Profile_Field) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *DataProfileResult_Profile_Field) GetMode() string {
	if x != nil {
		return x.Mode
	}
	return ""
}

func (x *DataProfileResult_Profile_Field) GetProfile() *DataProfileResult_Profile_Field_ProfileInfo {
	if x != nil {
		return x.Profile
	}
	return nil
}

// The profile information for each field type.
type DataProfileResult_Profile_Field_ProfileInfo struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Ratio of rows with null value against total scanned rows.
	NullRatio float64 `protobuf:"fixed64,2,opt,name=null_ratio,json=nullRatio,proto3" json:"null_ratio,omitempty"`
	// Ratio of rows with distinct values against total scanned rows.
	// Not available for complex non-groupable field type RECORD and fields
	// with REPEATABLE mode.
	DistinctRatio float64 `protobuf:"fixed64,3,opt,name=distinct_ratio,json=distinctRatio,proto3" json:"distinct_ratio,omitempty"`
	// The list of top N non-null values and number of times they occur in
	// the scanned data. N is 10 or equal to the number of distinct values
	// in the field, whichever is smaller. Not available for complex
	// non-groupable field type RECORD and fields with REPEATABLE mode.
	TopNValues []*DataProfileResult_Profile_Field_ProfileInfo_TopNValue `protobuf:"bytes,4,rep,name=top_n_values,json=topNValues,proto3" json:"top_n_values,omitempty"`
	// Structural and profile information for specific field type. Not
	// available, if mode is REPEATABLE.
	//
	// Types that are valid to be assigned to FieldInfo:
	//
	//	*DataProfileResult_Profile_Field_ProfileInfo_StringProfile
	//	*DataProfileResult_Profile_Field_ProfileInfo_IntegerProfile
	//	*DataProfileResult_Profile_Field_ProfileInfo_DoubleProfile
	FieldInfo     isDataProfileResult_Profile_Field_ProfileInfo_FieldInfo `protobuf_oneof:"field_info"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataProfileResult_Profile_Field_ProfileInfo) Reset() {
	*x = DataProfileResult_Profile_Field_ProfileInfo{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[62]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataProfileResult_Profile_Field_ProfileInfo) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataProfileResult_Profile_Field_ProfileInfo) ProtoMessage() {}

func (x *DataProfileResult_Profile_Field_ProfileInfo) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[62]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataProfileResult_Profile_Field_ProfileInfo.ProtoReflect.Descriptor instead.
func (*DataProfileResult_Profile_Field_ProfileInfo) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{9, 0, 0, 0}
}

func (x *DataProfileResult_Profile_Field_ProfileInfo) GetNullRatio() float64 {
	if x != nil {
		return x.NullRatio
	}
	return 0
}

func (x *DataProfileResult_Profile_Field_ProfileInfo) GetDistinctRatio() float64 {
	if x != nil {
		return x.DistinctRatio
	}
	return 0
}

func (x *DataProfileResult_Profile_Field_ProfileInfo) GetTopNValues() []*DataProfileResult_Profile_Field_ProfileInfo_TopNValue {
	if x != nil {
		return x.TopNValues
	}
	return nil
}

func (x *DataProfileResult_Profile_Field_ProfileInfo) GetFieldInfo() isDataProfileResult_Profile_Field_ProfileInfo_FieldInfo {
	if x != nil {
		return x.FieldInfo
	}
	return nil
}

func (x *DataProfileResult_Profile_Field_ProfileInfo) GetStringProfile() *DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo {
	if x != nil {
		if x, ok := x.FieldInfo.(*DataProfileResult_Profile_Field_ProfileInfo_StringProfile); ok {
			return x.StringProfile
		}
	}
	return nil
}

func (x *DataProfileResult_Profile_Field_ProfileInfo) GetIntegerProfile() *DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo {
	if x != nil {
		if x, ok := x.FieldInfo.(*DataProfileResult_Profile_Field_ProfileInfo_IntegerProfile); ok {
			return x.IntegerProfile
		}
	}
	return nil
}

func (x *DataProfileResult_Profile_Field_ProfileInfo) GetDoubleProfile() *DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo {
	if x != nil {
		if x, ok := x.FieldInfo.(*DataProfileResult_Profile_Field_ProfileInfo_DoubleProfile); ok {
			return x.DoubleProfile
		}
	}
	return nil
}

type isDataProfileResult_Profile_Field_ProfileInfo_FieldInfo interface {
	isDataProfileResult_Profile_Field_ProfileInfo_FieldInfo()
}

type DataProfileResult_Profile_Field_ProfileInfo_StringProfile struct {
	// String type field information.
	StringProfile *DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo `protobuf:"bytes,101,opt,name=string_profile,json=stringProfile,proto3,oneof"`
}

type DataProfileResult_Profile_Field_ProfileInfo_IntegerProfile struct {
	// Integer type field information.
	IntegerProfile *DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo `protobuf:"bytes,102,opt,name=integer_profile,json=integerProfile,proto3,oneof"`
}

type DataProfileResult_Profile_Field_ProfileInfo_DoubleProfile struct {
	// Double type field information.
	DoubleProfile *DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo `protobuf:"bytes,103,opt,name=double_profile,json=doubleProfile,proto3,oneof"`
}

func (*DataProfileResult_Profile_Field_ProfileInfo_StringProfile) isDataProfileResult_Profile_Field_ProfileInfo_FieldInfo() {
}

func (*DataProfileResult_Profile_Field_ProfileInfo_IntegerProfile) isDataProfileResult_Profile_Field_ProfileInfo_FieldInfo() {
}

func (*DataProfileResult_Profile_Field_ProfileInfo_DoubleProfile) isDataProfileResult_Profile_Field_ProfileInfo_FieldInfo() {
}

// The profile information for a string type field.
type DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Minimum length of non-null values in the scanned data.
	MinLength int64 `protobuf:"varint,1,opt,name=min_length,json=minLength,proto3" json:"min_length,omitempty"`
	// Maximum length of non-null values in the scanned data.
	MaxLength int64 `protobuf:"varint,2,opt,name=max_length,json=maxLength,proto3" json:"max_length,omitempty"`
	// Average length of non-null values in the scanned data.
	AverageLength float64 `protobuf:"fixed64,3,opt,name=average_length,json=averageLength,proto3" json:"average_length,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo) Reset() {
	*x = DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[63]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo) ProtoMessage() {}

func (x *DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[63]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo.ProtoReflect.Descriptor instead.
func (*DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{9, 0, 0, 0, 0}
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo) GetMinLength() int64 {
	if x != nil {
		return x.MinLength
	}
	return 0
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo) GetMaxLength() int64 {
	if x != nil {
		return x.MaxLength
	}
	return 0
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo) GetAverageLength() float64 {
	if x != nil {
		return x.AverageLength
	}
	return 0
}

// The profile information for an integer type field.
type DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Average of non-null values in the scanned data. NaN, if the field
	// has a NaN.
	Average float64 `protobuf:"fixed64,1,opt,name=average,proto3" json:"average,omitempty"`
	// Standard deviation of non-null values in the scanned data. NaN, if
	// the field has a NaN.
	StandardDeviation float64 `protobuf:"fixed64,3,opt,name=standard_deviation,json=standardDeviation,proto3" json:"standard_deviation,omitempty"`
	// Minimum of non-null values in the scanned data. NaN, if the field
	// has a NaN.
	Min int64 `protobuf:"varint,4,opt,name=min,proto3" json:"min,omitempty"`
	// A quartile divides the number of data points into four parts, or
	// quarters, of more-or-less equal size. Three main quartiles used
	// are: The first quartile (Q1) splits off the lowest 25% of data from
	// the highest 75%. It is also known as the lower or 25th empirical
	// quartile, as 25% of the data is below this point. The second
	// quartile (Q2) is the median of a data set. So, 50% of the data lies
	// below this point. The third quartile (Q3) splits off the highest
	// 25% of data from the lowest 75%. It is known as the upper or 75th
	// empirical quartile, as 75% of the data lies below this point.
	// Here, the quartiles is provided as an ordered list of quartile
	// values for the scanned data, occurring in order Q1, median, Q3.
	Quartiles []int64 `protobuf:"varint,6,rep,packed,name=quartiles,proto3" json:"quartiles,omitempty"`
	// Maximum of non-null values in the scanned data. NaN, if the field
	// has a NaN.
	Max           int64 `protobuf:"varint,5,opt,name=max,proto3" json:"max,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo) Reset() {
	*x = DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[64]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo) ProtoMessage() {}

func (x *DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[64]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo.ProtoReflect.Descriptor instead.
func (*DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{9, 0, 0, 0, 1}
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo) GetAverage() float64 {
	if x != nil {
		return x.Average
	}
	return 0
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo) GetStandardDeviation() float64 {
	if x != nil {
		return x.StandardDeviation
	}
	return 0
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo) GetMin() int64 {
	if x != nil {
		return x.Min
	}
	return 0
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo) GetQuartiles() []int64 {
	if x != nil {
		return x.Quartiles
	}
	return nil
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo) GetMax() int64 {
	if x != nil {
		return x.Max
	}
	return 0
}

// The profile information for a double type field.
type DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Average of non-null values in the scanned data. NaN, if the field
	// has a NaN.
	Average float64 `protobuf:"fixed64,1,opt,name=average,proto3" json:"average,omitempty"`
	// Standard deviation of non-null values in the scanned data. NaN, if
	// the field has a NaN.
	StandardDeviation float64 `protobuf:"fixed64,3,opt,name=standard_deviation,json=standardDeviation,proto3" json:"standard_deviation,omitempty"`
	// Minimum of non-null values in the scanned data. NaN, if the field
	// has a NaN.
	Min float64 `protobuf:"fixed64,4,opt,name=min,proto3" json:"min,omitempty"`
	// A quartile divides the number of data points into four parts, or
	// quarters, of more-or-less equal size. Three main quartiles used
	// are: The first quartile (Q1) splits off the lowest 25% of data from
	// the highest 75%. It is also known as the lower or 25th empirical
	// quartile, as 25% of the data is below this point. The second
	// quartile (Q2) is the median of a data set. So, 50% of the data lies
	// below this point. The third quartile (Q3) splits off the highest
	// 25% of data from the lowest 75%. It is known as the upper or 75th
	// empirical quartile, as 75% of the data lies below this point.
	// Here, the quartiles is provided as an ordered list of quartile
	// values for the scanned data, occurring in order Q1, median, Q3.
	Quartiles []float64 `protobuf:"fixed64,6,rep,packed,name=quartiles,proto3" json:"quartiles,omitempty"`
	// Maximum of non-null values in the scanned data. NaN, if the field
	// has a NaN.
	Max           float64 `protobuf:"fixed64,5,opt,name=max,proto3" json:"max,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo) Reset() {
	*x = DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[65]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo) ProtoMessage() {}

func (x *DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[65]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo.ProtoReflect.Descriptor instead.
func (*DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{9, 0, 0, 0, 2}
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo) GetAverage() float64 {
	if x != nil {
		return x.Average
	}
	return 0
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo) GetStandardDeviation() float64 {
	if x != nil {
		return x.StandardDeviation
	}
	return 0
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo) GetMin() float64 {
	if x != nil {
		return x.Min
	}
	return 0
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo) GetQuartiles() []float64 {
	if x != nil {
		return x.Quartiles
	}
	return nil
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo) GetMax() float64 {
	if x != nil {
		return x.Max
	}
	return 0
}

// Top N non-null values in the scanned data.
type DataProfileResult_Profile_Field_ProfileInfo_TopNValue struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// String value of a top N non-null value.
	Value string `protobuf:"bytes,1,opt,name=value,proto3" json:"value,omitempty"`
	// Count of the corresponding value in the scanned data.
	Count         int64 `protobuf:"varint,2,opt,name=count,proto3" json:"count,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_TopNValue) Reset() {
	*x = DataProfileResult_Profile_Field_ProfileInfo_TopNValue{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[66]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_TopNValue) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataProfileResult_Profile_Field_ProfileInfo_TopNValue) ProtoMessage() {}

func (x *DataProfileResult_Profile_Field_ProfileInfo_TopNValue) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[66]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataProfileResult_Profile_Field_ProfileInfo_TopNValue.ProtoReflect.Descriptor instead.
func (*DataProfileResult_Profile_Field_ProfileInfo_TopNValue) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{9, 0, 0, 0, 3}
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_TopNValue) GetValue() string {
	if x != nil {
		return x.Value
	}
	return ""
}

func (x *DataProfileResult_Profile_Field_ProfileInfo_TopNValue) GetCount() int64 {
	if x != nil {
		return x.Count
	}
	return 0
}

// Evaluates whether each column value lies between a specified range.
type DataQualityRule_RangeExpectation struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The minimum column value allowed for a row to pass this
	// validation. At least one of `min_value` and `max_value` need to be
	// provided.
	MinValue string `protobuf:"bytes,1,opt,name=min_value,json=minValue,proto3" json:"min_value,omitempty"`
	// Optional. The maximum column value allowed for a row to pass this
	// validation. At least one of `min_value` and `max_value` need to be
	// provided.
	MaxValue string `protobuf:"bytes,2,opt,name=max_value,json=maxValue,proto3" json:"max_value,omitempty"`
	// Optional. Whether each value needs to be strictly greater than ('>') the
	// minimum, or if equality is allowed.
	//
	// Only relevant if a `min_value` has been defined. Default = false.
	StrictMinEnabled bool `protobuf:"varint,3,opt,name=strict_min_enabled,json=strictMinEnabled,proto3" json:"strict_min_enabled,omitempty"`
	// Optional. Whether each value needs to be strictly lesser than ('<') the
	// maximum, or if equality is allowed.
	//
	// Only relevant if a `max_value` has been defined. Default = false.
	StrictMaxEnabled bool `protobuf:"varint,4,opt,name=strict_max_enabled,json=strictMaxEnabled,proto3" json:"strict_max_enabled,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *DataQualityRule_RangeExpectation) Reset() {
	*x = DataQualityRule_RangeExpectation{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[67]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataQualityRule_RangeExpectation) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataQualityRule_RangeExpectation) ProtoMessage() {}

func (x *DataQualityRule_RangeExpectation) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[67]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataQualityRule_RangeExpectation.ProtoReflect.Descriptor instead.
func (*DataQualityRule_RangeExpectation) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{14, 0}
}

func (x *DataQualityRule_RangeExpectation) GetMinValue() string {
	if x != nil {
		return x.MinValue
	}
	return ""
}

func (x *DataQualityRule_RangeExpectation) GetMaxValue() string {
	if x != nil {
		return x.MaxValue
	}
	return ""
}

func (x *DataQualityRule_RangeExpectation) GetStrictMinEnabled() bool {
	if x != nil {
		return x.StrictMinEnabled
	}
	return false
}

func (x *DataQualityRule_RangeExpectation) GetStrictMaxEnabled() bool {
	if x != nil {
		return x.StrictMaxEnabled
	}
	return false
}

// Evaluates whether each column value is null.
type DataQualityRule_NonNullExpectation struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataQualityRule_NonNullExpectation) Reset() {
	*x = DataQualityRule_NonNullExpectation{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[68]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataQualityRule_NonNullExpectation) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataQualityRule_NonNullExpectation) ProtoMessage() {}

func (x *DataQualityRule_NonNullExpectation) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[68]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataQualityRule_NonNullExpectation.ProtoReflect.Descriptor instead.
func (*DataQualityRule_NonNullExpectation) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{14, 1}
}

// Evaluates whether each column value is contained by a specified set.
type DataQualityRule_SetExpectation struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Expected values for the column value.
	Values        []string `protobuf:"bytes,1,rep,name=values,proto3" json:"values,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataQualityRule_SetExpectation) Reset() {
	*x = DataQualityRule_SetExpectation{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[69]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataQualityRule_SetExpectation) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataQualityRule_SetExpectation) ProtoMessage() {}

func (x *DataQualityRule_SetExpectation) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[69]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataQualityRule_SetExpectation.ProtoReflect.Descriptor instead.
func (*DataQualityRule_SetExpectation) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{14, 2}
}

func (x *DataQualityRule_SetExpectation) GetValues() []string {
	if x != nil {
		return x.Values
	}
	return nil
}

// Evaluates whether each column value matches a specified regex.
type DataQualityRule_RegexExpectation struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// A regular expression the column value is expected to match.
	Regex         string `protobuf:"bytes,1,opt,name=regex,proto3" json:"regex,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataQualityRule_RegexExpectation) Reset() {
	*x = DataQualityRule_RegexExpectation{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[70]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataQualityRule_RegexExpectation) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataQualityRule_RegexExpectation) ProtoMessage() {}

func (x *DataQualityRule_RegexExpectation) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[70]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataQualityRule_RegexExpectation.ProtoReflect.Descriptor instead.
func (*DataQualityRule_RegexExpectation) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{14, 3}
}

func (x *DataQualityRule_RegexExpectation) GetRegex() string {
	if x != nil {
		return x.Regex
	}
	return ""
}

// Evaluates whether the column has duplicates.
type DataQualityRule_UniquenessExpectation struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataQualityRule_UniquenessExpectation) Reset() {
	*x = DataQualityRule_UniquenessExpectation{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[71]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataQualityRule_UniquenessExpectation) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataQualityRule_UniquenessExpectation) ProtoMessage() {}

func (x *DataQualityRule_UniquenessExpectation) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[71]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataQualityRule_UniquenessExpectation.ProtoReflect.Descriptor instead.
func (*DataQualityRule_UniquenessExpectation) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{14, 4}
}

// Evaluates whether the column aggregate statistic lies between a specified
// range.
type DataQualityRule_StatisticRangeExpectation struct {
	state     protoimpl.MessageState                                    `protogen:"open.v1"`
	Statistic DataQualityRule_StatisticRangeExpectation_ColumnStatistic `protobuf:"varint,1,opt,name=statistic,proto3,enum=google.events.cloud.dataplex.v1.DataQualityRule_StatisticRangeExpectation_ColumnStatistic" json:"statistic,omitempty"`
	// The minimum column statistic value allowed for a row to pass this
	// validation.
	//
	// At least one of `min_value` and `max_value` need to be provided.
	MinValue string `protobuf:"bytes,2,opt,name=min_value,json=minValue,proto3" json:"min_value,omitempty"`
	// The maximum column statistic value allowed for a row to pass this
	// validation.
	//
	// At least one of `min_value` and `max_value` need to be provided.
	MaxValue string `protobuf:"bytes,3,opt,name=max_value,json=maxValue,proto3" json:"max_value,omitempty"`
	// Whether column statistic needs to be strictly greater than ('>')
	// the minimum, or if equality is allowed.
	//
	// Only relevant if a `min_value` has been defined. Default = false.
	StrictMinEnabled bool `protobuf:"varint,4,opt,name=strict_min_enabled,json=strictMinEnabled,proto3" json:"strict_min_enabled,omitempty"`
	// Whether column statistic needs to be strictly lesser than ('<') the
	// maximum, or if equality is allowed.
	//
	// Only relevant if a `max_value` has been defined. Default = false.
	StrictMaxEnabled bool `protobuf:"varint,5,opt,name=strict_max_enabled,json=strictMaxEnabled,proto3" json:"strict_max_enabled,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *DataQualityRule_StatisticRangeExpectation) Reset() {
	*x = DataQualityRule_StatisticRangeExpectation{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[72]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataQualityRule_StatisticRangeExpectation) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataQualityRule_StatisticRangeExpectation) ProtoMessage() {}

func (x *DataQualityRule_StatisticRangeExpectation) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[72]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataQualityRule_StatisticRangeExpectation.ProtoReflect.Descriptor instead.
func (*DataQualityRule_StatisticRangeExpectation) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{14, 5}
}

func (x *DataQualityRule_StatisticRangeExpectation) GetStatistic() DataQualityRule_StatisticRangeExpectation_ColumnStatistic {
	if x != nil {
		return x.Statistic
	}
	return DataQualityRule_StatisticRangeExpectation_STATISTIC_UNDEFINED
}

func (x *DataQualityRule_StatisticRangeExpectation) GetMinValue() string {
	if x != nil {
		return x.MinValue
	}
	return ""
}

func (x *DataQualityRule_StatisticRangeExpectation) GetMaxValue() string {
	if x != nil {
		return x.MaxValue
	}
	return ""
}

func (x *DataQualityRule_StatisticRangeExpectation) GetStrictMinEnabled() bool {
	if x != nil {
		return x.StrictMinEnabled
	}
	return false
}

func (x *DataQualityRule_StatisticRangeExpectation) GetStrictMaxEnabled() bool {
	if x != nil {
		return x.StrictMaxEnabled
	}
	return false
}

// Evaluates whether each row passes the specified condition.
//
// The SQL expression needs to use BigQuery standard SQL syntax and should
// produce a boolean value per row as the result.
//
// Example: col1 >= 0 AND col2 < 10
type DataQualityRule_RowConditionExpectation struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The SQL expression.
	SqlExpression string `protobuf:"bytes,1,opt,name=sql_expression,json=sqlExpression,proto3" json:"sql_expression,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataQualityRule_RowConditionExpectation) Reset() {
	*x = DataQualityRule_RowConditionExpectation{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[73]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataQualityRule_RowConditionExpectation) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataQualityRule_RowConditionExpectation) ProtoMessage() {}

func (x *DataQualityRule_RowConditionExpectation) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[73]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataQualityRule_RowConditionExpectation.ProtoReflect.Descriptor instead.
func (*DataQualityRule_RowConditionExpectation) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{14, 6}
}

func (x *DataQualityRule_RowConditionExpectation) GetSqlExpression() string {
	if x != nil {
		return x.SqlExpression
	}
	return ""
}

// Evaluates whether the provided expression is true.
//
// The SQL expression needs to use BigQuery standard SQL syntax and should
// produce a scalar boolean result.
//
// Example: MIN(col1) >= 0
type DataQualityRule_TableConditionExpectation struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The SQL expression.
	SqlExpression string `protobuf:"bytes,1,opt,name=sql_expression,json=sqlExpression,proto3" json:"sql_expression,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataQualityRule_TableConditionExpectation) Reset() {
	*x = DataQualityRule_TableConditionExpectation{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[74]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataQualityRule_TableConditionExpectation) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataQualityRule_TableConditionExpectation) ProtoMessage() {}

func (x *DataQualityRule_TableConditionExpectation) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[74]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataQualityRule_TableConditionExpectation.ProtoReflect.Descriptor instead.
func (*DataQualityRule_TableConditionExpectation) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{14, 7}
}

func (x *DataQualityRule_TableConditionExpectation) GetSqlExpression() string {
	if x != nil {
		return x.SqlExpression
	}
	return ""
}

// Represents a subresource of a given resource, and associated bindings with
// it.
type DataAttributeBinding_Path struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Required. The name identifier of the path.
	// Nested columns should be of the form: 'country.state.city'.
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Optional. List of attributes to be associated with the path of the
	// resource, provided in the form:
	// projects/{project}/locations/{location}/dataTaxonomies/{dataTaxonomy}/attributes/{data_attribute_id}
	Attributes    []string `protobuf:"bytes,2,rep,name=attributes,proto3" json:"attributes,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataAttributeBinding_Path) Reset() {
	*x = DataAttributeBinding_Path{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[77]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataAttributeBinding_Path) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataAttributeBinding_Path) ProtoMessage() {}

func (x *DataAttributeBinding_Path) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[77]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataAttributeBinding_Path.ProtoReflect.Descriptor instead.
func (*DataAttributeBinding_Path) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{19, 0}
}

func (x *DataAttributeBinding_Path) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *DataAttributeBinding_Path) GetAttributes() []string {
	if x != nil {
		return x.Attributes
	}
	return nil
}

// DataScan execution settings.
type DataScan_ExecutionSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. Spec related to how often and when a scan should be triggered.
	//
	// If not specified, the default is `OnDemand`, which means the scan will
	// not run until the user calls `RunDataScan` API.
	Trigger *Trigger `protobuf:"bytes,1,opt,name=trigger,proto3" json:"trigger,omitempty"`
	// Spec related to incremental scan of the data
	//
	// When an option is selected for incremental scan, it cannot be unset or
	// changed. If not specified, a data scan will run for all data in the
	// table.
	//
	// Types that are valid to be assigned to Incremental:
	//
	//	*DataScan_ExecutionSpec_Field
	Incremental   isDataScan_ExecutionSpec_Incremental `protobuf_oneof:"incremental"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DataScan_ExecutionSpec) Reset() {
	*x = DataScan_ExecutionSpec{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[79]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataScan_ExecutionSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataScan_ExecutionSpec) ProtoMessage() {}

func (x *DataScan_ExecutionSpec) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[79]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataScan_ExecutionSpec.ProtoReflect.Descriptor instead.
func (*DataScan_ExecutionSpec) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{20, 0}
}

func (x *DataScan_ExecutionSpec) GetTrigger() *Trigger {
	if x != nil {
		return x.Trigger
	}
	return nil
}

func (x *DataScan_ExecutionSpec) GetIncremental() isDataScan_ExecutionSpec_Incremental {
	if x != nil {
		return x.Incremental
	}
	return nil
}

func (x *DataScan_ExecutionSpec) GetField() string {
	if x != nil {
		if x, ok := x.Incremental.(*DataScan_ExecutionSpec_Field); ok {
			return x.Field
		}
	}
	return ""
}

type isDataScan_ExecutionSpec_Incremental interface {
	isDataScan_ExecutionSpec_Incremental()
}

type DataScan_ExecutionSpec_Field struct {
	// Immutable. The unnested field (of type *Date* or *Timestamp*) that
	// contains values which monotonically increase over time.
	//
	// If not specified, a data scan will run for all data in the table.
	Field string `protobuf:"bytes,100,opt,name=field,proto3,oneof"`
}

func (*DataScan_ExecutionSpec_Field) isDataScan_ExecutionSpec_Incremental() {}

// Status of the data scan execution.
type DataScan_ExecutionStatus struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The time when the latest DataScanJob started.
	LatestJobStartTime *timestamppb.Timestamp `protobuf:"bytes,4,opt,name=latest_job_start_time,json=latestJobStartTime,proto3" json:"latest_job_start_time,omitempty"`
	// The time when the latest DataScanJob ended.
	LatestJobEndTime *timestamppb.Timestamp `protobuf:"bytes,5,opt,name=latest_job_end_time,json=latestJobEndTime,proto3" json:"latest_job_end_time,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *DataScan_ExecutionStatus) Reset() {
	*x = DataScan_ExecutionStatus{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[80]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DataScan_ExecutionStatus) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DataScan_ExecutionStatus) ProtoMessage() {}

func (x *DataScan_ExecutionStatus) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[80]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DataScan_ExecutionStatus.ProtoReflect.Descriptor instead.
func (*DataScan_ExecutionStatus) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{20, 1}
}

func (x *DataScan_ExecutionStatus) GetLatestJobStartTime() *timestamppb.Timestamp {
	if x != nil {
		return x.LatestJobStartTime
	}
	return nil
}

func (x *DataScan_ExecutionStatus) GetLatestJobEndTime() *timestamppb.Timestamp {
	if x != nil {
		return x.LatestJobEndTime
	}
	return nil
}

// Configuration for the underlying infrastructure used to run workloads.
type Task_InfrastructureSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Hardware config.
	//
	// Types that are valid to be assigned to Resources:
	//
	//	*Task_InfrastructureSpec_Batch
	Resources isTask_InfrastructureSpec_Resources `protobuf_oneof:"resources"`
	// Software config.
	//
	// Types that are valid to be assigned to Runtime:
	//
	//	*Task_InfrastructureSpec_ContainerImage
	Runtime isTask_InfrastructureSpec_Runtime `protobuf_oneof:"runtime"`
	// Networking config.
	//
	// Types that are valid to be assigned to Network:
	//
	//	*Task_InfrastructureSpec_VpcNetwork_
	Network       isTask_InfrastructureSpec_Network `protobuf_oneof:"network"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Task_InfrastructureSpec) Reset() {
	*x = Task_InfrastructureSpec{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[82]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Task_InfrastructureSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Task_InfrastructureSpec) ProtoMessage() {}

func (x *Task_InfrastructureSpec) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[82]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Task_InfrastructureSpec.ProtoReflect.Descriptor instead.
func (*Task_InfrastructureSpec) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{21, 0}
}

func (x *Task_InfrastructureSpec) GetResources() isTask_InfrastructureSpec_Resources {
	if x != nil {
		return x.Resources
	}
	return nil
}

func (x *Task_InfrastructureSpec) GetBatch() *Task_InfrastructureSpec_BatchComputeResources {
	if x != nil {
		if x, ok := x.Resources.(*Task_InfrastructureSpec_Batch); ok {
			return x.Batch
		}
	}
	return nil
}

func (x *Task_InfrastructureSpec) GetRuntime() isTask_InfrastructureSpec_Runtime {
	if x != nil {
		return x.Runtime
	}
	return nil
}

func (x *Task_InfrastructureSpec) GetContainerImage() *Task_InfrastructureSpec_ContainerImageRuntime {
	if x != nil {
		if x, ok := x.Runtime.(*Task_InfrastructureSpec_ContainerImage); ok {
			return x.ContainerImage
		}
	}
	return nil
}

func (x *Task_InfrastructureSpec) GetNetwork() isTask_InfrastructureSpec_Network {
	if x != nil {
		return x.Network
	}
	return nil
}

func (x *Task_InfrastructureSpec) GetVpcNetwork() *Task_InfrastructureSpec_VpcNetwork {
	if x != nil {
		if x, ok := x.Network.(*Task_InfrastructureSpec_VpcNetwork_); ok {
			return x.VpcNetwork
		}
	}
	return nil
}

type isTask_InfrastructureSpec_Resources interface {
	isTask_InfrastructureSpec_Resources()
}

type Task_InfrastructureSpec_Batch struct {
	// Compute resources needed for a Task when using Dataproc Serverless.
	Batch *Task_InfrastructureSpec_BatchComputeResources `protobuf:"bytes,52,opt,name=batch,proto3,oneof"`
}

func (*Task_InfrastructureSpec_Batch) isTask_InfrastructureSpec_Resources() {}

type isTask_InfrastructureSpec_Runtime interface {
	isTask_InfrastructureSpec_Runtime()
}

type Task_InfrastructureSpec_ContainerImage struct {
	// Container Image Runtime Configuration.
	ContainerImage *Task_InfrastructureSpec_ContainerImageRuntime `protobuf:"bytes,101,opt,name=container_image,json=containerImage,proto3,oneof"`
}

func (*Task_InfrastructureSpec_ContainerImage) isTask_InfrastructureSpec_Runtime() {}

type isTask_InfrastructureSpec_Network interface {
	isTask_InfrastructureSpec_Network()
}

type Task_InfrastructureSpec_VpcNetwork_ struct {
	// Vpc network.
	VpcNetwork *Task_InfrastructureSpec_VpcNetwork `protobuf:"bytes,150,opt,name=vpc_network,json=vpcNetwork,proto3,oneof"`
}

func (*Task_InfrastructureSpec_VpcNetwork_) isTask_InfrastructureSpec_Network() {}

// Task scheduling and trigger settings.
type Task_TriggerSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Required. Immutable. Trigger type of the user-specified Task.
	Type Task_TriggerSpec_Type `protobuf:"varint,5,opt,name=type,proto3,enum=google.events.cloud.dataplex.v1.Task_TriggerSpec_Type" json:"type,omitempty"`
	// Optional. The first run of the task will be after this time.
	// If not specified, the task will run shortly after being submitted if
	// ON_DEMAND and based on the schedule if RECURRING.
	StartTime *timestamppb.Timestamp `protobuf:"bytes,6,opt,name=start_time,json=startTime,proto3" json:"start_time,omitempty"`
	// Optional. Prevent the task from executing.
	// This does not cancel already running tasks. It is intended to temporarily
	// disable RECURRING tasks.
	Disabled bool `protobuf:"varint,4,opt,name=disabled,proto3" json:"disabled,omitempty"`
	// Optional. Number of retry attempts before aborting.
	// Set to zero to never attempt to retry a failed task.
	MaxRetries int32 `protobuf:"varint,7,opt,name=max_retries,json=maxRetries,proto3" json:"max_retries,omitempty"`
	// Trigger only applies for RECURRING tasks.
	//
	// Types that are valid to be assigned to Trigger:
	//
	//	*Task_TriggerSpec_Schedule
	Trigger       isTask_TriggerSpec_Trigger `protobuf_oneof:"trigger"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Task_TriggerSpec) Reset() {
	*x = Task_TriggerSpec{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[83]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Task_TriggerSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Task_TriggerSpec) ProtoMessage() {}

func (x *Task_TriggerSpec) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[83]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Task_TriggerSpec.ProtoReflect.Descriptor instead.
func (*Task_TriggerSpec) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{21, 1}
}

func (x *Task_TriggerSpec) GetType() Task_TriggerSpec_Type {
	if x != nil {
		return x.Type
	}
	return Task_TriggerSpec_TYPE_UNSPECIFIED
}

func (x *Task_TriggerSpec) GetStartTime() *timestamppb.Timestamp {
	if x != nil {
		return x.StartTime
	}
	return nil
}

func (x *Task_TriggerSpec) GetDisabled() bool {
	if x != nil {
		return x.Disabled
	}
	return false
}

func (x *Task_TriggerSpec) GetMaxRetries() int32 {
	if x != nil {
		return x.MaxRetries
	}
	return 0
}

func (x *Task_TriggerSpec) GetTrigger() isTask_TriggerSpec_Trigger {
	if x != nil {
		return x.Trigger
	}
	return nil
}

func (x *Task_TriggerSpec) GetSchedule() string {
	if x != nil {
		if x, ok := x.Trigger.(*Task_TriggerSpec_Schedule); ok {
			return x.Schedule
		}
	}
	return ""
}

type isTask_TriggerSpec_Trigger interface {
	isTask_TriggerSpec_Trigger()
}

type Task_TriggerSpec_Schedule struct {
	// Optional. Cron schedule (https://en.wikipedia.org/wiki/Cron) for
	// running tasks periodically. To explicitly set a timezone to the cron
	// tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or
	// "TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid
	// string from IANA time zone database. For example,
	// `CRON_TZ=America/New_York 1 * * * *`, or `TZ=America/New_York 1 * * *
	// *`. This field is required for RECURRING tasks.
	Schedule string `protobuf:"bytes,100,opt,name=schedule,proto3,oneof"`
}

func (*Task_TriggerSpec_Schedule) isTask_TriggerSpec_Trigger() {}

// Execution related settings, like retry and service_account.
type Task_ExecutionSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The arguments to pass to the task.
	// The args can use placeholders of the format ${placeholder} as
	// part of key/value string. These will be interpolated before passing the
	// args to the driver. Currently supported placeholders:
	// - ${task_id}
	// - ${job_time}
	// To pass positional args, set the key as TASK_ARGS. The value should be a
	// comma-separated string of all the positional arguments. To use a
	// delimiter other than comma, refer to
	// https://cloud.google.com/sdk/gcloud/reference/topic/escaping. In case of
	// other keys being present in the args, then TASK_ARGS will be passed as
	// the last argument.
	Args map[string]string `protobuf:"bytes,4,rep,name=args,proto3" json:"args,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	// Required. Service account to use to execute a task.
	// If not provided, the default Compute service account for the project is
	// used.
	ServiceAccount string `protobuf:"bytes,5,opt,name=service_account,json=serviceAccount,proto3" json:"service_account,omitempty"`
	// Optional. The project in which jobs are run. By default, the project
	// containing the Lake is used. If a project is provided, the
	// [ExecutionSpec.service_account][google.cloud.dataplex.v1.Task.ExecutionSpec.service_account]
	// must belong to this project.
	Project string `protobuf:"bytes,7,opt,name=project,proto3" json:"project,omitempty"`
	// Optional. The maximum duration after which the job execution is expired.
	MaxJobExecutionLifetime *durationpb.Duration `protobuf:"bytes,8,opt,name=max_job_execution_lifetime,json=maxJobExecutionLifetime,proto3" json:"max_job_execution_lifetime,omitempty"`
	// Optional. The Cloud KMS key to use for encryption, of the form:
	// `projects/{project_number}/locations/{location_id}/keyRings/{key-ring-name}/cryptoKeys/{key-name}`.
	KmsKey        string `protobuf:"bytes,9,opt,name=kms_key,json=kmsKey,proto3" json:"kms_key,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Task_ExecutionSpec) Reset() {
	*x = Task_ExecutionSpec{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[84]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Task_ExecutionSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Task_ExecutionSpec) ProtoMessage() {}

func (x *Task_ExecutionSpec) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[84]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Task_ExecutionSpec.ProtoReflect.Descriptor instead.
func (*Task_ExecutionSpec) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{21, 2}
}

func (x *Task_ExecutionSpec) GetArgs() map[string]string {
	if x != nil {
		return x.Args
	}
	return nil
}

func (x *Task_ExecutionSpec) GetServiceAccount() string {
	if x != nil {
		return x.ServiceAccount
	}
	return ""
}

func (x *Task_ExecutionSpec) GetProject() string {
	if x != nil {
		return x.Project
	}
	return ""
}

func (x *Task_ExecutionSpec) GetMaxJobExecutionLifetime() *durationpb.Duration {
	if x != nil {
		return x.MaxJobExecutionLifetime
	}
	return nil
}

func (x *Task_ExecutionSpec) GetKmsKey() string {
	if x != nil {
		return x.KmsKey
	}
	return ""
}

// User-specified config for running a Spark task.
type Task_SparkTaskConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Required. The specification of the main method to call to drive the
	// job. Specify either the jar file that contains the main class or the
	// main class name.
	//
	// Types that are valid to be assigned to Driver:
	//
	//	*Task_SparkTaskConfig_MainJarFileUri
	//	*Task_SparkTaskConfig_MainClass
	//	*Task_SparkTaskConfig_PythonScriptFile
	//	*Task_SparkTaskConfig_SqlScriptFile
	//	*Task_SparkTaskConfig_SqlScript
	Driver isTask_SparkTaskConfig_Driver `protobuf_oneof:"driver"`
	// Optional. Cloud Storage URIs of files to be placed in the working
	// directory of each executor.
	FileUris []string `protobuf:"bytes,3,rep,name=file_uris,json=fileUris,proto3" json:"file_uris,omitempty"`
	// Optional. Cloud Storage URIs of archives to be extracted into the working
	// directory of each executor. Supported file types: .jar, .tar, .tar.gz,
	// .tgz, and .zip.
	ArchiveUris []string `protobuf:"bytes,4,rep,name=archive_uris,json=archiveUris,proto3" json:"archive_uris,omitempty"`
	// Optional. Infrastructure specification for the execution.
	InfrastructureSpec *Task_InfrastructureSpec `protobuf:"bytes,6,opt,name=infrastructure_spec,json=infrastructureSpec,proto3" json:"infrastructure_spec,omitempty"`
	unknownFields      protoimpl.UnknownFields
	sizeCache          protoimpl.SizeCache
}

func (x *Task_SparkTaskConfig) Reset() {
	*x = Task_SparkTaskConfig{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[85]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Task_SparkTaskConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Task_SparkTaskConfig) ProtoMessage() {}

func (x *Task_SparkTaskConfig) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[85]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Task_SparkTaskConfig.ProtoReflect.Descriptor instead.
func (*Task_SparkTaskConfig) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{21, 3}
}

func (x *Task_SparkTaskConfig) GetDriver() isTask_SparkTaskConfig_Driver {
	if x != nil {
		return x.Driver
	}
	return nil
}

func (x *Task_SparkTaskConfig) GetMainJarFileUri() string {
	if x != nil {
		if x, ok := x.Driver.(*Task_SparkTaskConfig_MainJarFileUri); ok {
			return x.MainJarFileUri
		}
	}
	return ""
}

func (x *Task_SparkTaskConfig) GetMainClass() string {
	if x != nil {
		if x, ok := x.Driver.(*Task_SparkTaskConfig_MainClass); ok {
			return x.MainClass
		}
	}
	return ""
}

func (x *Task_SparkTaskConfig) GetPythonScriptFile() string {
	if x != nil {
		if x, ok := x.Driver.(*Task_SparkTaskConfig_PythonScriptFile); ok {
			return x.PythonScriptFile
		}
	}
	return ""
}

func (x *Task_SparkTaskConfig) GetSqlScriptFile() string {
	if x != nil {
		if x, ok := x.Driver.(*Task_SparkTaskConfig_SqlScriptFile); ok {
			return x.SqlScriptFile
		}
	}
	return ""
}

func (x *Task_SparkTaskConfig) GetSqlScript() string {
	if x != nil {
		if x, ok := x.Driver.(*Task_SparkTaskConfig_SqlScript); ok {
			return x.SqlScript
		}
	}
	return ""
}

func (x *Task_SparkTaskConfig) GetFileUris() []string {
	if x != nil {
		return x.FileUris
	}
	return nil
}

func (x *Task_SparkTaskConfig) GetArchiveUris() []string {
	if x != nil {
		return x.ArchiveUris
	}
	return nil
}

func (x *Task_SparkTaskConfig) GetInfrastructureSpec() *Task_InfrastructureSpec {
	if x != nil {
		return x.InfrastructureSpec
	}
	return nil
}

type isTask_SparkTaskConfig_Driver interface {
	isTask_SparkTaskConfig_Driver()
}

type Task_SparkTaskConfig_MainJarFileUri struct {
	// The Cloud Storage URI of the jar file that contains the main class.
	// The execution args are passed in as a sequence of named process
	// arguments (`--key=value`).
	MainJarFileUri string `protobuf:"bytes,100,opt,name=main_jar_file_uri,json=mainJarFileUri,proto3,oneof"`
}

type Task_SparkTaskConfig_MainClass struct {
	// The name of the driver's main class. The jar file that contains the
	// class must be in the default CLASSPATH or specified in
	// `jar_file_uris`.
	// The execution args are passed in as a sequence of named process
	// arguments (`--key=value`).
	MainClass string `protobuf:"bytes,101,opt,name=main_class,json=mainClass,proto3,oneof"`
}

type Task_SparkTaskConfig_PythonScriptFile struct {
	// The Gcloud Storage URI of the main Python file to use as the driver.
	// Must be a .py file. The execution args are passed in as a sequence of
	// named process arguments (`--key=value`).
	PythonScriptFile string `protobuf:"bytes,102,opt,name=python_script_file,json=pythonScriptFile,proto3,oneof"`
}

type Task_SparkTaskConfig_SqlScriptFile struct {
	// A reference to a query file. This can be the Cloud Storage URI of the
	// query file or it can the path to a SqlScript Content. The execution
	// args are used to declare a set of script variables
	// (`set key="value";`).
	SqlScriptFile string `protobuf:"bytes,104,opt,name=sql_script_file,json=sqlScriptFile,proto3,oneof"`
}

type Task_SparkTaskConfig_SqlScript struct {
	// The query text.
	// The execution args are used to declare a set of script variables
	// (`set key="value";`).
	SqlScript string `protobuf:"bytes,105,opt,name=sql_script,json=sqlScript,proto3,oneof"`
}

func (*Task_SparkTaskConfig_MainJarFileUri) isTask_SparkTaskConfig_Driver() {}

func (*Task_SparkTaskConfig_MainClass) isTask_SparkTaskConfig_Driver() {}

func (*Task_SparkTaskConfig_PythonScriptFile) isTask_SparkTaskConfig_Driver() {}

func (*Task_SparkTaskConfig_SqlScriptFile) isTask_SparkTaskConfig_Driver() {}

func (*Task_SparkTaskConfig_SqlScript) isTask_SparkTaskConfig_Driver() {}

// Config for running scheduled notebooks.
type Task_NotebookTaskConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Required. Path to input notebook. This can be the Cloud Storage URI of
	// the notebook file or the path to a Notebook Content. The execution args
	// are accessible as environment variables
	// (`TASK_key=value`).
	Notebook string `protobuf:"bytes,4,opt,name=notebook,proto3" json:"notebook,omitempty"`
	// Optional. Infrastructure specification for the execution.
	InfrastructureSpec *Task_InfrastructureSpec `protobuf:"bytes,3,opt,name=infrastructure_spec,json=infrastructureSpec,proto3" json:"infrastructure_spec,omitempty"`
	// Optional. Cloud Storage URIs of files to be placed in the working
	// directory of each executor.
	FileUris []string `protobuf:"bytes,5,rep,name=file_uris,json=fileUris,proto3" json:"file_uris,omitempty"`
	// Optional. Cloud Storage URIs of archives to be extracted into the working
	// directory of each executor. Supported file types: .jar, .tar, .tar.gz,
	// .tgz, and .zip.
	ArchiveUris   []string `protobuf:"bytes,6,rep,name=archive_uris,json=archiveUris,proto3" json:"archive_uris,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Task_NotebookTaskConfig) Reset() {
	*x = Task_NotebookTaskConfig{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[86]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Task_NotebookTaskConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Task_NotebookTaskConfig) ProtoMessage() {}

func (x *Task_NotebookTaskConfig) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[86]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Task_NotebookTaskConfig.ProtoReflect.Descriptor instead.
func (*Task_NotebookTaskConfig) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{21, 4}
}

func (x *Task_NotebookTaskConfig) GetNotebook() string {
	if x != nil {
		return x.Notebook
	}
	return ""
}

func (x *Task_NotebookTaskConfig) GetInfrastructureSpec() *Task_InfrastructureSpec {
	if x != nil {
		return x.InfrastructureSpec
	}
	return nil
}

func (x *Task_NotebookTaskConfig) GetFileUris() []string {
	if x != nil {
		return x.FileUris
	}
	return nil
}

func (x *Task_NotebookTaskConfig) GetArchiveUris() []string {
	if x != nil {
		return x.ArchiveUris
	}
	return nil
}

// Status of the task execution (e.g. Jobs).
type Task_ExecutionStatus struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Output only. Last update time of the status.
	UpdateTime *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=update_time,json=updateTime,proto3" json:"update_time,omitempty"`
	// Output only. latest job execution
	LatestJob     *Job `protobuf:"bytes,9,opt,name=latest_job,json=latestJob,proto3" json:"latest_job,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Task_ExecutionStatus) Reset() {
	*x = Task_ExecutionStatus{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[87]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Task_ExecutionStatus) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Task_ExecutionStatus) ProtoMessage() {}

func (x *Task_ExecutionStatus) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[87]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Task_ExecutionStatus.ProtoReflect.Descriptor instead.
func (*Task_ExecutionStatus) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{21, 5}
}

func (x *Task_ExecutionStatus) GetUpdateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.UpdateTime
	}
	return nil
}

func (x *Task_ExecutionStatus) GetLatestJob() *Job {
	if x != nil {
		return x.LatestJob
	}
	return nil
}

// Batch compute resources associated with the task.
type Task_InfrastructureSpec_BatchComputeResources struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. Total number of job executors.
	// Executor Count should be between 2 and 100. [Default=2]
	ExecutorsCount int32 `protobuf:"varint,1,opt,name=executors_count,json=executorsCount,proto3" json:"executors_count,omitempty"`
	// Optional. Max configurable executors.
	// If max_executors_count > executors_count, then auto-scaling is enabled.
	// Max Executor Count should be between 2 and 1000. [Default=1000]
	MaxExecutorsCount int32 `protobuf:"varint,2,opt,name=max_executors_count,json=maxExecutorsCount,proto3" json:"max_executors_count,omitempty"`
	unknownFields     protoimpl.UnknownFields
	sizeCache         protoimpl.SizeCache
}

func (x *Task_InfrastructureSpec_BatchComputeResources) Reset() {
	*x = Task_InfrastructureSpec_BatchComputeResources{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[89]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Task_InfrastructureSpec_BatchComputeResources) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Task_InfrastructureSpec_BatchComputeResources) ProtoMessage() {}

func (x *Task_InfrastructureSpec_BatchComputeResources) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[89]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Task_InfrastructureSpec_BatchComputeResources.ProtoReflect.Descriptor instead.
func (*Task_InfrastructureSpec_BatchComputeResources) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{21, 0, 0}
}

func (x *Task_InfrastructureSpec_BatchComputeResources) GetExecutorsCount() int32 {
	if x != nil {
		return x.ExecutorsCount
	}
	return 0
}

func (x *Task_InfrastructureSpec_BatchComputeResources) GetMaxExecutorsCount() int32 {
	if x != nil {
		return x.MaxExecutorsCount
	}
	return 0
}

// Container Image Runtime Configuration used with Batch execution.
type Task_InfrastructureSpec_ContainerImageRuntime struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. Container image to use.
	Image string `protobuf:"bytes,1,opt,name=image,proto3" json:"image,omitempty"`
	// Optional. A list of Java JARS to add to the classpath.
	// Valid input includes Cloud Storage URIs to Jar binaries.
	// For example, gs://bucket-name/my/path/to/file.jar
	JavaJars []string `protobuf:"bytes,2,rep,name=java_jars,json=javaJars,proto3" json:"java_jars,omitempty"`
	// Optional. A list of python packages to be installed.
	// Valid formats include Cloud Storage URI to a PIP installable library.
	// For example, gs://bucket-name/my/path/to/lib.tar.gz
	PythonPackages []string `protobuf:"bytes,3,rep,name=python_packages,json=pythonPackages,proto3" json:"python_packages,omitempty"`
	// Optional. Override to common configuration of open source components
	// installed on the Dataproc cluster. The properties to set on daemon
	// config files. Property keys are specified in `prefix:property` format,
	// for example `core:hadoop.tmp.dir`. For more information, see [Cluster
	// properties](https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
	Properties    map[string]string `protobuf:"bytes,4,rep,name=properties,proto3" json:"properties,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Task_InfrastructureSpec_ContainerImageRuntime) Reset() {
	*x = Task_InfrastructureSpec_ContainerImageRuntime{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[90]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Task_InfrastructureSpec_ContainerImageRuntime) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Task_InfrastructureSpec_ContainerImageRuntime) ProtoMessage() {}

func (x *Task_InfrastructureSpec_ContainerImageRuntime) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[90]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Task_InfrastructureSpec_ContainerImageRuntime.ProtoReflect.Descriptor instead.
func (*Task_InfrastructureSpec_ContainerImageRuntime) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{21, 0, 1}
}

func (x *Task_InfrastructureSpec_ContainerImageRuntime) GetImage() string {
	if x != nil {
		return x.Image
	}
	return ""
}

func (x *Task_InfrastructureSpec_ContainerImageRuntime) GetJavaJars() []string {
	if x != nil {
		return x.JavaJars
	}
	return nil
}

func (x *Task_InfrastructureSpec_ContainerImageRuntime) GetPythonPackages() []string {
	if x != nil {
		return x.PythonPackages
	}
	return nil
}

func (x *Task_InfrastructureSpec_ContainerImageRuntime) GetProperties() map[string]string {
	if x != nil {
		return x.Properties
	}
	return nil
}

// Cloud VPC Network used to run the infrastructure.
type Task_InfrastructureSpec_VpcNetwork struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The Cloud VPC network identifier.
	//
	// Types that are valid to be assigned to NetworkName:
	//
	//	*Task_InfrastructureSpec_VpcNetwork_Network
	//	*Task_InfrastructureSpec_VpcNetwork_SubNetwork
	NetworkName isTask_InfrastructureSpec_VpcNetwork_NetworkName `protobuf_oneof:"network_name"`
	// Optional. List of network tags to apply to the job.
	NetworkTags   []string `protobuf:"bytes,3,rep,name=network_tags,json=networkTags,proto3" json:"network_tags,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Task_InfrastructureSpec_VpcNetwork) Reset() {
	*x = Task_InfrastructureSpec_VpcNetwork{}
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[91]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Task_InfrastructureSpec_VpcNetwork) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Task_InfrastructureSpec_VpcNetwork) ProtoMessage() {}

func (x *Task_InfrastructureSpec_VpcNetwork) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_dataplex_v1_data_proto_msgTypes[91]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Task_InfrastructureSpec_VpcNetwork.ProtoReflect.Descriptor instead.
func (*Task_InfrastructureSpec_VpcNetwork) Descriptor() ([]byte, []int) {
	return file_cloud_dataplex_v1_data_proto_rawDescGZIP(), []int{21, 0, 2}
}

func (x *Task_InfrastructureSpec_VpcNetwork) GetNetworkName() isTask_InfrastructureSpec_VpcNetwork_NetworkName {
	if x != nil {
		return x.NetworkName
	}
	return nil
}

func (x *Task_InfrastructureSpec_VpcNetwork) GetNetwork() string {
	if x != nil {
		if x, ok := x.NetworkName.(*Task_InfrastructureSpec_VpcNetwork_Network); ok {
			return x.Network
		}
	}
	return ""
}

func (x *Task_InfrastructureSpec_VpcNetwork) GetSubNetwork() string {
	if x != nil {
		if x, ok := x.NetworkName.(*Task_InfrastructureSpec_VpcNetwork_SubNetwork); ok {
			return x.SubNetwork
		}
	}
	return ""
}

func (x *Task_InfrastructureSpec_VpcNetwork) GetNetworkTags() []string {
	if x != nil {
		return x.NetworkTags
	}
	return nil
}

type isTask_InfrastructureSpec_VpcNetwork_NetworkName interface {
	isTask_InfrastructureSpec_VpcNetwork_NetworkName()
}

type Task_InfrastructureSpec_VpcNetwork_Network struct {
	// Optional. The Cloud VPC network in which the job is run. By default,
	// the Cloud VPC network named Default within the project is used.
	Network string `protobuf:"bytes,1,opt,name=network,proto3,oneof"`
}

type Task_InfrastructureSpec_VpcNetwork_SubNetwork struct {
	// Optional. The Cloud VPC sub-network in which the job is run.
	SubNetwork string `protobuf:"bytes,2,opt,name=sub_network,json=subNetwork,proto3,oneof"`
}

func (*Task_InfrastructureSpec_VpcNetwork_Network) isTask_InfrastructureSpec_VpcNetwork_NetworkName() {
}

func (*Task_InfrastructureSpec_VpcNetwork_SubNetwork) isTask_InfrastructureSpec_VpcNetwork_NetworkName() {
}

var File_cloud_dataplex_v1_data_proto protoreflect.FileDescriptor

const file_cloud_dataplex_v1_data_proto_rawDesc = "" +
	"\n" +
	"\x1ccloud/dataplex/v1/data.proto\x12\x1fgoogle.events.cloud.dataplex.v1\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\"\xa9\b\n" +
	"\x04Lake\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12!\n" +
	"\fdisplay_name\x18\x02 \x01(\tR\vdisplayName\x12\x10\n" +
	"\x03uid\x18\x03 \x01(\tR\x03uid\x12;\n" +
	"\vcreate_time\x18\x04 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"createTime\x12;\n" +
	"\vupdate_time\x18\x05 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"updateTime\x12I\n" +
	"\x06labels\x18\x06 \x03(\v21.google.events.cloud.dataplex.v1.Lake.LabelsEntryR\x06labels\x12 \n" +
	"\vdescription\x18\a \x01(\tR\vdescription\x12<\n" +
	"\x05state\x18\b \x01(\x0e2&.google.events.cloud.dataplex.v1.StateR\x05state\x12'\n" +
	"\x0fservice_account\x18\t \x01(\tR\x0eserviceAccount\x12M\n" +
	"\tmetastore\x18f \x01(\v2/.google.events.cloud.dataplex.v1.Lake.MetastoreR\tmetastore\x12O\n" +
	"\fasset_status\x18g \x01(\v2,.google.events.cloud.dataplex.v1.AssetStatusR\vassetStatus\x12`\n" +
	"\x10metastore_status\x18h \x01(\v25.google.events.cloud.dataplex.v1.Lake.MetastoreStatusR\x0fmetastoreStatus\x1a%\n" +
	"\tMetastore\x12\x18\n" +
	"\aservice\x18\x01 \x01(\tR\aservice\x1a\xa5\x02\n" +
	"\x0fMetastoreStatus\x12Q\n" +
	"\x05state\x18\x01 \x01(\x0e2;.google.events.cloud.dataplex.v1.Lake.MetastoreStatus.StateR\x05state\x12\x18\n" +
	"\amessage\x18\x02 \x01(\tR\amessage\x12;\n" +
	"\vupdate_time\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"updateTime\x12\x1a\n" +
	"\bendpoint\x18\x04 \x01(\tR\bendpoint\"L\n" +
	"\x05State\x12\x15\n" +
	"\x11STATE_UNSPECIFIED\x10\x00\x12\b\n" +
	"\x04NONE\x10\x01\x12\t\n" +
	"\x05READY\x10\x02\x12\f\n" +
	"\bUPDATING\x10\x03\x12\t\n" +
	"\x05ERROR\x10\x04\x1a9\n" +
	"\vLabelsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\xb6\x01\n" +
	"\vAssetStatus\x12;\n" +
	"\vupdate_time\x18\x01 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"updateTime\x12#\n" +
	"\ractive_assets\x18\x02 \x01(\x05R\factiveAssets\x12E\n" +
	"\x1fsecurity_policy_applying_assets\x18\x03 \x01(\x05R\x1csecurityPolicyApplyingAssets\"\xe5\f\n" +
	"\x04Zone\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12!\n" +
	"\fdisplay_name\x18\x02 \x01(\tR\vdisplayName\x12\x10\n" +
	"\x03uid\x18\x03 \x01(\tR\x03uid\x12;\n" +
	"\vcreate_time\x18\x04 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"createTime\x12;\n" +
	"\vupdate_time\x18\x05 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"updateTime\x12I\n" +
	"\x06labels\x18\x06 \x03(\v21.google.events.cloud.dataplex.v1.Zone.LabelsEntryR\x06labels\x12 \n" +
	"\vdescription\x18\a \x01(\tR\vdescription\x12<\n" +
	"\x05state\x18\b \x01(\x0e2&.google.events.cloud.dataplex.v1.StateR\x05state\x12>\n" +
	"\x04type\x18\t \x01(\x0e2*.google.events.cloud.dataplex.v1.Zone.TypeR\x04type\x12Z\n" +
	"\x0ediscovery_spec\x18g \x01(\v23.google.events.cloud.dataplex.v1.Zone.DiscoverySpecR\rdiscoverySpec\x12W\n" +
	"\rresource_spec\x18h \x01(\v22.google.events.cloud.dataplex.v1.Zone.ResourceSpecR\fresourceSpec\x12O\n" +
	"\fasset_status\x18i \x01(\v2,.google.events.cloud.dataplex.v1.AssetStatusR\vassetStatus\x1a\xc8\x01\n" +
	"\fResourceSpec\x12d\n" +
	"\rlocation_type\x18\x01 \x01(\x0e2?.google.events.cloud.dataplex.v1.Zone.ResourceSpec.LocationTypeR\flocationType\"R\n" +
	"\fLocationType\x12\x1d\n" +
	"\x19LOCATION_TYPE_UNSPECIFIED\x10\x00\x12\x11\n" +
	"\rSINGLE_REGION\x10\x01\x12\x10\n" +
	"\fMULTI_REGION\x10\x02\x1a\xee\x04\n" +
	"\rDiscoverySpec\x12\x18\n" +
	"\aenabled\x18\x01 \x01(\bR\aenabled\x12)\n" +
	"\x10include_patterns\x18\x02 \x03(\tR\x0fincludePatterns\x12)\n" +
	"\x10exclude_patterns\x18\x03 \x03(\tR\x0fexcludePatterns\x12_\n" +
	"\vcsv_options\x18\x04 \x01(\v2>.google.events.cloud.dataplex.v1.Zone.DiscoverySpec.CsvOptionsR\n" +
	"csvOptions\x12b\n" +
	"\fjson_options\x18\x05 \x01(\v2?.google.events.cloud.dataplex.v1.Zone.DiscoverySpec.JsonOptionsR\vjsonOptions\x12\x1c\n" +
	"\bschedule\x18\n" +
	" \x01(\tH\x00R\bschedule\x1a\x9d\x01\n" +
	"\n" +
	"CsvOptions\x12\x1f\n" +
	"\vheader_rows\x18\x01 \x01(\x05R\n" +
	"headerRows\x12\x1c\n" +
	"\tdelimiter\x18\x02 \x01(\tR\tdelimiter\x12\x1a\n" +
	"\bencoding\x18\x03 \x01(\tR\bencoding\x124\n" +
	"\x16disable_type_inference\x18\x04 \x01(\bR\x14disableTypeInference\x1a_\n" +
	"\vJsonOptions\x12\x1a\n" +
	"\bencoding\x18\x01 \x01(\tR\bencoding\x124\n" +
	"\x16disable_type_inference\x18\x02 \x01(\bR\x14disableTypeInferenceB\t\n" +
	"\atrigger\x1a9\n" +
	"\vLabelsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"2\n" +
	"\x04Type\x12\x14\n" +
	"\x10TYPE_UNSPECIFIED\x10\x00\x12\a\n" +
	"\x03RAW\x10\x01\x12\v\n" +
	"\aCURATED\x10\x02\"\x80\x18\n" +
	"\x05Asset\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12!\n" +
	"\fdisplay_name\x18\x02 \x01(\tR\vdisplayName\x12\x10\n" +
	"\x03uid\x18\x03 \x01(\tR\x03uid\x12;\n" +
	"\vcreate_time\x18\x04 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"createTime\x12;\n" +
	"\vupdate_time\x18\x05 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"updateTime\x12J\n" +
	"\x06labels\x18\x06 \x03(\v22.google.events.cloud.dataplex.v1.Asset.LabelsEntryR\x06labels\x12 \n" +
	"\vdescription\x18\a \x01(\tR\vdescription\x12<\n" +
	"\x05state\x18\b \x01(\x0e2&.google.events.cloud.dataplex.v1.StateR\x05state\x12X\n" +
	"\rresource_spec\x18d \x01(\v23.google.events.cloud.dataplex.v1.Asset.ResourceSpecR\fresourceSpec\x12^\n" +
	"\x0fresource_status\x18e \x01(\v25.google.events.cloud.dataplex.v1.Asset.ResourceStatusR\x0eresourceStatus\x12^\n" +
	"\x0fsecurity_status\x18g \x01(\v25.google.events.cloud.dataplex.v1.Asset.SecurityStatusR\x0esecurityStatus\x12[\n" +
	"\x0ediscovery_spec\x18j \x01(\v24.google.events.cloud.dataplex.v1.Asset.DiscoverySpecR\rdiscoverySpec\x12a\n" +
	"\x10discovery_status\x18k \x01(\v26.google.events.cloud.dataplex.v1.Asset.DiscoveryStatusR\x0fdiscoveryStatus\x1a\xfe\x01\n" +
	"\x0eSecurityStatus\x12Q\n" +
	"\x05state\x18\x01 \x01(\x0e2;.google.events.cloud.dataplex.v1.Asset.SecurityStatus.StateR\x05state\x12\x18\n" +
	"\amessage\x18\x02 \x01(\tR\amessage\x12;\n" +
	"\vupdate_time\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"updateTime\"B\n" +
	"\x05State\x12\x15\n" +
	"\x11STATE_UNSPECIFIED\x10\x00\x12\t\n" +
	"\x05READY\x10\x01\x12\f\n" +
	"\bAPPLYING\x10\x02\x12\t\n" +
	"\x05ERROR\x10\x03\x1a\xf0\x04\n" +
	"\rDiscoverySpec\x12\x18\n" +
	"\aenabled\x18\x01 \x01(\bR\aenabled\x12)\n" +
	"\x10include_patterns\x18\x02 \x03(\tR\x0fincludePatterns\x12)\n" +
	"\x10exclude_patterns\x18\x03 \x03(\tR\x0fexcludePatterns\x12`\n" +
	"\vcsv_options\x18\x04 \x01(\v2?.google.events.cloud.dataplex.v1.Asset.DiscoverySpec.CsvOptionsR\n" +
	"csvOptions\x12c\n" +
	"\fjson_options\x18\x05 \x01(\v2@.google.events.cloud.dataplex.v1.Asset.DiscoverySpec.JsonOptionsR\vjsonOptions\x12\x1c\n" +
	"\bschedule\x18\n" +
	" \x01(\tH\x00R\bschedule\x1a\x9d\x01\n" +
	"\n" +
	"CsvOptions\x12\x1f\n" +
	"\vheader_rows\x18\x01 \x01(\x05R\n" +
	"headerRows\x12\x1c\n" +
	"\tdelimiter\x18\x02 \x01(\tR\tdelimiter\x12\x1a\n" +
	"\bencoding\x18\x03 \x01(\tR\bencoding\x124\n" +
	"\x16disable_type_inference\x18\x04 \x01(\bR\x14disableTypeInference\x1a_\n" +
	"\vJsonOptions\x12\x1a\n" +
	"\bencoding\x18\x01 \x01(\tR\bencoding\x124\n" +
	"\x16disable_type_inference\x18\x02 \x01(\bR\x14disableTypeInferenceB\t\n" +
	"\atrigger\x1a\xe6\x02\n" +
	"\fResourceSpec\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12L\n" +
	"\x04type\x18\x02 \x01(\x0e28.google.events.cloud.dataplex.v1.Asset.ResourceSpec.TypeR\x04type\x12h\n" +
	"\x10read_access_mode\x18\x05 \x01(\x0e2>.google.events.cloud.dataplex.v1.Asset.ResourceSpec.AccessModeR\x0ereadAccessMode\"F\n" +
	"\x04Type\x12\x14\n" +
	"\x10TYPE_UNSPECIFIED\x10\x00\x12\x12\n" +
	"\x0eSTORAGE_BUCKET\x10\x01\x12\x14\n" +
	"\x10BIGQUERY_DATASET\x10\x02\"B\n" +
	"\n" +
	"AccessMode\x12\x1b\n" +
	"\x17ACCESS_MODE_UNSPECIFIED\x10\x00\x12\n" +
	"\n" +
	"\x06DIRECT\x10\x01\x12\v\n" +
	"\aMANAGED\x10\x02\x1a\xa8\x02\n" +
	"\x0eResourceStatus\x12Q\n" +
	"\x05state\x18\x01 \x01(\x0e2;.google.events.cloud.dataplex.v1.Asset.ResourceStatus.StateR\x05state\x12\x18\n" +
	"\amessage\x18\x02 \x01(\tR\amessage\x12;\n" +
	"\vupdate_time\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"updateTime\x126\n" +
	"\x17managed_access_identity\x18\x04 \x01(\tR\x15managedAccessIdentity\"4\n" +
	"\x05State\x12\x15\n" +
	"\x11STATE_UNSPECIFIED\x10\x00\x12\t\n" +
	"\x05READY\x10\x01\x12\t\n" +
	"\x05ERROR\x10\x02\x1a\xea\x04\n" +
	"\x0fDiscoveryStatus\x12R\n" +
	"\x05state\x18\x01 \x01(\x0e2<.google.events.cloud.dataplex.v1.Asset.DiscoveryStatus.StateR\x05state\x12\x18\n" +
	"\amessage\x18\x02 \x01(\tR\amessage\x12;\n" +
	"\vupdate_time\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"updateTime\x12>\n" +
	"\rlast_run_time\x18\x04 \x01(\v2\x1a.google.protobuf.TimestampR\vlastRunTime\x12R\n" +
	"\x05stats\x18\x06 \x01(\v2<.google.events.cloud.dataplex.v1.Asset.DiscoveryStatus.StatsR\x05stats\x12E\n" +
	"\x11last_run_duration\x18\a \x01(\v2\x19.google.protobuf.DurationR\x0flastRunDuration\x1aw\n" +
	"\x05Stats\x12\x1d\n" +
	"\n" +
	"data_items\x18\x01 \x01(\x03R\tdataItems\x12\x1b\n" +
	"\tdata_size\x18\x02 \x01(\x03R\bdataSize\x12\x16\n" +
	"\x06tables\x18\x03 \x01(\x03R\x06tables\x12\x1a\n" +
	"\bfilesets\x18\x04 \x01(\x03R\bfilesets\"X\n" +
	"\x05State\x12\x15\n" +
	"\x11STATE_UNSPECIFIED\x10\x00\x12\r\n" +
	"\tSCHEDULED\x10\x01\x12\x0f\n" +
	"\vIN_PROGRESS\x10\x02\x12\n" +
	"\n" +
	"\x06PAUSED\x10\x03\x12\f\n" +
	"\bDISABLED\x10\x05\x1a9\n" +
	"\vLabelsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\xff\r\n" +
	"\vEnvironment\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12!\n" +
	"\fdisplay_name\x18\x02 \x01(\tR\vdisplayName\x12\x10\n" +
	"\x03uid\x18\x03 \x01(\tR\x03uid\x12;\n" +
	"\vcreate_time\x18\x04 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"createTime\x12;\n" +
	"\vupdate_time\x18\x05 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"updateTime\x12P\n" +
	"\x06labels\x18\x06 \x03(\v28.google.events.cloud.dataplex.v1.Environment.LabelsEntryR\x06labels\x12 \n" +
	"\vdescription\x18\a \x01(\tR\vdescription\x12<\n" +
	"\x05state\x18\b \x01(\x0e2&.google.events.cloud.dataplex.v1.StateR\x05state\x12p\n" +
	"\x13infrastructure_spec\x18d \x01(\v2?.google.events.cloud.dataplex.v1.Environment.InfrastructureSpecR\x12infrastructureSpec\x12[\n" +
	"\fsession_spec\x18e \x01(\v28.google.events.cloud.dataplex.v1.Environment.SessionSpecR\vsessionSpec\x12a\n" +
	"\x0esession_status\x18f \x01(\v2:.google.events.cloud.dataplex.v1.Environment.SessionStatusR\rsessionStatus\x12U\n" +
	"\tendpoints\x18\xc8\x01 \x01(\v26.google.events.cloud.dataplex.v1.Environment.EndpointsR\tendpoints\x1a\xc9\x05\n" +
	"\x12InfrastructureSpec\x12l\n" +
	"\acompute\x182 \x01(\v2P.google.events.cloud.dataplex.v1.Environment.InfrastructureSpec.ComputeResourcesH\x00R\acompute\x12k\n" +
	"\bos_image\x18d \x01(\v2N.google.events.cloud.dataplex.v1.Environment.InfrastructureSpec.OsImageRuntimeH\x01R\aosImage\x1ay\n" +
	"\x10ComputeResources\x12 \n" +
	"\fdisk_size_gb\x18\x01 \x01(\x05R\n" +
	"diskSizeGb\x12\x1d\n" +
	"\n" +
	"node_count\x18\x02 \x01(\x05R\tnodeCount\x12$\n" +
	"\x0emax_node_count\x18\x03 \x01(\x05R\fmaxNodeCount\x1a\xc4\x02\n" +
	"\x0eOsImageRuntime\x12#\n" +
	"\rimage_version\x18\x01 \x01(\tR\fimageVersion\x12%\n" +
	"\x0ejava_libraries\x18\x02 \x03(\tR\rjavaLibraries\x12'\n" +
	"\x0fpython_packages\x18\x03 \x03(\tR\x0epythonPackages\x12~\n" +
	"\n" +
	"properties\x18\x04 \x03(\v2^.google.events.cloud.dataplex.v1.Environment.InfrastructureSpec.OsImageRuntime.PropertiesEntryR\n" +
	"properties\x1a=\n" +
	"\x0fPropertiesEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01B\v\n" +
	"\tresourcesB\t\n" +
	"\aruntime\x1a\x84\x01\n" +
	"\vSessionSpec\x12E\n" +
	"\x11max_idle_duration\x18\x01 \x01(\v2\x19.google.protobuf.DurationR\x0fmaxIdleDuration\x12.\n" +
	"\x13enable_fast_startup\x18\x02 \x01(\bR\x11enableFastStartup\x1a'\n" +
	"\rSessionStatus\x12\x16\n" +
	"\x06active\x18\x01 \x01(\bR\x06active\x1a;\n" +
	"\tEndpoints\x12\x1c\n" +
	"\tnotebooks\x18\x01 \x01(\tR\tnotebooks\x12\x10\n" +
	"\x03sql\x18\x02 \x01(\tR\x03sql\x1a9\n" +
	"\vLabelsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\xe0\x01\n" +
	"\aTrigger\x12P\n" +
	"\ton_demand\x18d \x01(\v21.google.events.cloud.dataplex.v1.Trigger.OnDemandH\x00R\bonDemand\x12O\n" +
	"\bschedule\x18e \x01(\v21.google.events.cloud.dataplex.v1.Trigger.ScheduleH\x00R\bschedule\x1a\n" +
	"\n" +
	"\bOnDemand\x1a\x1e\n" +
	"\bSchedule\x12\x12\n" +
	"\x04cron\x18\x01 \x01(\tR\x04cronB\x06\n" +
	"\x04mode\"0\n" +
	"\n" +
	"DataSource\x12\x18\n" +
	"\x06entity\x18d \x01(\tH\x00R\x06entityB\b\n" +
	"\x06source\"\xdb\x01\n" +
	"\vScannedData\x12l\n" +
	"\x11incremental_field\x18\x01 \x01(\v2=.google.events.cloud.dataplex.v1.ScannedData.IncrementalFieldH\x00R\x10incrementalField\x1aP\n" +
	"\x10IncrementalField\x12\x14\n" +
	"\x05field\x18\x01 \x01(\tR\x05field\x12\x14\n" +
	"\x05start\x18\x02 \x01(\tR\x05start\x12\x10\n" +
	"\x03end\x18\x03 \x01(\tR\x03endB\f\n" +
	"\n" +
	"data_range\"\x11\n" +
	"\x0fDataProfileSpec\"\xd4\f\n" +
	"\x11DataProfileResult\x12\x1b\n" +
	"\trow_count\x18\x03 \x01(\x03R\browCount\x12T\n" +
	"\aprofile\x18\x04 \x01(\v2:.google.events.cloud.dataplex.v1.DataProfileResult.ProfileR\aprofile\x12O\n" +
	"\fscanned_data\x18\x05 \x01(\v2,.google.events.cloud.dataplex.v1.ScannedDataR\vscannedData\x1a\xfa\n" +
	"\n" +
	"\aProfile\x12X\n" +
	"\x06fields\x18\x02 \x03(\v2@.google.events.cloud.dataplex.v1.DataProfileResult.Profile.FieldR\x06fields\x1a\x94\n" +
	"\n" +
	"\x05Field\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x12\n" +
	"\x04type\x18\x02 \x01(\tR\x04type\x12\x12\n" +
	"\x04mode\x18\x03 \x01(\tR\x04mode\x12f\n" +
	"\aprofile\x18\x04 \x01(\v2L.google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.ProfileInfoR\aprofile\x1a\xe6\b\n" +
	"\vProfileInfo\x12\x1d\n" +
	"\n" +
	"null_ratio\x18\x02 \x01(\x01R\tnullRatio\x12%\n" +
	"\x0edistinct_ratio\x18\x03 \x01(\x01R\rdistinctRatio\x12x\n" +
	"\ftop_n_values\x18\x04 \x03(\v2V.google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.ProfileInfo.TopNValueR\n" +
	"topNValues\x12\x85\x01\n" +
	"\x0estring_profile\x18e \x01(\v2\\.google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.ProfileInfo.StringFieldInfoH\x00R\rstringProfile\x12\x88\x01\n" +
	"\x0finteger_profile\x18f \x01(\v2].google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.ProfileInfo.IntegerFieldInfoH\x00R\x0eintegerProfile\x12\x85\x01\n" +
	"\x0edouble_profile\x18g \x01(\v2\\.google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.ProfileInfo.DoubleFieldInfoH\x00R\rdoubleProfile\x1av\n" +
	"\x0fStringFieldInfo\x12\x1d\n" +
	"\n" +
	"min_length\x18\x01 \x01(\x03R\tminLength\x12\x1d\n" +
	"\n" +
	"max_length\x18\x02 \x01(\x03R\tmaxLength\x12%\n" +
	"\x0eaverage_length\x18\x03 \x01(\x01R\raverageLength\x1a\x9d\x01\n" +
	"\x10IntegerFieldInfo\x12\x18\n" +
	"\aaverage\x18\x01 \x01(\x01R\aaverage\x12-\n" +
	"\x12standard_deviation\x18\x03 \x01(\x01R\x11standardDeviation\x12\x10\n" +
	"\x03min\x18\x04 \x01(\x03R\x03min\x12\x1c\n" +
	"\tquartiles\x18\x06 \x03(\x03R\tquartiles\x12\x10\n" +
	"\x03max\x18\x05 \x01(\x03R\x03max\x1a\x9c\x01\n" +
	"\x0fDoubleFieldInfo\x12\x18\n" +
	"\aaverage\x18\x01 \x01(\x01R\aaverage\x12-\n" +
	"\x12standard_deviation\x18\x03 \x01(\x01R\x11standardDeviation\x12\x10\n" +
	"\x03min\x18\x04 \x01(\x01R\x03min\x12\x1c\n" +
	"\tquartiles\x18\x06 \x03(\x01R\tquartiles\x12\x10\n" +
	"\x03max\x18\x05 \x01(\x01R\x03max\x1a7\n" +
	"\tTopNValue\x12\x14\n" +
	"\x05value\x18\x01 \x01(\tR\x05value\x12\x14\n" +
	"\x05count\x18\x02 \x01(\x03R\x05countB\f\n" +
	"\n" +
	"field_info\"Y\n" +
	"\x0fDataQualitySpec\x12F\n" +
	"\x05rules\x18\x01 \x03(\v20.google.events.cloud.dataplex.v1.DataQualityRuleR\x05rules\"\xc4\x02\n" +
	"\x11DataQualityResult\x12\x16\n" +
	"\x06passed\x18\x05 \x01(\bR\x06passed\x12[\n" +
	"\n" +
	"dimensions\x18\x02 \x03(\v2;.google.events.cloud.dataplex.v1.DataQualityDimensionResultR\n" +
	"dimensions\x12L\n" +
	"\x05rules\x18\x03 \x03(\v26.google.events.cloud.dataplex.v1.DataQualityRuleResultR\x05rules\x12\x1b\n" +
	"\trow_count\x18\x04 \x01(\x03R\browCount\x12O\n" +
	"\fscanned_data\x18\a \x01(\v2,.google.events.cloud.dataplex.v1.ScannedDataR\vscannedData\"\xad\x02\n" +
	"\x15DataQualityRuleResult\x12D\n" +
	"\x04rule\x18\x01 \x01(\v20.google.events.cloud.dataplex.v1.DataQualityRuleR\x04rule\x12\x16\n" +
	"\x06passed\x18\a \x01(\bR\x06passed\x12'\n" +
	"\x0fevaluated_count\x18\t \x01(\x03R\x0eevaluatedCount\x12!\n" +
	"\fpassed_count\x18\b \x01(\x03R\vpassedCount\x12\x1d\n" +
	"\n" +
	"null_count\x18\x05 \x01(\x03R\tnullCount\x12\x1d\n" +
	"\n" +
	"pass_ratio\x18\x06 \x01(\x01R\tpassRatio\x12,\n" +
	"\x12failing_rows_query\x18\n" +
	" \x01(\tR\x10failingRowsQuery\"4\n" +
	"\x1aDataQualityDimensionResult\x12\x16\n" +
	"\x06passed\x18\x03 \x01(\bR\x06passed\"\xb4\x0f\n" +
	"\x0fDataQualityRule\x12p\n" +
	"\x11range_expectation\x18\x01 \x01(\v2A.google.events.cloud.dataplex.v1.DataQualityRule.RangeExpectationH\x00R\x10rangeExpectation\x12w\n" +
	"\x14non_null_expectation\x18\x02 \x01(\v2C.google.events.cloud.dataplex.v1.DataQualityRule.NonNullExpectationH\x00R\x12nonNullExpectation\x12j\n" +
	"\x0fset_expectation\x18\x03 \x01(\v2?.google.events.cloud.dataplex.v1.DataQualityRule.SetExpectationH\x00R\x0esetExpectation\x12p\n" +
	"\x11regex_expectation\x18\x04 \x01(\v2A.google.events.cloud.dataplex.v1.DataQualityRule.RegexExpectationH\x00R\x10regexExpectation\x12\x7f\n" +
	"\x16uniqueness_expectation\x18d \x01(\v2F.google.events.cloud.dataplex.v1.DataQualityRule.UniquenessExpectationH\x00R\x15uniquenessExpectation\x12\x8c\x01\n" +
	"\x1bstatistic_range_expectation\x18e \x01(\v2J.google.events.cloud.dataplex.v1.DataQualityRule.StatisticRangeExpectationH\x00R\x19statisticRangeExpectation\x12\x87\x01\n" +
	"\x19row_condition_expectation\x18\xc8\x01 \x01(\v2H.google.events.cloud.dataplex.v1.DataQualityRule.RowConditionExpectationH\x00R\x17rowConditionExpectation\x12\x8d\x01\n" +
	"\x1btable_condition_expectation\x18\xc9\x01 \x01(\v2J.google.events.cloud.dataplex.v1.DataQualityRule.TableConditionExpectationH\x00R\x19tableConditionExpectation\x12\x17\n" +
	"\x06column\x18\xf4\x03 \x01(\tR\x06column\x12 \n" +
	"\vignore_null\x18\xf5\x03 \x01(\bR\n" +
	"ignoreNull\x12\x1d\n" +
	"\tdimension\x18\xf6\x03 \x01(\tR\tdimension\x12\x1d\n" +
	"\tthreshold\x18\xf7\x03 \x01(\x01R\tthreshold\x1a\xa8\x01\n" +
	"\x10RangeExpectation\x12\x1b\n" +
	"\tmin_value\x18\x01 \x01(\tR\bminValue\x12\x1b\n" +
	"\tmax_value\x18\x02 \x01(\tR\bmaxValue\x12,\n" +
	"\x12strict_min_enabled\x18\x03 \x01(\bR\x10strictMinEnabled\x12,\n" +
	"\x12strict_max_enabled\x18\x04 \x01(\bR\x10strictMaxEnabled\x1a\x14\n" +
	"\x12NonNullExpectation\x1a(\n" +
	"\x0eSetExpectation\x12\x16\n" +
	"\x06values\x18\x01 \x03(\tR\x06values\x1a(\n" +
	"\x10RegexExpectation\x12\x14\n" +
	"\x05regex\x18\x01 \x01(\tR\x05regex\x1a\x17\n" +
	"\x15UniquenessExpectation\x1a\xf3\x02\n" +
	"\x19StatisticRangeExpectation\x12x\n" +
	"\tstatistic\x18\x01 \x01(\x0e2Z.google.events.cloud.dataplex.v1.DataQualityRule.StatisticRangeExpectation.ColumnStatisticR\tstatistic\x12\x1b\n" +
	"\tmin_value\x18\x02 \x01(\tR\bminValue\x12\x1b\n" +
	"\tmax_value\x18\x03 \x01(\tR\bmaxValue\x12,\n" +
	"\x12strict_min_enabled\x18\x04 \x01(\bR\x10strictMinEnabled\x12,\n" +
	"\x12strict_max_enabled\x18\x05 \x01(\bR\x10strictMaxEnabled\"F\n" +
	"\x0fColumnStatistic\x12\x17\n" +
	"\x13STATISTIC_UNDEFINED\x10\x00\x12\b\n" +
	"\x04MEAN\x10\x01\x12\a\n" +
	"\x03MIN\x10\x02\x12\a\n" +
	"\x03MAX\x10\x03\x1a@\n" +
	"\x17RowConditionExpectation\x12%\n" +
	"\x0esql_expression\x18\x01 \x01(\tR\rsqlExpression\x1aB\n" +
	"\x19TableConditionExpectation\x12%\n" +
	"\x0esql_expression\x18\x01 \x01(\tR\rsqlExpressionB\v\n" +
	"\trule_type\"`\n" +
	"\x12ResourceAccessSpec\x12\x18\n" +
	"\areaders\x18\x01 \x03(\tR\areaders\x12\x18\n" +
	"\awriters\x18\x02 \x03(\tR\awriters\x12\x16\n" +
	"\x06owners\x18\x03 \x03(\tR\x06owners\"*\n" +
	"\x0eDataAccessSpec\x12\x18\n" +
	"\areaders\x18\x01 \x03(\tR\areaders\"\xbe\x03\n" +
	"\fDataTaxonomy\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x10\n" +
	"\x03uid\x18\x02 \x01(\tR\x03uid\x12;\n" +
	"\vcreate_time\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"createTime\x12;\n" +
	"\vupdate_time\x18\x04 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"updateTime\x12 \n" +
	"\vdescription\x18\x05 \x01(\tR\vdescription\x12!\n" +
	"\fdisplay_name\x18\x06 \x01(\tR\vdisplayName\x12Q\n" +
	"\x06labels\x18\b \x03(\v29.google.events.cloud.dataplex.v1.DataTaxonomy.LabelsEntryR\x06labels\x12'\n" +
	"\x0fattribute_count\x18\t \x01(\x05R\x0eattributeCount\x12\x12\n" +
	"\x04etag\x18\n" +
	" \x01(\tR\x04etag\x1a9\n" +
	"\vLabelsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\x9f\x05\n" +
	"\rDataAttribute\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x10\n" +
	"\x03uid\x18\x02 \x01(\tR\x03uid\x12;\n" +
	"\vcreate_time\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"createTime\x12;\n" +
	"\vupdate_time\x18\x04 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"updateTime\x12 \n" +
	"\vdescription\x18\x05 \x01(\tR\vdescription\x12!\n" +
	"\fdisplay_name\x18\x06 \x01(\tR\vdisplayName\x12R\n" +
	"\x06labels\x18\a \x03(\v2:.google.events.cloud.dataplex.v1.DataAttribute.LabelsEntryR\x06labels\x12\x1b\n" +
	"\tparent_id\x18\b \x01(\tR\bparentId\x12'\n" +
	"\x0fattribute_count\x18\t \x01(\x05R\x0eattributeCount\x12\x12\n" +
	"\x04etag\x18\n" +
	" \x01(\tR\x04etag\x12e\n" +
	"\x14resource_access_spec\x18d \x01(\v23.google.events.cloud.dataplex.v1.ResourceAccessSpecR\x12resourceAccessSpec\x12Y\n" +
	"\x10data_access_spec\x18e \x01(\v2/.google.events.cloud.dataplex.v1.DataAccessSpecR\x0edataAccessSpec\x1a9\n" +
	"\vLabelsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\x87\x05\n" +
	"\x14DataAttributeBinding\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x10\n" +
	"\x03uid\x18\x02 \x01(\tR\x03uid\x12;\n" +
	"\vcreate_time\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"createTime\x12;\n" +
	"\vupdate_time\x18\x04 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"updateTime\x12 \n" +
	"\vdescription\x18\x05 \x01(\tR\vdescription\x12!\n" +
	"\fdisplay_name\x18\x06 \x01(\tR\vdisplayName\x12Y\n" +
	"\x06labels\x18\a \x03(\v2A.google.events.cloud.dataplex.v1.DataAttributeBinding.LabelsEntryR\x06labels\x12\x12\n" +
	"\x04etag\x18\b \x01(\tR\x04etag\x12\x1c\n" +
	"\bresource\x18d \x01(\tH\x00R\bresource\x12\x1e\n" +
	"\n" +
	"attributes\x18n \x03(\tR\n" +
	"attributes\x12P\n" +
	"\x05paths\x18x \x03(\v2:.google.events.cloud.dataplex.v1.DataAttributeBinding.PathR\x05paths\x1a:\n" +
	"\x04Path\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x1e\n" +
	"\n" +
	"attributes\x18\x02 \x03(\tR\n" +
	"attributes\x1a9\n" +
	"\vLabelsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01B\x14\n" +
	"\x12resource_reference\"\xcb\v\n" +
	"\bDataScan\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x10\n" +
	"\x03uid\x18\x02 \x01(\tR\x03uid\x12 \n" +
	"\vdescription\x18\x03 \x01(\tR\vdescription\x12!\n" +
	"\fdisplay_name\x18\x04 \x01(\tR\vdisplayName\x12M\n" +
	"\x06labels\x18\x05 \x03(\v25.google.events.cloud.dataplex.v1.DataScan.LabelsEntryR\x06labels\x12<\n" +
	"\x05state\x18\x06 \x01(\x0e2&.google.events.cloud.dataplex.v1.StateR\x05state\x12;\n" +
	"\vcreate_time\x18\a \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"createTime\x12;\n" +
	"\vupdate_time\x18\b \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"updateTime\x12?\n" +
	"\x04data\x18\t \x01(\v2+.google.events.cloud.dataplex.v1.DataSourceR\x04data\x12^\n" +
	"\x0eexecution_spec\x18\n" +
	" \x01(\v27.google.events.cloud.dataplex.v1.DataScan.ExecutionSpecR\rexecutionSpec\x12d\n" +
	"\x10execution_status\x18\v \x01(\v29.google.events.cloud.dataplex.v1.DataScan.ExecutionStatusR\x0fexecutionStatus\x12A\n" +
	"\x04type\x18\f \x01(\x0e2-.google.events.cloud.dataplex.v1.DataScanTypeR\x04type\x12^\n" +
	"\x11data_quality_spec\x18d \x01(\v20.google.events.cloud.dataplex.v1.DataQualitySpecH\x00R\x0fdataQualitySpec\x12^\n" +
	"\x11data_profile_spec\x18e \x01(\v20.google.events.cloud.dataplex.v1.DataProfileSpecH\x00R\x0fdataProfileSpec\x12e\n" +
	"\x13data_quality_result\x18\xc8\x01 \x01(\v22.google.events.cloud.dataplex.v1.DataQualityResultH\x01R\x11dataQualityResult\x12e\n" +
	"\x13data_profile_result\x18\xc9\x01 \x01(\v22.google.events.cloud.dataplex.v1.DataProfileResultH\x01R\x11dataProfileResult\x1az\n" +
	"\rExecutionSpec\x12B\n" +
	"\atrigger\x18\x01 \x01(\v2(.google.events.cloud.dataplex.v1.TriggerR\atrigger\x12\x16\n" +
	"\x05field\x18d \x01(\tH\x00R\x05fieldB\r\n" +
	"\vincremental\x1a\xab\x01\n" +
	"\x0fExecutionStatus\x12M\n" +
	"\x15latest_job_start_time\x18\x04 \x01(\v2\x1a.google.protobuf.TimestampR\x12latestJobStartTime\x12I\n" +
	"\x13latest_job_end_time\x18\x05 \x01(\v2\x1a.google.protobuf.TimestampR\x10latestJobEndTime\x1a9\n" +
	"\vLabelsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01B\x06\n" +
	"\x04specB\b\n" +
	"\x06result\"\xb5\x19\n" +
	"\x04Task\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x10\n" +
	"\x03uid\x18\x02 \x01(\tR\x03uid\x12;\n" +
	"\vcreate_time\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"createTime\x12;\n" +
	"\vupdate_time\x18\x04 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"updateTime\x12 \n" +
	"\vdescription\x18\x05 \x01(\tR\vdescription\x12!\n" +
	"\fdisplay_name\x18\x06 \x01(\tR\vdisplayName\x12<\n" +
	"\x05state\x18\a \x01(\x0e2&.google.events.cloud.dataplex.v1.StateR\x05state\x12I\n" +
	"\x06labels\x18\b \x03(\v21.google.events.cloud.dataplex.v1.Task.LabelsEntryR\x06labels\x12T\n" +
	"\ftrigger_spec\x18d \x01(\v21.google.events.cloud.dataplex.v1.Task.TriggerSpecR\vtriggerSpec\x12Z\n" +
	"\x0eexecution_spec\x18e \x01(\v23.google.events.cloud.dataplex.v1.Task.ExecutionSpecR\rexecutionSpec\x12a\n" +
	"\x10execution_status\x18\xc9\x01 \x01(\v25.google.events.cloud.dataplex.v1.Task.ExecutionStatusR\x0fexecutionStatus\x12N\n" +
	"\x05spark\x18\xac\x02 \x01(\v25.google.events.cloud.dataplex.v1.Task.SparkTaskConfigH\x00R\x05spark\x12W\n" +
	"\bnotebook\x18\xae\x02 \x01(\v28.google.events.cloud.dataplex.v1.Task.NotebookTaskConfigH\x00R\bnotebook\x1a\xaa\a\n" +
	"\x12InfrastructureSpec\x12f\n" +
	"\x05batch\x184 \x01(\v2N.google.events.cloud.dataplex.v1.Task.InfrastructureSpec.BatchComputeResourcesH\x00R\x05batch\x12y\n" +
	"\x0fcontainer_image\x18e \x01(\v2N.google.events.cloud.dataplex.v1.Task.InfrastructureSpec.ContainerImageRuntimeH\x01R\x0econtainerImage\x12g\n" +
	"\vvpc_network\x18\x96\x01 \x01(\v2C.google.events.cloud.dataplex.v1.Task.InfrastructureSpec.VpcNetworkH\x02R\n" +
	"vpcNetwork\x1ap\n" +
	"\x15BatchComputeResources\x12'\n" +
	"\x0fexecutors_count\x18\x01 \x01(\x05R\x0eexecutorsCount\x12.\n" +
	"\x13max_executors_count\x18\x02 \x01(\x05R\x11maxExecutorsCount\x1a\xb2\x02\n" +
	"\x15ContainerImageRuntime\x12\x14\n" +
	"\x05image\x18\x01 \x01(\tR\x05image\x12\x1b\n" +
	"\tjava_jars\x18\x02 \x03(\tR\bjavaJars\x12'\n" +
	"\x0fpython_packages\x18\x03 \x03(\tR\x0epythonPackages\x12~\n" +
	"\n" +
	"properties\x18\x04 \x03(\v2^.google.events.cloud.dataplex.v1.Task.InfrastructureSpec.ContainerImageRuntime.PropertiesEntryR\n" +
	"properties\x1a=\n" +
	"\x0fPropertiesEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\x1a~\n" +
	"\n" +
	"VpcNetwork\x12\x1a\n" +
	"\anetwork\x18\x01 \x01(\tH\x00R\anetwork\x12!\n" +
	"\vsub_network\x18\x02 \x01(\tH\x00R\n" +
	"subNetwork\x12!\n" +
	"\fnetwork_tags\x18\x03 \x03(\tR\vnetworkTagsB\x0e\n" +
	"\fnetwork_nameB\v\n" +
	"\tresourcesB\t\n" +
	"\aruntimeB\t\n" +
	"\anetwork\x1a\xb6\x02\n" +
	"\vTriggerSpec\x12J\n" +
	"\x04type\x18\x05 \x01(\x0e26.google.events.cloud.dataplex.v1.Task.TriggerSpec.TypeR\x04type\x129\n" +
	"\n" +
	"start_time\x18\x06 \x01(\v2\x1a.google.protobuf.TimestampR\tstartTime\x12\x1a\n" +
	"\bdisabled\x18\x04 \x01(\bR\bdisabled\x12\x1f\n" +
	"\vmax_retries\x18\a \x01(\x05R\n" +
	"maxRetries\x12\x1c\n" +
	"\bschedule\x18d \x01(\tH\x00R\bschedule\":\n" +
	"\x04Type\x12\x14\n" +
	"\x10TYPE_UNSPECIFIED\x10\x00\x12\r\n" +
	"\tON_DEMAND\x10\x01\x12\r\n" +
	"\tRECURRING\x10\x02B\t\n" +
	"\atrigger\x1a\xcf\x02\n" +
	"\rExecutionSpec\x12Q\n" +
	"\x04args\x18\x04 \x03(\v2=.google.events.cloud.dataplex.v1.Task.ExecutionSpec.ArgsEntryR\x04args\x12'\n" +
	"\x0fservice_account\x18\x05 \x01(\tR\x0eserviceAccount\x12\x18\n" +
	"\aproject\x18\a \x01(\tR\aproject\x12V\n" +
	"\x1amax_job_execution_lifetime\x18\b \x01(\v2\x19.google.protobuf.DurationR\x17maxJobExecutionLifetime\x12\x17\n" +
	"\akms_key\x18\t \x01(\tR\x06kmsKey\x1a7\n" +
	"\tArgsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\x1a\x8f\x03\n" +
	"\x0fSparkTaskConfig\x12+\n" +
	"\x11main_jar_file_uri\x18d \x01(\tH\x00R\x0emainJarFileUri\x12\x1f\n" +
	"\n" +
	"main_class\x18e \x01(\tH\x00R\tmainClass\x12.\n" +
	"\x12python_script_file\x18f \x01(\tH\x00R\x10pythonScriptFile\x12(\n" +
	"\x0fsql_script_file\x18h \x01(\tH\x00R\rsqlScriptFile\x12\x1f\n" +
	"\n" +
	"sql_script\x18i \x01(\tH\x00R\tsqlScript\x12\x1b\n" +
	"\tfile_uris\x18\x03 \x03(\tR\bfileUris\x12!\n" +
	"\farchive_uris\x18\x04 \x03(\tR\varchiveUris\x12i\n" +
	"\x13infrastructure_spec\x18\x06 \x01(\v28.google.events.cloud.dataplex.v1.Task.InfrastructureSpecR\x12infrastructureSpecB\b\n" +
	"\x06driver\x1a\xdb\x01\n" +
	"\x12NotebookTaskConfig\x12\x1a\n" +
	"\bnotebook\x18\x04 \x01(\tR\bnotebook\x12i\n" +
	"\x13infrastructure_spec\x18\x03 \x01(\v28.google.events.cloud.dataplex.v1.Task.InfrastructureSpecR\x12infrastructureSpec\x12\x1b\n" +
	"\tfile_uris\x18\x05 \x03(\tR\bfileUris\x12!\n" +
	"\farchive_uris\x18\x06 \x03(\tR\varchiveUris\x1a\x93\x01\n" +
	"\x0fExecutionStatus\x12;\n" +
	"\vupdate_time\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"updateTime\x12C\n" +
	"\n" +
	"latest_job\x18\t \x01(\v2$.google.events.cloud.dataplex.v1.JobR\tlatestJob\x1a9\n" +
	"\vLabelsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01B\b\n" +
	"\x06config\"\xa9\x04\n" +
	"\x03Job\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x10\n" +
	"\x03uid\x18\x02 \x01(\tR\x03uid\x129\n" +
	"\n" +
	"start_time\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\tstartTime\x125\n" +
	"\bend_time\x18\x04 \x01(\v2\x1a.google.protobuf.TimestampR\aendTime\x12@\n" +
	"\x05state\x18\x05 \x01(\x0e2*.google.events.cloud.dataplex.v1.Job.StateR\x05state\x12\x1f\n" +
	"\vretry_count\x18\x06 \x01(\rR\n" +
	"retryCount\x12F\n" +
	"\aservice\x18\a \x01(\x0e2,.google.events.cloud.dataplex.v1.Job.ServiceR\aservice\x12\x1f\n" +
	"\vservice_job\x18\b \x01(\tR\n" +
	"serviceJob\x12\x18\n" +
	"\amessage\x18\t \x01(\tR\amessage\"0\n" +
	"\aService\x12\x17\n" +
	"\x13SERVICE_UNSPECIFIED\x10\x00\x12\f\n" +
	"\bDATAPROC\x10\x01\"r\n" +
	"\x05State\x12\x15\n" +
	"\x11STATE_UNSPECIFIED\x10\x00\x12\v\n" +
	"\aRUNNING\x10\x01\x12\x0e\n" +
	"\n" +
	"CANCELLING\x10\x02\x12\r\n" +
	"\tCANCELLED\x10\x03\x12\r\n" +
	"\tSUCCEEDED\x10\x04\x12\n" +
	"\n" +
	"\x06FAILED\x10\x05\x12\v\n" +
	"\aABORTED\x10\x06\"a\n" +
	"\rTaskEventData\x12D\n" +
	"\apayload\x18\x01 \x01(\v2%.google.events.cloud.dataplex.v1.TaskH\x00R\apayload\x88\x01\x01B\n" +
	"\n" +
	"\b_payload\"a\n" +
	"\rZoneEventData\x12D\n" +
	"\apayload\x18\x01 \x01(\v2%.google.events.cloud.dataplex.v1.ZoneH\x00R\apayload\x88\x01\x01B\n" +
	"\n" +
	"\b_payload\"c\n" +
	"\x0eAssetEventData\x12E\n" +
	"\apayload\x18\x01 \x01(\v2&.google.events.cloud.dataplex.v1.AssetH\x00R\apayload\x88\x01\x01B\n" +
	"\n" +
	"\b_payload\"o\n" +
	"\x14EnvironmentEventData\x12K\n" +
	"\apayload\x18\x01 \x01(\v2,.google.events.cloud.dataplex.v1.EnvironmentH\x00R\apayload\x88\x01\x01B\n" +
	"\n" +
	"\b_payload\"q\n" +
	"\x15DataTaxonomyEventData\x12L\n" +
	"\apayload\x18\x01 \x01(\v2-.google.events.cloud.dataplex.v1.DataTaxonomyH\x00R\apayload\x88\x01\x01B\n" +
	"\n" +
	"\b_payload\"\x81\x01\n" +
	"\x1dDataAttributeBindingEventData\x12T\n" +
	"\apayload\x18\x01 \x01(\v25.google.events.cloud.dataplex.v1.DataAttributeBindingH\x00R\apayload\x88\x01\x01B\n" +
	"\n" +
	"\b_payload\"i\n" +
	"\x11DataScanEventData\x12H\n" +
	"\apayload\x18\x01 \x01(\v2).google.events.cloud.dataplex.v1.DataScanH\x00R\apayload\x88\x01\x01B\n" +
	"\n" +
	"\b_payload\"a\n" +
	"\rLakeEventData\x12D\n" +
	"\apayload\x18\x01 \x01(\v2%.google.events.cloud.dataplex.v1.LakeH\x00R\apayload\x88\x01\x01B\n" +
	"\n" +
	"\b_payload\"s\n" +
	"\x16DataAttributeEventData\x12M\n" +
	"\apayload\x18\x01 \x01(\v2..google.events.cloud.dataplex.v1.DataAttributeH\x00R\apayload\x88\x01\x01B\n" +
	"\n" +
	"\b_payload*[\n" +
	"\x05State\x12\x15\n" +
	"\x11STATE_UNSPECIFIED\x10\x00\x12\n" +
	"\n" +
	"\x06ACTIVE\x10\x01\x12\f\n" +
	"\bCREATING\x10\x02\x12\f\n" +
	"\bDELETING\x10\x03\x12\x13\n" +
	"\x0fACTION_REQUIRED\x10\x04*R\n" +
	"\fDataScanType\x12\x1e\n" +
	"\x1aDATA_SCAN_TYPE_UNSPECIFIED\x10\x00\x12\x10\n" +
	"\fDATA_QUALITY\x10\x01\x12\x10\n" +
	"\fDATA_PROFILE\x10\x02B+\xaa\x02(Google.Events.Protobuf.Cloud.Dataplex.V1b\x06proto3"

var (
	file_cloud_dataplex_v1_data_proto_rawDescOnce sync.Once
	file_cloud_dataplex_v1_data_proto_rawDescData []byte
)

func file_cloud_dataplex_v1_data_proto_rawDescGZIP() []byte {
	file_cloud_dataplex_v1_data_proto_rawDescOnce.Do(func() {
		file_cloud_dataplex_v1_data_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_cloud_dataplex_v1_data_proto_rawDesc), len(file_cloud_dataplex_v1_data_proto_rawDesc)))
	})
	return file_cloud_dataplex_v1_data_proto_rawDescData
}

var file_cloud_dataplex_v1_data_proto_enumTypes = make([]protoimpl.EnumInfo, 14)
var file_cloud_dataplex_v1_data_proto_msgTypes = make([]protoimpl.MessageInfo, 94)
var file_cloud_dataplex_v1_data_proto_goTypes = []any{
	(State)(0),                          // 0: google.events.cloud.dataplex.v1.State
	(DataScanType)(0),                   // 1: google.events.cloud.dataplex.v1.DataScanType
	(Lake_MetastoreStatus_State)(0),     // 2: google.events.cloud.dataplex.v1.Lake.MetastoreStatus.State
	(Zone_Type)(0),                      // 3: google.events.cloud.dataplex.v1.Zone.Type
	(Zone_ResourceSpec_LocationType)(0), // 4: google.events.cloud.dataplex.v1.Zone.ResourceSpec.LocationType
	(Asset_SecurityStatus_State)(0),     // 5: google.events.cloud.dataplex.v1.Asset.SecurityStatus.State
	(Asset_ResourceSpec_Type)(0),        // 6: google.events.cloud.dataplex.v1.Asset.ResourceSpec.Type
	(Asset_ResourceSpec_AccessMode)(0),  // 7: google.events.cloud.dataplex.v1.Asset.ResourceSpec.AccessMode
	(Asset_ResourceStatus_State)(0),     // 8: google.events.cloud.dataplex.v1.Asset.ResourceStatus.State
	(Asset_DiscoveryStatus_State)(0),    // 9: google.events.cloud.dataplex.v1.Asset.DiscoveryStatus.State
	(DataQualityRule_StatisticRangeExpectation_ColumnStatistic)(0), // 10: google.events.cloud.dataplex.v1.DataQualityRule.StatisticRangeExpectation.ColumnStatistic
	(Task_TriggerSpec_Type)(0),                                     // 11: google.events.cloud.dataplex.v1.Task.TriggerSpec.Type
	(Job_Service)(0),                                               // 12: google.events.cloud.dataplex.v1.Job.Service
	(Job_State)(0),                                                 // 13: google.events.cloud.dataplex.v1.Job.State
	(*Lake)(nil),                                                   // 14: google.events.cloud.dataplex.v1.Lake
	(*AssetStatus)(nil),                                            // 15: google.events.cloud.dataplex.v1.AssetStatus
	(*Zone)(nil),                                                   // 16: google.events.cloud.dataplex.v1.Zone
	(*Asset)(nil),                                                  // 17: google.events.cloud.dataplex.v1.Asset
	(*Environment)(nil),                                            // 18: google.events.cloud.dataplex.v1.Environment
	(*Trigger)(nil),                                                // 19: google.events.cloud.dataplex.v1.Trigger
	(*DataSource)(nil),                                             // 20: google.events.cloud.dataplex.v1.DataSource
	(*ScannedData)(nil),                                            // 21: google.events.cloud.dataplex.v1.ScannedData
	(*DataProfileSpec)(nil),                                        // 22: google.events.cloud.dataplex.v1.DataProfileSpec
	(*DataProfileResult)(nil),                                      // 23: google.events.cloud.dataplex.v1.DataProfileResult
	(*DataQualitySpec)(nil),                                        // 24: google.events.cloud.dataplex.v1.DataQualitySpec
	(*DataQualityResult)(nil),                                      // 25: google.events.cloud.dataplex.v1.DataQualityResult
	(*DataQualityRuleResult)(nil),                                  // 26: google.events.cloud.dataplex.v1.DataQualityRuleResult
	(*DataQualityDimensionResult)(nil),                             // 27: google.events.cloud.dataplex.v1.DataQualityDimensionResult
	(*DataQualityRule)(nil),                                        // 28: google.events.cloud.dataplex.v1.DataQualityRule
	(*ResourceAccessSpec)(nil),                                     // 29: google.events.cloud.dataplex.v1.ResourceAccessSpec
	(*DataAccessSpec)(nil),                                         // 30: google.events.cloud.dataplex.v1.DataAccessSpec
	(*DataTaxonomy)(nil),                                           // 31: google.events.cloud.dataplex.v1.DataTaxonomy
	(*DataAttribute)(nil),                                          // 32: google.events.cloud.dataplex.v1.DataAttribute
	(*DataAttributeBinding)(nil),                                   // 33: google.events.cloud.dataplex.v1.DataAttributeBinding
	(*DataScan)(nil),                                               // 34: google.events.cloud.dataplex.v1.DataScan
	(*Task)(nil),                                                   // 35: google.events.cloud.dataplex.v1.Task
	(*Job)(nil),                                                    // 36: google.events.cloud.dataplex.v1.Job
	(*TaskEventData)(nil),                                          // 37: google.events.cloud.dataplex.v1.TaskEventData
	(*ZoneEventData)(nil),                                          // 38: google.events.cloud.dataplex.v1.ZoneEventData
	(*AssetEventData)(nil),                                         // 39: google.events.cloud.dataplex.v1.AssetEventData
	(*EnvironmentEventData)(nil),                                   // 40: google.events.cloud.dataplex.v1.EnvironmentEventData
	(*DataTaxonomyEventData)(nil),                                  // 41: google.events.cloud.dataplex.v1.DataTaxonomyEventData
	(*DataAttributeBindingEventData)(nil),                          // 42: google.events.cloud.dataplex.v1.DataAttributeBindingEventData
	(*DataScanEventData)(nil),                                      // 43: google.events.cloud.dataplex.v1.DataScanEventData
	(*LakeEventData)(nil),                                          // 44: google.events.cloud.dataplex.v1.LakeEventData
	(*DataAttributeEventData)(nil),                                 // 45: google.events.cloud.dataplex.v1.DataAttributeEventData
	(*Lake_Metastore)(nil),                                         // 46: google.events.cloud.dataplex.v1.Lake.Metastore
	(*Lake_MetastoreStatus)(nil),                                   // 47: google.events.cloud.dataplex.v1.Lake.MetastoreStatus
	nil,                                                            // 48: google.events.cloud.dataplex.v1.Lake.LabelsEntry
	(*Zone_ResourceSpec)(nil),                                      // 49: google.events.cloud.dataplex.v1.Zone.ResourceSpec
	(*Zone_DiscoverySpec)(nil),                                     // 50: google.events.cloud.dataplex.v1.Zone.DiscoverySpec
	nil,                                                            // 51: google.events.cloud.dataplex.v1.Zone.LabelsEntry
	(*Zone_DiscoverySpec_CsvOptions)(nil),                          // 52: google.events.cloud.dataplex.v1.Zone.DiscoverySpec.CsvOptions
	(*Zone_DiscoverySpec_JsonOptions)(nil),                         // 53: google.events.cloud.dataplex.v1.Zone.DiscoverySpec.JsonOptions
	(*Asset_SecurityStatus)(nil),                                   // 54: google.events.cloud.dataplex.v1.Asset.SecurityStatus
	(*Asset_DiscoverySpec)(nil),                                    // 55: google.events.cloud.dataplex.v1.Asset.DiscoverySpec
	(*Asset_ResourceSpec)(nil),                                     // 56: google.events.cloud.dataplex.v1.Asset.ResourceSpec
	(*Asset_ResourceStatus)(nil),                                   // 57: google.events.cloud.dataplex.v1.Asset.ResourceStatus
	(*Asset_DiscoveryStatus)(nil),                                  // 58: google.events.cloud.dataplex.v1.Asset.DiscoveryStatus
	nil,                                                            // 59: google.events.cloud.dataplex.v1.Asset.LabelsEntry
	(*Asset_DiscoverySpec_CsvOptions)(nil),                         // 60: google.events.cloud.dataplex.v1.Asset.DiscoverySpec.CsvOptions
	(*Asset_DiscoverySpec_JsonOptions)(nil),                        // 61: google.events.cloud.dataplex.v1.Asset.DiscoverySpec.JsonOptions
	(*Asset_DiscoveryStatus_Stats)(nil),                            // 62: google.events.cloud.dataplex.v1.Asset.DiscoveryStatus.Stats
	(*Environment_InfrastructureSpec)(nil),                         // 63: google.events.cloud.dataplex.v1.Environment.InfrastructureSpec
	(*Environment_SessionSpec)(nil),                                // 64: google.events.cloud.dataplex.v1.Environment.SessionSpec
	(*Environment_SessionStatus)(nil),                              // 65: google.events.cloud.dataplex.v1.Environment.SessionStatus
	(*Environment_Endpoints)(nil),                                  // 66: google.events.cloud.dataplex.v1.Environment.Endpoints
	nil,                                                            // 67: google.events.cloud.dataplex.v1.Environment.LabelsEntry
	(*Environment_InfrastructureSpec_ComputeResources)(nil), // 68: google.events.cloud.dataplex.v1.Environment.InfrastructureSpec.ComputeResources
	(*Environment_InfrastructureSpec_OsImageRuntime)(nil),   // 69: google.events.cloud.dataplex.v1.Environment.InfrastructureSpec.OsImageRuntime
	nil,                                                 // 70: google.events.cloud.dataplex.v1.Environment.InfrastructureSpec.OsImageRuntime.PropertiesEntry
	(*Trigger_OnDemand)(nil),                            // 71: google.events.cloud.dataplex.v1.Trigger.OnDemand
	(*Trigger_Schedule)(nil),                            // 72: google.events.cloud.dataplex.v1.Trigger.Schedule
	(*ScannedData_IncrementalField)(nil),                // 73: google.events.cloud.dataplex.v1.ScannedData.IncrementalField
	(*DataProfileResult_Profile)(nil),                   // 74: google.events.cloud.dataplex.v1.DataProfileResult.Profile
	(*DataProfileResult_Profile_Field)(nil),             // 75: google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field
	(*DataProfileResult_Profile_Field_ProfileInfo)(nil), // 76: google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.ProfileInfo
	(*DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo)(nil),  // 77: google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.ProfileInfo.StringFieldInfo
	(*DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo)(nil), // 78: google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.ProfileInfo.IntegerFieldInfo
	(*DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo)(nil),  // 79: google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.ProfileInfo.DoubleFieldInfo
	(*DataProfileResult_Profile_Field_ProfileInfo_TopNValue)(nil),        // 80: google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.ProfileInfo.TopNValue
	(*DataQualityRule_RangeExpectation)(nil),                             // 81: google.events.cloud.dataplex.v1.DataQualityRule.RangeExpectation
	(*DataQualityRule_NonNullExpectation)(nil),                           // 82: google.events.cloud.dataplex.v1.DataQualityRule.NonNullExpectation
	(*DataQualityRule_SetExpectation)(nil),                               // 83: google.events.cloud.dataplex.v1.DataQualityRule.SetExpectation
	(*DataQualityRule_RegexExpectation)(nil),                             // 84: google.events.cloud.dataplex.v1.DataQualityRule.RegexExpectation
	(*DataQualityRule_UniquenessExpectation)(nil),                        // 85: google.events.cloud.dataplex.v1.DataQualityRule.UniquenessExpectation
	(*DataQualityRule_StatisticRangeExpectation)(nil),                    // 86: google.events.cloud.dataplex.v1.DataQualityRule.StatisticRangeExpectation
	(*DataQualityRule_RowConditionExpectation)(nil),                      // 87: google.events.cloud.dataplex.v1.DataQualityRule.RowConditionExpectation
	(*DataQualityRule_TableConditionExpectation)(nil),                    // 88: google.events.cloud.dataplex.v1.DataQualityRule.TableConditionExpectation
	nil,                               // 89: google.events.cloud.dataplex.v1.DataTaxonomy.LabelsEntry
	nil,                               // 90: google.events.cloud.dataplex.v1.DataAttribute.LabelsEntry
	(*DataAttributeBinding_Path)(nil), // 91: google.events.cloud.dataplex.v1.DataAttributeBinding.Path
	nil,                               // 92: google.events.cloud.dataplex.v1.DataAttributeBinding.LabelsEntry
	(*DataScan_ExecutionSpec)(nil),    // 93: google.events.cloud.dataplex.v1.DataScan.ExecutionSpec
	(*DataScan_ExecutionStatus)(nil),  // 94: google.events.cloud.dataplex.v1.DataScan.ExecutionStatus
	nil,                               // 95: google.events.cloud.dataplex.v1.DataScan.LabelsEntry
	(*Task_InfrastructureSpec)(nil),   // 96: google.events.cloud.dataplex.v1.Task.InfrastructureSpec
	(*Task_TriggerSpec)(nil),          // 97: google.events.cloud.dataplex.v1.Task.TriggerSpec
	(*Task_ExecutionSpec)(nil),        // 98: google.events.cloud.dataplex.v1.Task.ExecutionSpec
	(*Task_SparkTaskConfig)(nil),      // 99: google.events.cloud.dataplex.v1.Task.SparkTaskConfig
	(*Task_NotebookTaskConfig)(nil),   // 100: google.events.cloud.dataplex.v1.Task.NotebookTaskConfig
	(*Task_ExecutionStatus)(nil),      // 101: google.events.cloud.dataplex.v1.Task.ExecutionStatus
	nil,                               // 102: google.events.cloud.dataplex.v1.Task.LabelsEntry
	(*Task_InfrastructureSpec_BatchComputeResources)(nil), // 103: google.events.cloud.dataplex.v1.Task.InfrastructureSpec.BatchComputeResources
	(*Task_InfrastructureSpec_ContainerImageRuntime)(nil), // 104: google.events.cloud.dataplex.v1.Task.InfrastructureSpec.ContainerImageRuntime
	(*Task_InfrastructureSpec_VpcNetwork)(nil),            // 105: google.events.cloud.dataplex.v1.Task.InfrastructureSpec.VpcNetwork
	nil,                           // 106: google.events.cloud.dataplex.v1.Task.InfrastructureSpec.ContainerImageRuntime.PropertiesEntry
	nil,                           // 107: google.events.cloud.dataplex.v1.Task.ExecutionSpec.ArgsEntry
	(*timestamppb.Timestamp)(nil), // 108: google.protobuf.Timestamp
	(*durationpb.Duration)(nil),   // 109: google.protobuf.Duration
}
var file_cloud_dataplex_v1_data_proto_depIdxs = []int32{
	108, // 0: google.events.cloud.dataplex.v1.Lake.create_time:type_name -> google.protobuf.Timestamp
	108, // 1: google.events.cloud.dataplex.v1.Lake.update_time:type_name -> google.protobuf.Timestamp
	48,  // 2: google.events.cloud.dataplex.v1.Lake.labels:type_name -> google.events.cloud.dataplex.v1.Lake.LabelsEntry
	0,   // 3: google.events.cloud.dataplex.v1.Lake.state:type_name -> google.events.cloud.dataplex.v1.State
	46,  // 4: google.events.cloud.dataplex.v1.Lake.metastore:type_name -> google.events.cloud.dataplex.v1.Lake.Metastore
	15,  // 5: google.events.cloud.dataplex.v1.Lake.asset_status:type_name -> google.events.cloud.dataplex.v1.AssetStatus
	47,  // 6: google.events.cloud.dataplex.v1.Lake.metastore_status:type_name -> google.events.cloud.dataplex.v1.Lake.MetastoreStatus
	108, // 7: google.events.cloud.dataplex.v1.AssetStatus.update_time:type_name -> google.protobuf.Timestamp
	108, // 8: google.events.cloud.dataplex.v1.Zone.create_time:type_name -> google.protobuf.Timestamp
	108, // 9: google.events.cloud.dataplex.v1.Zone.update_time:type_name -> google.protobuf.Timestamp
	51,  // 10: google.events.cloud.dataplex.v1.Zone.labels:type_name -> google.events.cloud.dataplex.v1.Zone.LabelsEntry
	0,   // 11: google.events.cloud.dataplex.v1.Zone.state:type_name -> google.events.cloud.dataplex.v1.State
	3,   // 12: google.events.cloud.dataplex.v1.Zone.type:type_name -> google.events.cloud.dataplex.v1.Zone.Type
	50,  // 13: google.events.cloud.dataplex.v1.Zone.discovery_spec:type_name -> google.events.cloud.dataplex.v1.Zone.DiscoverySpec
	49,  // 14: google.events.cloud.dataplex.v1.Zone.resource_spec:type_name -> google.events.cloud.dataplex.v1.Zone.ResourceSpec
	15,  // 15: google.events.cloud.dataplex.v1.Zone.asset_status:type_name -> google.events.cloud.dataplex.v1.AssetStatus
	108, // 16: google.events.cloud.dataplex.v1.Asset.create_time:type_name -> google.protobuf.Timestamp
	108, // 17: google.events.cloud.dataplex.v1.Asset.update_time:type_name -> google.protobuf.Timestamp
	59,  // 18: google.events.cloud.dataplex.v1.Asset.labels:type_name -> google.events.cloud.dataplex.v1.Asset.LabelsEntry
	0,   // 19: google.events.cloud.dataplex.v1.Asset.state:type_name -> google.events.cloud.dataplex.v1.State
	56,  // 20: google.events.cloud.dataplex.v1.Asset.resource_spec:type_name -> google.events.cloud.dataplex.v1.Asset.ResourceSpec
	57,  // 21: google.events.cloud.dataplex.v1.Asset.resource_status:type_name -> google.events.cloud.dataplex.v1.Asset.ResourceStatus
	54,  // 22: google.events.cloud.dataplex.v1.Asset.security_status:type_name -> google.events.cloud.dataplex.v1.Asset.SecurityStatus
	55,  // 23: google.events.cloud.dataplex.v1.Asset.discovery_spec:type_name -> google.events.cloud.dataplex.v1.Asset.DiscoverySpec
	58,  // 24: google.events.cloud.dataplex.v1.Asset.discovery_status:type_name -> google.events.cloud.dataplex.v1.Asset.DiscoveryStatus
	108, // 25: google.events.cloud.dataplex.v1.Environment.create_time:type_name -> google.protobuf.Timestamp
	108, // 26: google.events.cloud.dataplex.v1.Environment.update_time:type_name -> google.protobuf.Timestamp
	67,  // 27: google.events.cloud.dataplex.v1.Environment.labels:type_name -> google.events.cloud.dataplex.v1.Environment.LabelsEntry
	0,   // 28: google.events.cloud.dataplex.v1.Environment.state:type_name -> google.events.cloud.dataplex.v1.State
	63,  // 29: google.events.cloud.dataplex.v1.Environment.infrastructure_spec:type_name -> google.events.cloud.dataplex.v1.Environment.InfrastructureSpec
	64,  // 30: google.events.cloud.dataplex.v1.Environment.session_spec:type_name -> google.events.cloud.dataplex.v1.Environment.SessionSpec
	65,  // 31: google.events.cloud.dataplex.v1.Environment.session_status:type_name -> google.events.cloud.dataplex.v1.Environment.SessionStatus
	66,  // 32: google.events.cloud.dataplex.v1.Environment.endpoints:type_name -> google.events.cloud.dataplex.v1.Environment.Endpoints
	71,  // 33: google.events.cloud.dataplex.v1.Trigger.on_demand:type_name -> google.events.cloud.dataplex.v1.Trigger.OnDemand
	72,  // 34: google.events.cloud.dataplex.v1.Trigger.schedule:type_name -> google.events.cloud.dataplex.v1.Trigger.Schedule
	73,  // 35: google.events.cloud.dataplex.v1.ScannedData.incremental_field:type_name -> google.events.cloud.dataplex.v1.ScannedData.IncrementalField
	74,  // 36: google.events.cloud.dataplex.v1.DataProfileResult.profile:type_name -> google.events.cloud.dataplex.v1.DataProfileResult.Profile
	21,  // 37: google.events.cloud.dataplex.v1.DataProfileResult.scanned_data:type_name -> google.events.cloud.dataplex.v1.ScannedData
	28,  // 38: google.events.cloud.dataplex.v1.DataQualitySpec.rules:type_name -> google.events.cloud.dataplex.v1.DataQualityRule
	27,  // 39: google.events.cloud.dataplex.v1.DataQualityResult.dimensions:type_name -> google.events.cloud.dataplex.v1.DataQualityDimensionResult
	26,  // 40: google.events.cloud.dataplex.v1.DataQualityResult.rules:type_name -> google.events.cloud.dataplex.v1.DataQualityRuleResult
	21,  // 41: google.events.cloud.dataplex.v1.DataQualityResult.scanned_data:type_name -> google.events.cloud.dataplex.v1.ScannedData
	28,  // 42: google.events.cloud.dataplex.v1.DataQualityRuleResult.rule:type_name -> google.events.cloud.dataplex.v1.DataQualityRule
	81,  // 43: google.events.cloud.dataplex.v1.DataQualityRule.range_expectation:type_name -> google.events.cloud.dataplex.v1.DataQualityRule.RangeExpectation
	82,  // 44: google.events.cloud.dataplex.v1.DataQualityRule.non_null_expectation:type_name -> google.events.cloud.dataplex.v1.DataQualityRule.NonNullExpectation
	83,  // 45: google.events.cloud.dataplex.v1.DataQualityRule.set_expectation:type_name -> google.events.cloud.dataplex.v1.DataQualityRule.SetExpectation
	84,  // 46: google.events.cloud.dataplex.v1.DataQualityRule.regex_expectation:type_name -> google.events.cloud.dataplex.v1.DataQualityRule.RegexExpectation
	85,  // 47: google.events.cloud.dataplex.v1.DataQualityRule.uniqueness_expectation:type_name -> google.events.cloud.dataplex.v1.DataQualityRule.UniquenessExpectation
	86,  // 48: google.events.cloud.dataplex.v1.DataQualityRule.statistic_range_expectation:type_name -> google.events.cloud.dataplex.v1.DataQualityRule.StatisticRangeExpectation
	87,  // 49: google.events.cloud.dataplex.v1.DataQualityRule.row_condition_expectation:type_name -> google.events.cloud.dataplex.v1.DataQualityRule.RowConditionExpectation
	88,  // 50: google.events.cloud.dataplex.v1.DataQualityRule.table_condition_expectation:type_name -> google.events.cloud.dataplex.v1.DataQualityRule.TableConditionExpectation
	108, // 51: google.events.cloud.dataplex.v1.DataTaxonomy.create_time:type_name -> google.protobuf.Timestamp
	108, // 52: google.events.cloud.dataplex.v1.DataTaxonomy.update_time:type_name -> google.protobuf.Timestamp
	89,  // 53: google.events.cloud.dataplex.v1.DataTaxonomy.labels:type_name -> google.events.cloud.dataplex.v1.DataTaxonomy.LabelsEntry
	108, // 54: google.events.cloud.dataplex.v1.DataAttribute.create_time:type_name -> google.protobuf.Timestamp
	108, // 55: google.events.cloud.dataplex.v1.DataAttribute.update_time:type_name -> google.protobuf.Timestamp
	90,  // 56: google.events.cloud.dataplex.v1.DataAttribute.labels:type_name -> google.events.cloud.dataplex.v1.DataAttribute.LabelsEntry
	29,  // 57: google.events.cloud.dataplex.v1.DataAttribute.resource_access_spec:type_name -> google.events.cloud.dataplex.v1.ResourceAccessSpec
	30,  // 58: google.events.cloud.dataplex.v1.DataAttribute.data_access_spec:type_name -> google.events.cloud.dataplex.v1.DataAccessSpec
	108, // 59: google.events.cloud.dataplex.v1.DataAttributeBinding.create_time:type_name -> google.protobuf.Timestamp
	108, // 60: google.events.cloud.dataplex.v1.DataAttributeBinding.update_time:type_name -> google.protobuf.Timestamp
	92,  // 61: google.events.cloud.dataplex.v1.DataAttributeBinding.labels:type_name -> google.events.cloud.dataplex.v1.DataAttributeBinding.LabelsEntry
	91,  // 62: google.events.cloud.dataplex.v1.DataAttributeBinding.paths:type_name -> google.events.cloud.dataplex.v1.DataAttributeBinding.Path
	95,  // 63: google.events.cloud.dataplex.v1.DataScan.labels:type_name -> google.events.cloud.dataplex.v1.DataScan.LabelsEntry
	0,   // 64: google.events.cloud.dataplex.v1.DataScan.state:type_name -> google.events.cloud.dataplex.v1.State
	108, // 65: google.events.cloud.dataplex.v1.DataScan.create_time:type_name -> google.protobuf.Timestamp
	108, // 66: google.events.cloud.dataplex.v1.DataScan.update_time:type_name -> google.protobuf.Timestamp
	20,  // 67: google.events.cloud.dataplex.v1.DataScan.data:type_name -> google.events.cloud.dataplex.v1.DataSource
	93,  // 68: google.events.cloud.dataplex.v1.DataScan.execution_spec:type_name -> google.events.cloud.dataplex.v1.DataScan.ExecutionSpec
	94,  // 69: google.events.cloud.dataplex.v1.DataScan.execution_status:type_name -> google.events.cloud.dataplex.v1.DataScan.ExecutionStatus
	1,   // 70: google.events.cloud.dataplex.v1.DataScan.type:type_name -> google.events.cloud.dataplex.v1.DataScanType
	24,  // 71: google.events.cloud.dataplex.v1.DataScan.data_quality_spec:type_name -> google.events.cloud.dataplex.v1.DataQualitySpec
	22,  // 72: google.events.cloud.dataplex.v1.DataScan.data_profile_spec:type_name -> google.events.cloud.dataplex.v1.DataProfileSpec
	25,  // 73: google.events.cloud.dataplex.v1.DataScan.data_quality_result:type_name -> google.events.cloud.dataplex.v1.DataQualityResult
	23,  // 74: google.events.cloud.dataplex.v1.DataScan.data_profile_result:type_name -> google.events.cloud.dataplex.v1.DataProfileResult
	108, // 75: google.events.cloud.dataplex.v1.Task.create_time:type_name -> google.protobuf.Timestamp
	108, // 76: google.events.cloud.dataplex.v1.Task.update_time:type_name -> google.protobuf.Timestamp
	0,   // 77: google.events.cloud.dataplex.v1.Task.state:type_name -> google.events.cloud.dataplex.v1.State
	102, // 78: google.events.cloud.dataplex.v1.Task.labels:type_name -> google.events.cloud.dataplex.v1.Task.LabelsEntry
	97,  // 79: google.events.cloud.dataplex.v1.Task.trigger_spec:type_name -> google.events.cloud.dataplex.v1.Task.TriggerSpec
	98,  // 80: google.events.cloud.dataplex.v1.Task.execution_spec:type_name -> google.events.cloud.dataplex.v1.Task.ExecutionSpec
	101, // 81: google.events.cloud.dataplex.v1.Task.execution_status:type_name -> google.events.cloud.dataplex.v1.Task.ExecutionStatus
	99,  // 82: google.events.cloud.dataplex.v1.Task.spark:type_name -> google.events.cloud.dataplex.v1.Task.SparkTaskConfig
	100, // 83: google.events.cloud.dataplex.v1.Task.notebook:type_name -> google.events.cloud.dataplex.v1.Task.NotebookTaskConfig
	108, // 84: google.events.cloud.dataplex.v1.Job.start_time:type_name -> google.protobuf.Timestamp
	108, // 85: google.events.cloud.dataplex.v1.Job.end_time:type_name -> google.protobuf.Timestamp
	13,  // 86: google.events.cloud.dataplex.v1.Job.state:type_name -> google.events.cloud.dataplex.v1.Job.State
	12,  // 87: google.events.cloud.dataplex.v1.Job.service:type_name -> google.events.cloud.dataplex.v1.Job.Service
	35,  // 88: google.events.cloud.dataplex.v1.TaskEventData.payload:type_name -> google.events.cloud.dataplex.v1.Task
	16,  // 89: google.events.cloud.dataplex.v1.ZoneEventData.payload:type_name -> google.events.cloud.dataplex.v1.Zone
	17,  // 90: google.events.cloud.dataplex.v1.AssetEventData.payload:type_name -> google.events.cloud.dataplex.v1.Asset
	18,  // 91: google.events.cloud.dataplex.v1.EnvironmentEventData.payload:type_name -> google.events.cloud.dataplex.v1.Environment
	31,  // 92: google.events.cloud.dataplex.v1.DataTaxonomyEventData.payload:type_name -> google.events.cloud.dataplex.v1.DataTaxonomy
	33,  // 93: google.events.cloud.dataplex.v1.DataAttributeBindingEventData.payload:type_name -> google.events.cloud.dataplex.v1.DataAttributeBinding
	34,  // 94: google.events.cloud.dataplex.v1.DataScanEventData.payload:type_name -> google.events.cloud.dataplex.v1.DataScan
	14,  // 95: google.events.cloud.dataplex.v1.LakeEventData.payload:type_name -> google.events.cloud.dataplex.v1.Lake
	32,  // 96: google.events.cloud.dataplex.v1.DataAttributeEventData.payload:type_name -> google.events.cloud.dataplex.v1.DataAttribute
	2,   // 97: google.events.cloud.dataplex.v1.Lake.MetastoreStatus.state:type_name -> google.events.cloud.dataplex.v1.Lake.MetastoreStatus.State
	108, // 98: google.events.cloud.dataplex.v1.Lake.MetastoreStatus.update_time:type_name -> google.protobuf.Timestamp
	4,   // 99: google.events.cloud.dataplex.v1.Zone.ResourceSpec.location_type:type_name -> google.events.cloud.dataplex.v1.Zone.ResourceSpec.LocationType
	52,  // 100: google.events.cloud.dataplex.v1.Zone.DiscoverySpec.csv_options:type_name -> google.events.cloud.dataplex.v1.Zone.DiscoverySpec.CsvOptions
	53,  // 101: google.events.cloud.dataplex.v1.Zone.DiscoverySpec.json_options:type_name -> google.events.cloud.dataplex.v1.Zone.DiscoverySpec.JsonOptions
	5,   // 102: google.events.cloud.dataplex.v1.Asset.SecurityStatus.state:type_name -> google.events.cloud.dataplex.v1.Asset.SecurityStatus.State
	108, // 103: google.events.cloud.dataplex.v1.Asset.SecurityStatus.update_time:type_name -> google.protobuf.Timestamp
	60,  // 104: google.events.cloud.dataplex.v1.Asset.DiscoverySpec.csv_options:type_name -> google.events.cloud.dataplex.v1.Asset.DiscoverySpec.CsvOptions
	61,  // 105: google.events.cloud.dataplex.v1.Asset.DiscoverySpec.json_options:type_name -> google.events.cloud.dataplex.v1.Asset.DiscoverySpec.JsonOptions
	6,   // 106: google.events.cloud.dataplex.v1.Asset.ResourceSpec.type:type_name -> google.events.cloud.dataplex.v1.Asset.ResourceSpec.Type
	7,   // 107: google.events.cloud.dataplex.v1.Asset.ResourceSpec.read_access_mode:type_name -> google.events.cloud.dataplex.v1.Asset.ResourceSpec.AccessMode
	8,   // 108: google.events.cloud.dataplex.v1.Asset.ResourceStatus.state:type_name -> google.events.cloud.dataplex.v1.Asset.ResourceStatus.State
	108, // 109: google.events.cloud.dataplex.v1.Asset.ResourceStatus.update_time:type_name -> google.protobuf.Timestamp
	9,   // 110: google.events.cloud.dataplex.v1.Asset.DiscoveryStatus.state:type_name -> google.events.cloud.dataplex.v1.Asset.DiscoveryStatus.State
	108, // 111: google.events.cloud.dataplex.v1.Asset.DiscoveryStatus.update_time:type_name -> google.protobuf.Timestamp
	108, // 112: google.events.cloud.dataplex.v1.Asset.DiscoveryStatus.last_run_time:type_name -> google.protobuf.Timestamp
	62,  // 113: google.events.cloud.dataplex.v1.Asset.DiscoveryStatus.stats:type_name -> google.events.cloud.dataplex.v1.Asset.DiscoveryStatus.Stats
	109, // 114: google.events.cloud.dataplex.v1.Asset.DiscoveryStatus.last_run_duration:type_name -> google.protobuf.Duration
	68,  // 115: google.events.cloud.dataplex.v1.Environment.InfrastructureSpec.compute:type_name -> google.events.cloud.dataplex.v1.Environment.InfrastructureSpec.ComputeResources
	69,  // 116: google.events.cloud.dataplex.v1.Environment.InfrastructureSpec.os_image:type_name -> google.events.cloud.dataplex.v1.Environment.InfrastructureSpec.OsImageRuntime
	109, // 117: google.events.cloud.dataplex.v1.Environment.SessionSpec.max_idle_duration:type_name -> google.protobuf.Duration
	70,  // 118: google.events.cloud.dataplex.v1.Environment.InfrastructureSpec.OsImageRuntime.properties:type_name -> google.events.cloud.dataplex.v1.Environment.InfrastructureSpec.OsImageRuntime.PropertiesEntry
	75,  // 119: google.events.cloud.dataplex.v1.DataProfileResult.Profile.fields:type_name -> google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field
	76,  // 120: google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.profile:type_name -> google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.ProfileInfo
	80,  // 121: google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.ProfileInfo.top_n_values:type_name -> google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.ProfileInfo.TopNValue
	77,  // 122: google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.ProfileInfo.string_profile:type_name -> google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.ProfileInfo.StringFieldInfo
	78,  // 123: google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.ProfileInfo.integer_profile:type_name -> google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.ProfileInfo.IntegerFieldInfo
	79,  // 124: google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.ProfileInfo.double_profile:type_name -> google.events.cloud.dataplex.v1.DataProfileResult.Profile.Field.ProfileInfo.DoubleFieldInfo
	10,  // 125: google.events.cloud.dataplex.v1.DataQualityRule.StatisticRangeExpectation.statistic:type_name -> google.events.cloud.dataplex.v1.DataQualityRule.StatisticRangeExpectation.ColumnStatistic
	19,  // 126: google.events.cloud.dataplex.v1.DataScan.ExecutionSpec.trigger:type_name -> google.events.cloud.dataplex.v1.Trigger
	108, // 127: google.events.cloud.dataplex.v1.DataScan.ExecutionStatus.latest_job_start_time:type_name -> google.protobuf.Timestamp
	108, // 128: google.events.cloud.dataplex.v1.DataScan.ExecutionStatus.latest_job_end_time:type_name -> google.protobuf.Timestamp
	103, // 129: google.events.cloud.dataplex.v1.Task.InfrastructureSpec.batch:type_name -> google.events.cloud.dataplex.v1.Task.InfrastructureSpec.BatchComputeResources
	104, // 130: google.events.cloud.dataplex.v1.Task.InfrastructureSpec.container_image:type_name -> google.events.cloud.dataplex.v1.Task.InfrastructureSpec.ContainerImageRuntime
	105, // 131: google.events.cloud.dataplex.v1.Task.InfrastructureSpec.vpc_network:type_name -> google.events.cloud.dataplex.v1.Task.InfrastructureSpec.VpcNetwork
	11,  // 132: google.events.cloud.dataplex.v1.Task.TriggerSpec.type:type_name -> google.events.cloud.dataplex.v1.Task.TriggerSpec.Type
	108, // 133: google.events.cloud.dataplex.v1.Task.TriggerSpec.start_time:type_name -> google.protobuf.Timestamp
	107, // 134: google.events.cloud.dataplex.v1.Task.ExecutionSpec.args:type_name -> google.events.cloud.dataplex.v1.Task.ExecutionSpec.ArgsEntry
	109, // 135: google.events.cloud.dataplex.v1.Task.ExecutionSpec.max_job_execution_lifetime:type_name -> google.protobuf.Duration
	96,  // 136: google.events.cloud.dataplex.v1.Task.SparkTaskConfig.infrastructure_spec:type_name -> google.events.cloud.dataplex.v1.Task.InfrastructureSpec
	96,  // 137: google.events.cloud.dataplex.v1.Task.NotebookTaskConfig.infrastructure_spec:type_name -> google.events.cloud.dataplex.v1.Task.InfrastructureSpec
	108, // 138: google.events.cloud.dataplex.v1.Task.ExecutionStatus.update_time:type_name -> google.protobuf.Timestamp
	36,  // 139: google.events.cloud.dataplex.v1.Task.ExecutionStatus.latest_job:type_name -> google.events.cloud.dataplex.v1.Job
	106, // 140: google.events.cloud.dataplex.v1.Task.InfrastructureSpec.ContainerImageRuntime.properties:type_name -> google.events.cloud.dataplex.v1.Task.InfrastructureSpec.ContainerImageRuntime.PropertiesEntry
	141, // [141:141] is the sub-list for method output_type
	141, // [141:141] is the sub-list for method input_type
	141, // [141:141] is the sub-list for extension type_name
	141, // [141:141] is the sub-list for extension extendee
	0,   // [0:141] is the sub-list for field type_name
}

func init() { file_cloud_dataplex_v1_data_proto_init() }
func file_cloud_dataplex_v1_data_proto_init() {
	if File_cloud_dataplex_v1_data_proto != nil {
		return
	}
	file_cloud_dataplex_v1_data_proto_msgTypes[5].OneofWrappers = []any{
		(*Trigger_OnDemand_)(nil),
		(*Trigger_Schedule_)(nil),
	}
	file_cloud_dataplex_v1_data_proto_msgTypes[6].OneofWrappers = []any{
		(*DataSource_Entity)(nil),
	}
	file_cloud_dataplex_v1_data_proto_msgTypes[7].OneofWrappers = []any{
		(*ScannedData_IncrementalField_)(nil),
	}
	file_cloud_dataplex_v1_data_proto_msgTypes[14].OneofWrappers = []any{
		(*DataQualityRule_RangeExpectation_)(nil),
		(*DataQualityRule_NonNullExpectation_)(nil),
		(*DataQualityRule_SetExpectation_)(nil),
		(*DataQualityRule_RegexExpectation_)(nil),
		(*DataQualityRule_UniquenessExpectation_)(nil),
		(*DataQualityRule_StatisticRangeExpectation_)(nil),
		(*DataQualityRule_RowConditionExpectation_)(nil),
		(*DataQualityRule_TableConditionExpectation_)(nil),
	}
	file_cloud_dataplex_v1_data_proto_msgTypes[19].OneofWrappers = []any{
		(*DataAttributeBinding_Resource)(nil),
	}
	file_cloud_dataplex_v1_data_proto_msgTypes[20].OneofWrappers = []any{
		(*DataScan_DataQualitySpec)(nil),
		(*DataScan_DataProfileSpec)(nil),
		(*DataScan_DataQualityResult)(nil),
		(*DataScan_DataProfileResult)(nil),
	}
	file_cloud_dataplex_v1_data_proto_msgTypes[21].OneofWrappers = []any{
		(*Task_Spark)(nil),
		(*Task_Notebook)(nil),
	}
	file_cloud_dataplex_v1_data_proto_msgTypes[23].OneofWrappers = []any{}
	file_cloud_dataplex_v1_data_proto_msgTypes[24].OneofWrappers = []any{}
	file_cloud_dataplex_v1_data_proto_msgTypes[25].OneofWrappers = []any{}
	file_cloud_dataplex_v1_data_proto_msgTypes[26].OneofWrappers = []any{}
	file_cloud_dataplex_v1_data_proto_msgTypes[27].OneofWrappers = []any{}
	file_cloud_dataplex_v1_data_proto_msgTypes[28].OneofWrappers = []any{}
	file_cloud_dataplex_v1_data_proto_msgTypes[29].OneofWrappers = []any{}
	file_cloud_dataplex_v1_data_proto_msgTypes[30].OneofWrappers = []any{}
	file_cloud_dataplex_v1_data_proto_msgTypes[31].OneofWrappers = []any{}
	file_cloud_dataplex_v1_data_proto_msgTypes[36].OneofWrappers = []any{
		(*Zone_DiscoverySpec_Schedule)(nil),
	}
	file_cloud_dataplex_v1_data_proto_msgTypes[41].OneofWrappers = []any{
		(*Asset_DiscoverySpec_Schedule)(nil),
	}
	file_cloud_dataplex_v1_data_proto_msgTypes[49].OneofWrappers = []any{
		(*Environment_InfrastructureSpec_Compute)(nil),
		(*Environment_InfrastructureSpec_OsImage)(nil),
	}
	file_cloud_dataplex_v1_data_proto_msgTypes[62].OneofWrappers = []any{
		(*DataProfileResult_Profile_Field_ProfileInfo_StringProfile)(nil),
		(*DataProfileResult_Profile_Field_ProfileInfo_IntegerProfile)(nil),
		(*DataProfileResult_Profile_Field_ProfileInfo_DoubleProfile)(nil),
	}
	file_cloud_dataplex_v1_data_proto_msgTypes[79].OneofWrappers = []any{
		(*DataScan_ExecutionSpec_Field)(nil),
	}
	file_cloud_dataplex_v1_data_proto_msgTypes[82].OneofWrappers = []any{
		(*Task_InfrastructureSpec_Batch)(nil),
		(*Task_InfrastructureSpec_ContainerImage)(nil),
		(*Task_InfrastructureSpec_VpcNetwork_)(nil),
	}
	file_cloud_dataplex_v1_data_proto_msgTypes[83].OneofWrappers = []any{
		(*Task_TriggerSpec_Schedule)(nil),
	}
	file_cloud_dataplex_v1_data_proto_msgTypes[85].OneofWrappers = []any{
		(*Task_SparkTaskConfig_MainJarFileUri)(nil),
		(*Task_SparkTaskConfig_MainClass)(nil),
		(*Task_SparkTaskConfig_PythonScriptFile)(nil),
		(*Task_SparkTaskConfig_SqlScriptFile)(nil),
		(*Task_SparkTaskConfig_SqlScript)(nil),
	}
	file_cloud_dataplex_v1_data_proto_msgTypes[91].OneofWrappers = []any{
		(*Task_InfrastructureSpec_VpcNetwork_Network)(nil),
		(*Task_InfrastructureSpec_VpcNetwork_SubNetwork)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_cloud_dataplex_v1_data_proto_rawDesc), len(file_cloud_dataplex_v1_data_proto_rawDesc)),
			NumEnums:      14,
			NumMessages:   94,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_cloud_dataplex_v1_data_proto_goTypes,
		DependencyIndexes: file_cloud_dataplex_v1_data_proto_depIdxs,
		EnumInfos:         file_cloud_dataplex_v1_data_proto_enumTypes,
		MessageInfos:      file_cloud_dataplex_v1_data_proto_msgTypes,
	}.Build()
	File_cloud_dataplex_v1_data_proto = out.File
	file_cloud_dataplex_v1_data_proto_goTypes = nil
	file_cloud_dataplex_v1_data_proto_depIdxs = nil
}
