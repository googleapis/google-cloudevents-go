// Copyright 2023 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.8
// 	protoc        v3.21.6
// source: cloud/video/transcoder/v1/data.proto

package transcoderdata

import (
	status "google.golang.org/genproto/googleapis/rpc/status"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	durationpb "google.golang.org/protobuf/types/known/durationpb"
	timestamppb "google.golang.org/protobuf/types/known/timestamppb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// The current state of the job.
type Job_ProcessingState int32

const (
	// The processing state is not specified.
	Job_PROCESSING_STATE_UNSPECIFIED Job_ProcessingState = 0
	// The job is enqueued and will be picked up for processing soon.
	Job_PENDING Job_ProcessingState = 1
	// The job is being processed.
	Job_RUNNING Job_ProcessingState = 2
	// The job has been completed successfully.
	Job_SUCCEEDED Job_ProcessingState = 3
	// The job has failed. For additional information, see `failure_reason` and
	// `failure_details`
	Job_FAILED Job_ProcessingState = 4
)

// Enum value maps for Job_ProcessingState.
var (
	Job_ProcessingState_name = map[int32]string{
		0: "PROCESSING_STATE_UNSPECIFIED",
		1: "PENDING",
		2: "RUNNING",
		3: "SUCCEEDED",
		4: "FAILED",
	}
	Job_ProcessingState_value = map[string]int32{
		"PROCESSING_STATE_UNSPECIFIED": 0,
		"PENDING":                      1,
		"RUNNING":                      2,
		"SUCCEEDED":                    3,
		"FAILED":                       4,
	}
)

func (x Job_ProcessingState) Enum() *Job_ProcessingState {
	p := new(Job_ProcessingState)
	*p = x
	return p
}

func (x Job_ProcessingState) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Job_ProcessingState) Descriptor() protoreflect.EnumDescriptor {
	return file_cloud_video_transcoder_v1_data_proto_enumTypes[0].Descriptor()
}

func (Job_ProcessingState) Type() protoreflect.EnumType {
	return &file_cloud_video_transcoder_v1_data_proto_enumTypes[0]
}

func (x Job_ProcessingState) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Job_ProcessingState.Descriptor instead.
func (Job_ProcessingState) EnumDescriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{0, 0}
}

// The processing mode of the job.
type Job_ProcessingMode int32

const (
	// The job processing mode is not specified.
	Job_PROCESSING_MODE_UNSPECIFIED Job_ProcessingMode = 0
	// The job processing mode is interactive mode.
	// Interactive job will either be ran or rejected if quota does not allow
	// for it.
	Job_PROCESSING_MODE_INTERACTIVE Job_ProcessingMode = 1
	// The job processing mode is batch mode.
	// Batch mode allows queuing of jobs.
	Job_PROCESSING_MODE_BATCH Job_ProcessingMode = 2
)

// Enum value maps for Job_ProcessingMode.
var (
	Job_ProcessingMode_name = map[int32]string{
		0: "PROCESSING_MODE_UNSPECIFIED",
		1: "PROCESSING_MODE_INTERACTIVE",
		2: "PROCESSING_MODE_BATCH",
	}
	Job_ProcessingMode_value = map[string]int32{
		"PROCESSING_MODE_UNSPECIFIED": 0,
		"PROCESSING_MODE_INTERACTIVE": 1,
		"PROCESSING_MODE_BATCH":       2,
	}
)

func (x Job_ProcessingMode) Enum() *Job_ProcessingMode {
	p := new(Job_ProcessingMode)
	*p = x
	return p
}

func (x Job_ProcessingMode) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Job_ProcessingMode) Descriptor() protoreflect.EnumDescriptor {
	return file_cloud_video_transcoder_v1_data_proto_enumTypes[1].Descriptor()
}

func (Job_ProcessingMode) Type() protoreflect.EnumType {
	return &file_cloud_video_transcoder_v1_data_proto_enumTypes[1]
}

func (x Job_ProcessingMode) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Job_ProcessingMode.Descriptor instead.
func (Job_ProcessingMode) EnumDescriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{0, 1}
}

// The manifest type, which corresponds to the adaptive streaming format used.
type Manifest_ManifestType int32

const (
	// The manifest type is not specified.
	Manifest_MANIFEST_TYPE_UNSPECIFIED Manifest_ManifestType = 0
	// Create an HLS manifest. The corresponding file extension is `.m3u8`.
	Manifest_HLS Manifest_ManifestType = 1
	// Create an MPEG-DASH manifest. The corresponding file extension is `.mpd`.
	Manifest_DASH Manifest_ManifestType = 2
)

// Enum value maps for Manifest_ManifestType.
var (
	Manifest_ManifestType_name = map[int32]string{
		0: "MANIFEST_TYPE_UNSPECIFIED",
		1: "HLS",
		2: "DASH",
	}
	Manifest_ManifestType_value = map[string]int32{
		"MANIFEST_TYPE_UNSPECIFIED": 0,
		"HLS":                       1,
		"DASH":                      2,
	}
)

func (x Manifest_ManifestType) Enum() *Manifest_ManifestType {
	p := new(Manifest_ManifestType)
	*p = x
	return p
}

func (x Manifest_ManifestType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Manifest_ManifestType) Descriptor() protoreflect.EnumDescriptor {
	return file_cloud_video_transcoder_v1_data_proto_enumTypes[2].Descriptor()
}

func (Manifest_ManifestType) Type() protoreflect.EnumType {
	return &file_cloud_video_transcoder_v1_data_proto_enumTypes[2]
}

func (x Manifest_ManifestType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Manifest_ManifestType.Descriptor instead.
func (Manifest_ManifestType) EnumDescriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{9, 0}
}

// Fade type for the overlay: `FADE_IN` or `FADE_OUT`.
type Overlay_FadeType int32

const (
	// The fade type is not specified.
	Overlay_FADE_TYPE_UNSPECIFIED Overlay_FadeType = 0
	// Fade the overlay object into view.
	Overlay_FADE_IN Overlay_FadeType = 1
	// Fade the overlay object out of view.
	Overlay_FADE_OUT Overlay_FadeType = 2
)

// Enum value maps for Overlay_FadeType.
var (
	Overlay_FadeType_name = map[int32]string{
		0: "FADE_TYPE_UNSPECIFIED",
		1: "FADE_IN",
		2: "FADE_OUT",
	}
	Overlay_FadeType_value = map[string]int32{
		"FADE_TYPE_UNSPECIFIED": 0,
		"FADE_IN":               1,
		"FADE_OUT":              2,
	}
)

func (x Overlay_FadeType) Enum() *Overlay_FadeType {
	p := new(Overlay_FadeType)
	*p = x
	return p
}

func (x Overlay_FadeType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (Overlay_FadeType) Descriptor() protoreflect.EnumDescriptor {
	return file_cloud_video_transcoder_v1_data_proto_enumTypes[3].Descriptor()
}

func (Overlay_FadeType) Type() protoreflect.EnumType {
	return &file_cloud_video_transcoder_v1_data_proto_enumTypes[3]
}

func (x Overlay_FadeType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use Overlay_FadeType.Descriptor instead.
func (Overlay_FadeType) EnumDescriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{12, 0}
}

// Transcoding job resource.
type Job struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The resource name of the job.
	// Format: `projects/{project_number}/locations/{location}/jobs/{job}`
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// Specify the `job_config` for the transcoding job. If you don't specify the
	// `job_config`, the API selects `templateId`; this template ID is set to
	// `preset/web-hd` by default. When you use a `template_id` to create a job,
	// the `Job.config` is populated by the `JobTemplate.config`.<br>
	//
	// Types that are valid to be assigned to JobConfig:
	//
	//	*Job_Config
	JobConfig isJob_JobConfig `protobuf_oneof:"job_config"`
	// Output only. The current state of the job.
	State Job_ProcessingState `protobuf:"varint,8,opt,name=state,proto3,enum=google.events.cloud.video.transcoder.v1.Job_ProcessingState" json:"state,omitempty"`
	// Output only. The time the job was created.
	CreateTime *timestamppb.Timestamp `protobuf:"bytes,12,opt,name=create_time,json=createTime,proto3" json:"create_time,omitempty"`
	// Output only. The time the transcoding started.
	StartTime *timestamppb.Timestamp `protobuf:"bytes,13,opt,name=start_time,json=startTime,proto3" json:"start_time,omitempty"`
	// Output only. The time the transcoding finished.
	EndTime *timestamppb.Timestamp `protobuf:"bytes,14,opt,name=end_time,json=endTime,proto3" json:"end_time,omitempty"`
	// Job time to live value in days, which will be effective after job
	// completion. Job should be deleted automatically after the given TTL. Enter
	// a value between 1 and 90. The default is 30.
	TtlAfterCompletionDays int32 `protobuf:"varint,15,opt,name=ttl_after_completion_days,json=ttlAfterCompletionDays,proto3" json:"ttl_after_completion_days,omitempty"`
	// The labels associated with this job. You can use these to organize and
	// group your jobs.
	Labels map[string]string `protobuf:"bytes,16,rep,name=labels,proto3" json:"labels,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	// Output only. An error object that describes the reason for the failure.
	// This property is always present when `state` is `FAILED`.
	Error *status.Status `protobuf:"bytes,17,opt,name=error,proto3" json:"error,omitempty"`
	// The processing mode of the job.
	// The default is `PROCESSING_MODE_INTERACTIVE`.
	Mode          Job_ProcessingMode `protobuf:"varint,20,opt,name=mode,proto3,enum=google.events.cloud.video.transcoder.v1.Job_ProcessingMode" json:"mode,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Job) Reset() {
	*x = Job{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Job) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Job) ProtoMessage() {}

func (x *Job) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Job.ProtoReflect.Descriptor instead.
func (*Job) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{0}
}

func (x *Job) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *Job) GetJobConfig() isJob_JobConfig {
	if x != nil {
		return x.JobConfig
	}
	return nil
}

func (x *Job) GetConfig() *JobConfig {
	if x != nil {
		if x, ok := x.JobConfig.(*Job_Config); ok {
			return x.Config
		}
	}
	return nil
}

func (x *Job) GetState() Job_ProcessingState {
	if x != nil {
		return x.State
	}
	return Job_PROCESSING_STATE_UNSPECIFIED
}

func (x *Job) GetCreateTime() *timestamppb.Timestamp {
	if x != nil {
		return x.CreateTime
	}
	return nil
}

func (x *Job) GetStartTime() *timestamppb.Timestamp {
	if x != nil {
		return x.StartTime
	}
	return nil
}

func (x *Job) GetEndTime() *timestamppb.Timestamp {
	if x != nil {
		return x.EndTime
	}
	return nil
}

func (x *Job) GetTtlAfterCompletionDays() int32 {
	if x != nil {
		return x.TtlAfterCompletionDays
	}
	return 0
}

func (x *Job) GetLabels() map[string]string {
	if x != nil {
		return x.Labels
	}
	return nil
}

func (x *Job) GetError() *status.Status {
	if x != nil {
		return x.Error
	}
	return nil
}

func (x *Job) GetMode() Job_ProcessingMode {
	if x != nil {
		return x.Mode
	}
	return Job_PROCESSING_MODE_UNSPECIFIED
}

type isJob_JobConfig interface {
	isJob_JobConfig()
}

type Job_Config struct {
	// The configuration for this job.
	Config *JobConfig `protobuf:"bytes,5,opt,name=config,proto3,oneof"`
}

func (*Job_Config) isJob_JobConfig() {}

// Transcoding job template resource.
type JobTemplate struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The resource name of the job template.
	// Format:
	// `projects/{project_number}/locations/{location}/jobTemplates/{job_template}`
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// The configuration for this template.
	Config *JobConfig `protobuf:"bytes,2,opt,name=config,proto3" json:"config,omitempty"`
	// The labels associated with this job template. You can use these to organize
	// and group your job templates.
	Labels        map[string]string `protobuf:"bytes,3,rep,name=labels,proto3" json:"labels,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *JobTemplate) Reset() {
	*x = JobTemplate{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *JobTemplate) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*JobTemplate) ProtoMessage() {}

func (x *JobTemplate) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use JobTemplate.ProtoReflect.Descriptor instead.
func (*JobTemplate) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{1}
}

func (x *JobTemplate) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *JobTemplate) GetConfig() *JobConfig {
	if x != nil {
		return x.Config
	}
	return nil
}

func (x *JobTemplate) GetLabels() map[string]string {
	if x != nil {
		return x.Labels
	}
	return nil
}

// Job configuration
type JobConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// List of input assets stored in Cloud Storage.
	Inputs []*Input `protobuf:"bytes,1,rep,name=inputs,proto3" json:"inputs,omitempty"`
	// List of `Edit atom`s. Defines the ultimate timeline of the resulting
	// file or manifest.
	EditList []*EditAtom `protobuf:"bytes,2,rep,name=edit_list,json=editList,proto3" json:"edit_list,omitempty"`
	// List of elementary streams.
	ElementaryStreams []*ElementaryStream `protobuf:"bytes,3,rep,name=elementary_streams,json=elementaryStreams,proto3" json:"elementary_streams,omitempty"`
	// List of multiplexing settings for output streams.
	MuxStreams []*MuxStream `protobuf:"bytes,4,rep,name=mux_streams,json=muxStreams,proto3" json:"mux_streams,omitempty"`
	// List of output manifests.
	Manifests []*Manifest `protobuf:"bytes,5,rep,name=manifests,proto3" json:"manifests,omitempty"`
	// Output configuration.
	Output *Output `protobuf:"bytes,6,opt,name=output,proto3" json:"output,omitempty"`
	// List of ad breaks. Specifies where to insert ad break tags in the output
	// manifests.
	AdBreaks []*AdBreak `protobuf:"bytes,7,rep,name=ad_breaks,json=adBreaks,proto3" json:"ad_breaks,omitempty"`
	// Destination on Pub/Sub.
	PubsubDestination *PubsubDestination `protobuf:"bytes,8,opt,name=pubsub_destination,json=pubsubDestination,proto3" json:"pubsub_destination,omitempty"`
	// List of output sprite sheets.
	// Spritesheets require at least one VideoStream in the Jobconfig.
	SpriteSheets []*SpriteSheet `protobuf:"bytes,9,rep,name=sprite_sheets,json=spriteSheets,proto3" json:"sprite_sheets,omitempty"`
	// List of overlays on the output video, in descending Z-order.
	Overlays      []*Overlay `protobuf:"bytes,10,rep,name=overlays,proto3" json:"overlays,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *JobConfig) Reset() {
	*x = JobConfig{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *JobConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*JobConfig) ProtoMessage() {}

func (x *JobConfig) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use JobConfig.ProtoReflect.Descriptor instead.
func (*JobConfig) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{2}
}

func (x *JobConfig) GetInputs() []*Input {
	if x != nil {
		return x.Inputs
	}
	return nil
}

func (x *JobConfig) GetEditList() []*EditAtom {
	if x != nil {
		return x.EditList
	}
	return nil
}

func (x *JobConfig) GetElementaryStreams() []*ElementaryStream {
	if x != nil {
		return x.ElementaryStreams
	}
	return nil
}

func (x *JobConfig) GetMuxStreams() []*MuxStream {
	if x != nil {
		return x.MuxStreams
	}
	return nil
}

func (x *JobConfig) GetManifests() []*Manifest {
	if x != nil {
		return x.Manifests
	}
	return nil
}

func (x *JobConfig) GetOutput() *Output {
	if x != nil {
		return x.Output
	}
	return nil
}

func (x *JobConfig) GetAdBreaks() []*AdBreak {
	if x != nil {
		return x.AdBreaks
	}
	return nil
}

func (x *JobConfig) GetPubsubDestination() *PubsubDestination {
	if x != nil {
		return x.PubsubDestination
	}
	return nil
}

func (x *JobConfig) GetSpriteSheets() []*SpriteSheet {
	if x != nil {
		return x.SpriteSheets
	}
	return nil
}

func (x *JobConfig) GetOverlays() []*Overlay {
	if x != nil {
		return x.Overlays
	}
	return nil
}

// Input asset.
type Input struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// A unique key for this input. Must be specified when using advanced
	// mapping and edit lists.
	Key string `protobuf:"bytes,1,opt,name=key,proto3" json:"key,omitempty"`
	// URI of the media. Input files must be at least 5 seconds in duration and
	// stored in Cloud Storage (for example, `gs://bucket/inputs/file.mp4`).
	// If empty, the value is populated from `Job.input_uri`. See
	// [Supported input and output
	// formats](https://cloud.google.com/transcoder/docs/concepts/supported-input-and-output-formats).
	Uri string `protobuf:"bytes,2,opt,name=uri,proto3" json:"uri,omitempty"`
	// Preprocessing configurations.
	PreprocessingConfig *PreprocessingConfig `protobuf:"bytes,3,opt,name=preprocessing_config,json=preprocessingConfig,proto3" json:"preprocessing_config,omitempty"`
	unknownFields       protoimpl.UnknownFields
	sizeCache           protoimpl.SizeCache
}

func (x *Input) Reset() {
	*x = Input{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Input) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Input) ProtoMessage() {}

func (x *Input) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Input.ProtoReflect.Descriptor instead.
func (*Input) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{3}
}

func (x *Input) GetKey() string {
	if x != nil {
		return x.Key
	}
	return ""
}

func (x *Input) GetUri() string {
	if x != nil {
		return x.Uri
	}
	return ""
}

func (x *Input) GetPreprocessingConfig() *PreprocessingConfig {
	if x != nil {
		return x.PreprocessingConfig
	}
	return nil
}

// Location of output file(s) in a Cloud Storage bucket.
type Output struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// URI for the output file(s). For example, `gs://my-bucket/outputs/`.
	// If empty, the value is populated from `Job.output_uri`. See
	// [Supported input and output
	// formats](https://cloud.google.com/transcoder/docs/concepts/supported-input-and-output-formats).
	Uri           string `protobuf:"bytes,1,opt,name=uri,proto3" json:"uri,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Output) Reset() {
	*x = Output{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Output) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Output) ProtoMessage() {}

func (x *Output) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Output.ProtoReflect.Descriptor instead.
func (*Output) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{4}
}

func (x *Output) GetUri() string {
	if x != nil {
		return x.Uri
	}
	return ""
}

// Edit atom.
type EditAtom struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// A unique key for this atom. Must be specified when using advanced
	// mapping.
	Key string `protobuf:"bytes,1,opt,name=key,proto3" json:"key,omitempty"`
	// List of `Input.key`s identifying files that should be used in this atom.
	// The listed `inputs` must have the same timeline.
	Inputs []string `protobuf:"bytes,2,rep,name=inputs,proto3" json:"inputs,omitempty"`
	// End time in seconds for the atom, relative to the input file timeline.
	// When `end_time_offset` is not specified, the `inputs` are used until
	// the end of the atom.
	EndTimeOffset *durationpb.Duration `protobuf:"bytes,3,opt,name=end_time_offset,json=endTimeOffset,proto3" json:"end_time_offset,omitempty"`
	// Start time in seconds for the atom, relative to the input file timeline.
	// The default is `0s`.
	StartTimeOffset *durationpb.Duration `protobuf:"bytes,4,opt,name=start_time_offset,json=startTimeOffset,proto3" json:"start_time_offset,omitempty"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *EditAtom) Reset() {
	*x = EditAtom{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *EditAtom) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*EditAtom) ProtoMessage() {}

func (x *EditAtom) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use EditAtom.ProtoReflect.Descriptor instead.
func (*EditAtom) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{5}
}

func (x *EditAtom) GetKey() string {
	if x != nil {
		return x.Key
	}
	return ""
}

func (x *EditAtom) GetInputs() []string {
	if x != nil {
		return x.Inputs
	}
	return nil
}

func (x *EditAtom) GetEndTimeOffset() *durationpb.Duration {
	if x != nil {
		return x.EndTimeOffset
	}
	return nil
}

func (x *EditAtom) GetStartTimeOffset() *durationpb.Duration {
	if x != nil {
		return x.StartTimeOffset
	}
	return nil
}

// Ad break.
type AdBreak struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Start time in seconds for the ad break, relative to the output file
	// timeline. The default is `0s`.
	StartTimeOffset *durationpb.Duration `protobuf:"bytes,1,opt,name=start_time_offset,json=startTimeOffset,proto3" json:"start_time_offset,omitempty"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *AdBreak) Reset() {
	*x = AdBreak{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AdBreak) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AdBreak) ProtoMessage() {}

func (x *AdBreak) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AdBreak.ProtoReflect.Descriptor instead.
func (*AdBreak) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{6}
}

func (x *AdBreak) GetStartTimeOffset() *durationpb.Duration {
	if x != nil {
		return x.StartTimeOffset
	}
	return nil
}

// Encoding of an input file such as an audio, video, or text track.
// Elementary streams must be packaged before
// mapping and sharing between different output formats.
type ElementaryStream struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// A unique key for this elementary stream.
	Key string `protobuf:"bytes,4,opt,name=key,proto3" json:"key,omitempty"`
	// Encoding of an audio, video, or text track.
	//
	// Types that are valid to be assigned to ElementaryStream:
	//
	//	*ElementaryStream_VideoStream
	//	*ElementaryStream_AudioStream
	//	*ElementaryStream_TextStream
	ElementaryStream isElementaryStream_ElementaryStream `protobuf_oneof:"elementary_stream"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *ElementaryStream) Reset() {
	*x = ElementaryStream{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ElementaryStream) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ElementaryStream) ProtoMessage() {}

func (x *ElementaryStream) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ElementaryStream.ProtoReflect.Descriptor instead.
func (*ElementaryStream) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{7}
}

func (x *ElementaryStream) GetKey() string {
	if x != nil {
		return x.Key
	}
	return ""
}

func (x *ElementaryStream) GetElementaryStream() isElementaryStream_ElementaryStream {
	if x != nil {
		return x.ElementaryStream
	}
	return nil
}

func (x *ElementaryStream) GetVideoStream() *VideoStream {
	if x != nil {
		if x, ok := x.ElementaryStream.(*ElementaryStream_VideoStream); ok {
			return x.VideoStream
		}
	}
	return nil
}

func (x *ElementaryStream) GetAudioStream() *AudioStream {
	if x != nil {
		if x, ok := x.ElementaryStream.(*ElementaryStream_AudioStream); ok {
			return x.AudioStream
		}
	}
	return nil
}

func (x *ElementaryStream) GetTextStream() *TextStream {
	if x != nil {
		if x, ok := x.ElementaryStream.(*ElementaryStream_TextStream); ok {
			return x.TextStream
		}
	}
	return nil
}

type isElementaryStream_ElementaryStream interface {
	isElementaryStream_ElementaryStream()
}

type ElementaryStream_VideoStream struct {
	// Encoding of a video stream.
	VideoStream *VideoStream `protobuf:"bytes,1,opt,name=video_stream,json=videoStream,proto3,oneof"`
}

type ElementaryStream_AudioStream struct {
	// Encoding of an audio stream.
	AudioStream *AudioStream `protobuf:"bytes,2,opt,name=audio_stream,json=audioStream,proto3,oneof"`
}

type ElementaryStream_TextStream struct {
	// Encoding of a text stream. For example, closed captions or subtitles.
	TextStream *TextStream `protobuf:"bytes,3,opt,name=text_stream,json=textStream,proto3,oneof"`
}

func (*ElementaryStream_VideoStream) isElementaryStream_ElementaryStream() {}

func (*ElementaryStream_AudioStream) isElementaryStream_ElementaryStream() {}

func (*ElementaryStream_TextStream) isElementaryStream_ElementaryStream() {}

// Multiplexing settings for output stream.
type MuxStream struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// A unique key for this multiplexed stream. HLS media manifests will be
	// named `MuxStream.key` with the `.m3u8` extension suffix.
	Key string `protobuf:"bytes,1,opt,name=key,proto3" json:"key,omitempty"`
	// The name of the generated file. The default is `MuxStream.key` with the
	// extension suffix corresponding to the `MuxStream.container`.
	//
	// Individual segments also have an incremental 10-digit zero-padded suffix
	// starting from 0 before the extension, such as `mux_stream0000000123.ts`.
	FileName string `protobuf:"bytes,2,opt,name=file_name,json=fileName,proto3" json:"file_name,omitempty"`
	// The container format. The default is `mp4`
	//
	// Supported container formats:
	//
	// - `ts`
	// - `fmp4`- the corresponding file extension is `.m4s`
	// - `mp4`
	// - `vtt`
	//
	// See also:
	// [Supported input and output
	// formats](https://cloud.google.com/transcoder/docs/concepts/supported-input-and-output-formats)
	Container string `protobuf:"bytes,3,opt,name=container,proto3" json:"container,omitempty"`
	// List of `ElementaryStream.key`s multiplexed in this stream.
	ElementaryStreams []string `protobuf:"bytes,4,rep,name=elementary_streams,json=elementaryStreams,proto3" json:"elementary_streams,omitempty"`
	// Segment settings for `ts`, `fmp4` and `vtt`.
	SegmentSettings *SegmentSettings `protobuf:"bytes,5,opt,name=segment_settings,json=segmentSettings,proto3" json:"segment_settings,omitempty"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *MuxStream) Reset() {
	*x = MuxStream{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *MuxStream) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*MuxStream) ProtoMessage() {}

func (x *MuxStream) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use MuxStream.ProtoReflect.Descriptor instead.
func (*MuxStream) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{8}
}

func (x *MuxStream) GetKey() string {
	if x != nil {
		return x.Key
	}
	return ""
}

func (x *MuxStream) GetFileName() string {
	if x != nil {
		return x.FileName
	}
	return ""
}

func (x *MuxStream) GetContainer() string {
	if x != nil {
		return x.Container
	}
	return ""
}

func (x *MuxStream) GetElementaryStreams() []string {
	if x != nil {
		return x.ElementaryStreams
	}
	return nil
}

func (x *MuxStream) GetSegmentSettings() *SegmentSettings {
	if x != nil {
		return x.SegmentSettings
	}
	return nil
}

// Manifest configuration.
type Manifest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The name of the generated file. The default is `manifest` with the
	// extension suffix corresponding to the `Manifest.type`.
	FileName string `protobuf:"bytes,1,opt,name=file_name,json=fileName,proto3" json:"file_name,omitempty"`
	// Required. Type of the manifest.
	Type Manifest_ManifestType `protobuf:"varint,2,opt,name=type,proto3,enum=google.events.cloud.video.transcoder.v1.Manifest_ManifestType" json:"type,omitempty"`
	// Required. List of user given `MuxStream.key`s that should appear in this
	// manifest.
	//
	// When `Manifest.type` is `HLS`, a media manifest with name `MuxStream.key`
	// and `.m3u8` extension is generated for each element of the
	// `Manifest.mux_streams`.
	MuxStreams    []string `protobuf:"bytes,3,rep,name=mux_streams,json=muxStreams,proto3" json:"mux_streams,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Manifest) Reset() {
	*x = Manifest{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Manifest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Manifest) ProtoMessage() {}

func (x *Manifest) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Manifest.ProtoReflect.Descriptor instead.
func (*Manifest) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{9}
}

func (x *Manifest) GetFileName() string {
	if x != nil {
		return x.FileName
	}
	return ""
}

func (x *Manifest) GetType() Manifest_ManifestType {
	if x != nil {
		return x.Type
	}
	return Manifest_MANIFEST_TYPE_UNSPECIFIED
}

func (x *Manifest) GetMuxStreams() []string {
	if x != nil {
		return x.MuxStreams
	}
	return nil
}

// A Pub/Sub destination.
type PubsubDestination struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The name of the Pub/Sub topic to publish job completion notification
	// to. For example: `projects/{project}/topics/{topic}`.
	Topic         string `protobuf:"bytes,1,opt,name=topic,proto3" json:"topic,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PubsubDestination) Reset() {
	*x = PubsubDestination{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PubsubDestination) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PubsubDestination) ProtoMessage() {}

func (x *PubsubDestination) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PubsubDestination.ProtoReflect.Descriptor instead.
func (*PubsubDestination) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{10}
}

func (x *PubsubDestination) GetTopic() string {
	if x != nil {
		return x.Topic
	}
	return ""
}

// Sprite sheet configuration.
type SpriteSheet struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Format type. The default is `jpeg`.
	//
	// Supported formats:
	//
	// - `jpeg`
	Format string `protobuf:"bytes,1,opt,name=format,proto3" json:"format,omitempty"`
	// Required. File name prefix for the generated sprite sheets.
	//
	// Each sprite sheet has an incremental 10-digit zero-padded suffix starting
	// from 0 before the extension, such as `sprite_sheet0000000123.jpeg`.
	FilePrefix string `protobuf:"bytes,2,opt,name=file_prefix,json=filePrefix,proto3" json:"file_prefix,omitempty"`
	// Required. The width of sprite in pixels. Must be an even integer. To
	// preserve the source aspect ratio, set the
	// [SpriteSheet.sprite_width_pixels][google.cloud.video.transcoder.v1.SpriteSheet.sprite_width_pixels]
	// field or the
	// [SpriteSheet.sprite_height_pixels][google.cloud.video.transcoder.v1.SpriteSheet.sprite_height_pixels]
	// field, but not both (the API will automatically calculate the missing
	// field).
	//
	// For portrait videos that contain horizontal ASR and rotation metadata,
	// provide the width, in pixels, per the horizontal ASR. The API calculates
	// the height per the horizontal ASR. The API detects any rotation metadata
	// and swaps the requested height and width for the output.
	SpriteWidthPixels int32 `protobuf:"varint,3,opt,name=sprite_width_pixels,json=spriteWidthPixels,proto3" json:"sprite_width_pixels,omitempty"`
	// Required. The height of sprite in pixels. Must be an even integer. To
	// preserve the source aspect ratio, set the
	// [SpriteSheet.sprite_height_pixels][google.cloud.video.transcoder.v1.SpriteSheet.sprite_height_pixels]
	// field or the
	// [SpriteSheet.sprite_width_pixels][google.cloud.video.transcoder.v1.SpriteSheet.sprite_width_pixels]
	// field, but not both (the API will automatically calculate the missing
	// field).
	//
	// For portrait videos that contain horizontal ASR and rotation metadata,
	// provide the height, in pixels, per the horizontal ASR. The API calculates
	// the width per the horizontal ASR. The API detects any rotation metadata
	// and swaps the requested height and width for the output.
	SpriteHeightPixels int32 `protobuf:"varint,4,opt,name=sprite_height_pixels,json=spriteHeightPixels,proto3" json:"sprite_height_pixels,omitempty"`
	// The maximum number of sprites per row in a sprite sheet. The default is 0,
	// which indicates no maximum limit.
	ColumnCount int32 `protobuf:"varint,5,opt,name=column_count,json=columnCount,proto3" json:"column_count,omitempty"`
	// The maximum number of rows per sprite sheet. When the sprite sheet is full,
	// a new sprite sheet is created. The default is 0, which indicates no maximum
	// limit.
	RowCount int32 `protobuf:"varint,6,opt,name=row_count,json=rowCount,proto3" json:"row_count,omitempty"`
	// Start time in seconds, relative to the output file timeline. Determines the
	// first sprite to pick. The default is `0s`.
	StartTimeOffset *durationpb.Duration `protobuf:"bytes,7,opt,name=start_time_offset,json=startTimeOffset,proto3" json:"start_time_offset,omitempty"`
	// End time in seconds, relative to the output file timeline. When
	// `end_time_offset` is not specified, the sprites are generated until the end
	// of the output file.
	EndTimeOffset *durationpb.Duration `protobuf:"bytes,8,opt,name=end_time_offset,json=endTimeOffset,proto3" json:"end_time_offset,omitempty"`
	// Specify either total number of sprites or interval to create sprites.
	//
	// Types that are valid to be assigned to ExtractionStrategy:
	//
	//	*SpriteSheet_TotalCount
	//	*SpriteSheet_Interval
	ExtractionStrategy isSpriteSheet_ExtractionStrategy `protobuf_oneof:"extraction_strategy"`
	// The quality of the generated sprite sheet. Enter a value between 1
	// and 100, where 1 is the lowest quality and 100 is the highest quality.
	// The default is 100. A high quality value corresponds to a low image data
	// compression ratio.
	Quality       int32 `protobuf:"varint,11,opt,name=quality,proto3" json:"quality,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SpriteSheet) Reset() {
	*x = SpriteSheet{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpriteSheet) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpriteSheet) ProtoMessage() {}

func (x *SpriteSheet) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SpriteSheet.ProtoReflect.Descriptor instead.
func (*SpriteSheet) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{11}
}

func (x *SpriteSheet) GetFormat() string {
	if x != nil {
		return x.Format
	}
	return ""
}

func (x *SpriteSheet) GetFilePrefix() string {
	if x != nil {
		return x.FilePrefix
	}
	return ""
}

func (x *SpriteSheet) GetSpriteWidthPixels() int32 {
	if x != nil {
		return x.SpriteWidthPixels
	}
	return 0
}

func (x *SpriteSheet) GetSpriteHeightPixels() int32 {
	if x != nil {
		return x.SpriteHeightPixels
	}
	return 0
}

func (x *SpriteSheet) GetColumnCount() int32 {
	if x != nil {
		return x.ColumnCount
	}
	return 0
}

func (x *SpriteSheet) GetRowCount() int32 {
	if x != nil {
		return x.RowCount
	}
	return 0
}

func (x *SpriteSheet) GetStartTimeOffset() *durationpb.Duration {
	if x != nil {
		return x.StartTimeOffset
	}
	return nil
}

func (x *SpriteSheet) GetEndTimeOffset() *durationpb.Duration {
	if x != nil {
		return x.EndTimeOffset
	}
	return nil
}

func (x *SpriteSheet) GetExtractionStrategy() isSpriteSheet_ExtractionStrategy {
	if x != nil {
		return x.ExtractionStrategy
	}
	return nil
}

func (x *SpriteSheet) GetTotalCount() int32 {
	if x != nil {
		if x, ok := x.ExtractionStrategy.(*SpriteSheet_TotalCount); ok {
			return x.TotalCount
		}
	}
	return 0
}

func (x *SpriteSheet) GetInterval() *durationpb.Duration {
	if x != nil {
		if x, ok := x.ExtractionStrategy.(*SpriteSheet_Interval); ok {
			return x.Interval
		}
	}
	return nil
}

func (x *SpriteSheet) GetQuality() int32 {
	if x != nil {
		return x.Quality
	}
	return 0
}

type isSpriteSheet_ExtractionStrategy interface {
	isSpriteSheet_ExtractionStrategy()
}

type SpriteSheet_TotalCount struct {
	// Total number of sprites. Create the specified number of sprites
	// distributed evenly across the timeline of the output media. The default
	// is 100.
	TotalCount int32 `protobuf:"varint,9,opt,name=total_count,json=totalCount,proto3,oneof"`
}

type SpriteSheet_Interval struct {
	// Starting from `0s`, create sprites at regular intervals. Specify the
	// interval value in seconds.
	Interval *durationpb.Duration `protobuf:"bytes,10,opt,name=interval,proto3,oneof"`
}

func (*SpriteSheet_TotalCount) isSpriteSheet_ExtractionStrategy() {}

func (*SpriteSheet_Interval) isSpriteSheet_ExtractionStrategy() {}

// Overlay configuration.
type Overlay struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Image overlay.
	Image *Overlay_Image `protobuf:"bytes,1,opt,name=image,proto3" json:"image,omitempty"`
	// List of Animations. The list should be chronological, without any time
	// overlap.
	Animations    []*Overlay_Animation `protobuf:"bytes,2,rep,name=animations,proto3" json:"animations,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Overlay) Reset() {
	*x = Overlay{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Overlay) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Overlay) ProtoMessage() {}

func (x *Overlay) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Overlay.ProtoReflect.Descriptor instead.
func (*Overlay) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{12}
}

func (x *Overlay) GetImage() *Overlay_Image {
	if x != nil {
		return x.Image
	}
	return nil
}

func (x *Overlay) GetAnimations() []*Overlay_Animation {
	if x != nil {
		return x.Animations
	}
	return nil
}

// Preprocessing configurations.
type PreprocessingConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Color preprocessing configuration.
	Color *PreprocessingConfig_Color `protobuf:"bytes,1,opt,name=color,proto3" json:"color,omitempty"`
	// Denoise preprocessing configuration.
	Denoise *PreprocessingConfig_Denoise `protobuf:"bytes,2,opt,name=denoise,proto3" json:"denoise,omitempty"`
	// Deblock preprocessing configuration.
	Deblock *PreprocessingConfig_Deblock `protobuf:"bytes,3,opt,name=deblock,proto3" json:"deblock,omitempty"`
	// Audio preprocessing configuration.
	Audio *PreprocessingConfig_Audio `protobuf:"bytes,4,opt,name=audio,proto3" json:"audio,omitempty"`
	// Specify the video cropping configuration.
	Crop *PreprocessingConfig_Crop `protobuf:"bytes,5,opt,name=crop,proto3" json:"crop,omitempty"`
	// Specify the video pad filter configuration.
	Pad *PreprocessingConfig_Pad `protobuf:"bytes,6,opt,name=pad,proto3" json:"pad,omitempty"`
	// Specify the video deinterlace configuration.
	Deinterlace   *PreprocessingConfig_Deinterlace `protobuf:"bytes,7,opt,name=deinterlace,proto3" json:"deinterlace,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PreprocessingConfig) Reset() {
	*x = PreprocessingConfig{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PreprocessingConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PreprocessingConfig) ProtoMessage() {}

func (x *PreprocessingConfig) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PreprocessingConfig.ProtoReflect.Descriptor instead.
func (*PreprocessingConfig) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{13}
}

func (x *PreprocessingConfig) GetColor() *PreprocessingConfig_Color {
	if x != nil {
		return x.Color
	}
	return nil
}

func (x *PreprocessingConfig) GetDenoise() *PreprocessingConfig_Denoise {
	if x != nil {
		return x.Denoise
	}
	return nil
}

func (x *PreprocessingConfig) GetDeblock() *PreprocessingConfig_Deblock {
	if x != nil {
		return x.Deblock
	}
	return nil
}

func (x *PreprocessingConfig) GetAudio() *PreprocessingConfig_Audio {
	if x != nil {
		return x.Audio
	}
	return nil
}

func (x *PreprocessingConfig) GetCrop() *PreprocessingConfig_Crop {
	if x != nil {
		return x.Crop
	}
	return nil
}

func (x *PreprocessingConfig) GetPad() *PreprocessingConfig_Pad {
	if x != nil {
		return x.Pad
	}
	return nil
}

func (x *PreprocessingConfig) GetDeinterlace() *PreprocessingConfig_Deinterlace {
	if x != nil {
		return x.Deinterlace
	}
	return nil
}

// Video stream resource.
type VideoStream struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Codec settings can be h264, h265, or vp9.
	//
	// Types that are valid to be assigned to CodecSettings:
	//
	//	*VideoStream_H264
	//	*VideoStream_H265
	//	*VideoStream_Vp9
	CodecSettings isVideoStream_CodecSettings `protobuf_oneof:"codec_settings"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *VideoStream) Reset() {
	*x = VideoStream{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[14]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *VideoStream) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*VideoStream) ProtoMessage() {}

func (x *VideoStream) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[14]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use VideoStream.ProtoReflect.Descriptor instead.
func (*VideoStream) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{14}
}

func (x *VideoStream) GetCodecSettings() isVideoStream_CodecSettings {
	if x != nil {
		return x.CodecSettings
	}
	return nil
}

func (x *VideoStream) GetH264() *VideoStream_H264CodecSettings {
	if x != nil {
		if x, ok := x.CodecSettings.(*VideoStream_H264); ok {
			return x.H264
		}
	}
	return nil
}

func (x *VideoStream) GetH265() *VideoStream_H265CodecSettings {
	if x != nil {
		if x, ok := x.CodecSettings.(*VideoStream_H265); ok {
			return x.H265
		}
	}
	return nil
}

func (x *VideoStream) GetVp9() *VideoStream_Vp9CodecSettings {
	if x != nil {
		if x, ok := x.CodecSettings.(*VideoStream_Vp9); ok {
			return x.Vp9
		}
	}
	return nil
}

type isVideoStream_CodecSettings interface {
	isVideoStream_CodecSettings()
}

type VideoStream_H264 struct {
	// H264 codec settings.
	H264 *VideoStream_H264CodecSettings `protobuf:"bytes,1,opt,name=h264,proto3,oneof"`
}

type VideoStream_H265 struct {
	// H265 codec settings.
	H265 *VideoStream_H265CodecSettings `protobuf:"bytes,2,opt,name=h265,proto3,oneof"`
}

type VideoStream_Vp9 struct {
	// VP9 codec settings.
	Vp9 *VideoStream_Vp9CodecSettings `protobuf:"bytes,3,opt,name=vp9,proto3,oneof"`
}

func (*VideoStream_H264) isVideoStream_CodecSettings() {}

func (*VideoStream_H265) isVideoStream_CodecSettings() {}

func (*VideoStream_Vp9) isVideoStream_CodecSettings() {}

// Audio stream resource.
type AudioStream struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The codec for this audio stream. The default is `aac`.
	//
	// Supported audio codecs:
	//
	// - `aac`
	// - `aac-he`
	// - `aac-he-v2`
	// - `mp3`
	// - `ac3`
	// - `eac3`
	Codec string `protobuf:"bytes,1,opt,name=codec,proto3" json:"codec,omitempty"`
	// Required. Audio bitrate in bits per second. Must be between 1 and
	// 10,000,000.
	BitrateBps int32 `protobuf:"varint,2,opt,name=bitrate_bps,json=bitrateBps,proto3" json:"bitrate_bps,omitempty"`
	// Number of audio channels. Must be between 1 and 6. The default is 2.
	ChannelCount int32 `protobuf:"varint,3,opt,name=channel_count,json=channelCount,proto3" json:"channel_count,omitempty"`
	// A list of channel names specifying layout of the audio channels.
	// This only affects the metadata embedded in the container headers, if
	// supported by the specified format. The default is `["fl", "fr"]`.
	//
	// Supported channel names:
	//
	// - `fl` - Front left channel
	// - `fr` - Front right channel
	// - `sl` - Side left channel
	// - `sr` - Side right channel
	// - `fc` - Front center channel
	// - `lfe` - Low frequency
	ChannelLayout []string `protobuf:"bytes,4,rep,name=channel_layout,json=channelLayout,proto3" json:"channel_layout,omitempty"`
	// The mapping for the `Job.edit_list` atoms with audio `EditAtom.inputs`.
	Mapping []*AudioStream_AudioMapping `protobuf:"bytes,5,rep,name=mapping,proto3" json:"mapping,omitempty"`
	// The audio sample rate in Hertz. The default is 48000 Hertz.
	SampleRateHertz int32 `protobuf:"varint,6,opt,name=sample_rate_hertz,json=sampleRateHertz,proto3" json:"sample_rate_hertz,omitempty"`
	// The BCP-47 language code, such as `en-US` or `sr-Latn`. For more
	// information, see
	// https://www.unicode.org/reports/tr35/#Unicode_locale_identifier. Not
	// supported in MP4 files.
	LanguageCode string `protobuf:"bytes,7,opt,name=language_code,json=languageCode,proto3" json:"language_code,omitempty"`
	// The name for this particular audio stream that
	// will be added to the HLS/DASH manifest. Not supported in MP4 files.
	DisplayName   string `protobuf:"bytes,8,opt,name=display_name,json=displayName,proto3" json:"display_name,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AudioStream) Reset() {
	*x = AudioStream{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[15]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AudioStream) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AudioStream) ProtoMessage() {}

func (x *AudioStream) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[15]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AudioStream.ProtoReflect.Descriptor instead.
func (*AudioStream) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{15}
}

func (x *AudioStream) GetCodec() string {
	if x != nil {
		return x.Codec
	}
	return ""
}

func (x *AudioStream) GetBitrateBps() int32 {
	if x != nil {
		return x.BitrateBps
	}
	return 0
}

func (x *AudioStream) GetChannelCount() int32 {
	if x != nil {
		return x.ChannelCount
	}
	return 0
}

func (x *AudioStream) GetChannelLayout() []string {
	if x != nil {
		return x.ChannelLayout
	}
	return nil
}

func (x *AudioStream) GetMapping() []*AudioStream_AudioMapping {
	if x != nil {
		return x.Mapping
	}
	return nil
}

func (x *AudioStream) GetSampleRateHertz() int32 {
	if x != nil {
		return x.SampleRateHertz
	}
	return 0
}

func (x *AudioStream) GetLanguageCode() string {
	if x != nil {
		return x.LanguageCode
	}
	return ""
}

func (x *AudioStream) GetDisplayName() string {
	if x != nil {
		return x.DisplayName
	}
	return ""
}

// Encoding of a text stream. For example, closed captions or subtitles.
type TextStream struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The codec for this text stream. The default is `webvtt`.
	//
	// Supported text codecs:
	//
	// - `srt`
	// - `ttml`
	// - `cea608`
	// - `cea708`
	// - `webvtt`
	Codec string `protobuf:"bytes,1,opt,name=codec,proto3" json:"codec,omitempty"`
	// The BCP-47 language code, such as `en-US` or `sr-Latn`. For more
	// information, see
	// https://www.unicode.org/reports/tr35/#Unicode_locale_identifier. Not
	// supported in MP4 files.
	LanguageCode string `protobuf:"bytes,2,opt,name=language_code,json=languageCode,proto3" json:"language_code,omitempty"`
	// The mapping for the `Job.edit_list` atoms with text `EditAtom.inputs`.
	Mapping []*TextStream_TextMapping `protobuf:"bytes,3,rep,name=mapping,proto3" json:"mapping,omitempty"`
	// The name for this particular text stream that
	// will be added to the HLS/DASH manifest. Not supported in MP4 files.
	DisplayName   string `protobuf:"bytes,4,opt,name=display_name,json=displayName,proto3" json:"display_name,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TextStream) Reset() {
	*x = TextStream{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[16]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TextStream) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TextStream) ProtoMessage() {}

func (x *TextStream) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[16]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TextStream.ProtoReflect.Descriptor instead.
func (*TextStream) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{16}
}

func (x *TextStream) GetCodec() string {
	if x != nil {
		return x.Codec
	}
	return ""
}

func (x *TextStream) GetLanguageCode() string {
	if x != nil {
		return x.LanguageCode
	}
	return ""
}

func (x *TextStream) GetMapping() []*TextStream_TextMapping {
	if x != nil {
		return x.Mapping
	}
	return nil
}

func (x *TextStream) GetDisplayName() string {
	if x != nil {
		return x.DisplayName
	}
	return ""
}

// Segment settings for `ts`, `fmp4` and `vtt`.
type SegmentSettings struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Duration of the segments in seconds. The default is `6.0s`. Note that
	// `segmentDuration` must be greater than or equal to
	// [`gopDuration`](#videostream), and `segmentDuration` must be divisible by
	// [`gopDuration`](#videostream).
	SegmentDuration *durationpb.Duration `protobuf:"bytes,1,opt,name=segment_duration,json=segmentDuration,proto3" json:"segment_duration,omitempty"`
	// Required. Create an individual segment file. The default is `false`.
	IndividualSegments bool `protobuf:"varint,3,opt,name=individual_segments,json=individualSegments,proto3" json:"individual_segments,omitempty"`
	unknownFields      protoimpl.UnknownFields
	sizeCache          protoimpl.SizeCache
}

func (x *SegmentSettings) Reset() {
	*x = SegmentSettings{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[17]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SegmentSettings) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SegmentSettings) ProtoMessage() {}

func (x *SegmentSettings) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[17]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SegmentSettings.ProtoReflect.Descriptor instead.
func (*SegmentSettings) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{17}
}

func (x *SegmentSettings) GetSegmentDuration() *durationpb.Duration {
	if x != nil {
		return x.SegmentDuration
	}
	return nil
}

func (x *SegmentSettings) GetIndividualSegments() bool {
	if x != nil {
		return x.IndividualSegments
	}
	return false
}

// The data within all Job events.
type JobEventData struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The Job event payload. Unset for deletion events.
	Payload       *Job `protobuf:"bytes,1,opt,name=payload,proto3,oneof" json:"payload,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *JobEventData) Reset() {
	*x = JobEventData{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[18]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *JobEventData) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*JobEventData) ProtoMessage() {}

func (x *JobEventData) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[18]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use JobEventData.ProtoReflect.Descriptor instead.
func (*JobEventData) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{18}
}

func (x *JobEventData) GetPayload() *Job {
	if x != nil {
		return x.Payload
	}
	return nil
}

// The data within all JobTemplate events.
type JobTemplateEventData struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Optional. The JobTemplate event payload. Unset for deletion events.
	Payload       *JobTemplate `protobuf:"bytes,1,opt,name=payload,proto3,oneof" json:"payload,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *JobTemplateEventData) Reset() {
	*x = JobTemplateEventData{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[19]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *JobTemplateEventData) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*JobTemplateEventData) ProtoMessage() {}

func (x *JobTemplateEventData) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[19]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use JobTemplateEventData.ProtoReflect.Descriptor instead.
func (*JobTemplateEventData) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{19}
}

func (x *JobTemplateEventData) GetPayload() *JobTemplate {
	if x != nil {
		return x.Payload
	}
	return nil
}

// 2D normalized coordinates. Default: `{0.0, 0.0}`
type Overlay_NormalizedCoordinate struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Normalized x coordinate.
	X float64 `protobuf:"fixed64,1,opt,name=x,proto3" json:"x,omitempty"`
	// Normalized y coordinate.
	Y             float64 `protobuf:"fixed64,2,opt,name=y,proto3" json:"y,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Overlay_NormalizedCoordinate) Reset() {
	*x = Overlay_NormalizedCoordinate{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[22]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Overlay_NormalizedCoordinate) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Overlay_NormalizedCoordinate) ProtoMessage() {}

func (x *Overlay_NormalizedCoordinate) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[22]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Overlay_NormalizedCoordinate.ProtoReflect.Descriptor instead.
func (*Overlay_NormalizedCoordinate) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{12, 0}
}

func (x *Overlay_NormalizedCoordinate) GetX() float64 {
	if x != nil {
		return x.X
	}
	return 0
}

func (x *Overlay_NormalizedCoordinate) GetY() float64 {
	if x != nil {
		return x.Y
	}
	return 0
}

// Overlaid image.
type Overlay_Image struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Required. URI of the image in Cloud Storage. For example,
	// `gs://bucket/inputs/image.png`. Only PNG and JPEG images are supported.
	Uri string `protobuf:"bytes,1,opt,name=uri,proto3" json:"uri,omitempty"`
	// Normalized image resolution, based on output video resolution. Valid
	// values: `0.0`–`1.0`. To respect the original image aspect ratio, set
	// either `x` or `y` to `0.0`. To use the original image resolution, set
	// both `x` and `y` to `0.0`.
	Resolution *Overlay_NormalizedCoordinate `protobuf:"bytes,2,opt,name=resolution,proto3" json:"resolution,omitempty"`
	// Target image opacity. Valid values are from  `1.0` (solid, default) to
	// `0.0` (transparent), exclusive. Set this to a value greater than `0.0`.
	Alpha         float64 `protobuf:"fixed64,3,opt,name=alpha,proto3" json:"alpha,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Overlay_Image) Reset() {
	*x = Overlay_Image{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[23]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Overlay_Image) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Overlay_Image) ProtoMessage() {}

func (x *Overlay_Image) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[23]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Overlay_Image.ProtoReflect.Descriptor instead.
func (*Overlay_Image) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{12, 1}
}

func (x *Overlay_Image) GetUri() string {
	if x != nil {
		return x.Uri
	}
	return ""
}

func (x *Overlay_Image) GetResolution() *Overlay_NormalizedCoordinate {
	if x != nil {
		return x.Resolution
	}
	return nil
}

func (x *Overlay_Image) GetAlpha() float64 {
	if x != nil {
		return x.Alpha
	}
	return 0
}

// Display static overlay object.
type Overlay_AnimationStatic struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Normalized coordinates based on output video resolution. Valid
	// values: `0.0`–`1.0`. `xy` is the upper-left coordinate of the overlay
	// object. For example, use the x and y coordinates {0,0} to position the
	// top-left corner of the overlay animation in the top-left corner of the
	// output video.
	Xy *Overlay_NormalizedCoordinate `protobuf:"bytes,1,opt,name=xy,proto3" json:"xy,omitempty"`
	// The time to start displaying the overlay object, in seconds. Default: 0
	StartTimeOffset *durationpb.Duration `protobuf:"bytes,2,opt,name=start_time_offset,json=startTimeOffset,proto3" json:"start_time_offset,omitempty"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *Overlay_AnimationStatic) Reset() {
	*x = Overlay_AnimationStatic{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[24]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Overlay_AnimationStatic) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Overlay_AnimationStatic) ProtoMessage() {}

func (x *Overlay_AnimationStatic) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[24]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Overlay_AnimationStatic.ProtoReflect.Descriptor instead.
func (*Overlay_AnimationStatic) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{12, 2}
}

func (x *Overlay_AnimationStatic) GetXy() *Overlay_NormalizedCoordinate {
	if x != nil {
		return x.Xy
	}
	return nil
}

func (x *Overlay_AnimationStatic) GetStartTimeOffset() *durationpb.Duration {
	if x != nil {
		return x.StartTimeOffset
	}
	return nil
}

// Display overlay object with fade animation.
type Overlay_AnimationFade struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Required. Type of fade animation: `FADE_IN` or `FADE_OUT`.
	FadeType Overlay_FadeType `protobuf:"varint,1,opt,name=fade_type,json=fadeType,proto3,enum=google.events.cloud.video.transcoder.v1.Overlay_FadeType" json:"fade_type,omitempty"`
	// Normalized coordinates based on output video resolution. Valid
	// values: `0.0`–`1.0`. `xy` is the upper-left coordinate of the overlay
	// object. For example, use the x and y coordinates {0,0} to position the
	// top-left corner of the overlay animation in the top-left corner of the
	// output video.
	Xy *Overlay_NormalizedCoordinate `protobuf:"bytes,2,opt,name=xy,proto3" json:"xy,omitempty"`
	// The time to start the fade animation, in seconds. Default: 0
	StartTimeOffset *durationpb.Duration `protobuf:"bytes,3,opt,name=start_time_offset,json=startTimeOffset,proto3" json:"start_time_offset,omitempty"`
	// The time to end the fade animation, in seconds. Default:
	// `start_time_offset` + 1s
	EndTimeOffset *durationpb.Duration `protobuf:"bytes,4,opt,name=end_time_offset,json=endTimeOffset,proto3" json:"end_time_offset,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Overlay_AnimationFade) Reset() {
	*x = Overlay_AnimationFade{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[25]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Overlay_AnimationFade) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Overlay_AnimationFade) ProtoMessage() {}

func (x *Overlay_AnimationFade) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[25]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Overlay_AnimationFade.ProtoReflect.Descriptor instead.
func (*Overlay_AnimationFade) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{12, 3}
}

func (x *Overlay_AnimationFade) GetFadeType() Overlay_FadeType {
	if x != nil {
		return x.FadeType
	}
	return Overlay_FADE_TYPE_UNSPECIFIED
}

func (x *Overlay_AnimationFade) GetXy() *Overlay_NormalizedCoordinate {
	if x != nil {
		return x.Xy
	}
	return nil
}

func (x *Overlay_AnimationFade) GetStartTimeOffset() *durationpb.Duration {
	if x != nil {
		return x.StartTimeOffset
	}
	return nil
}

func (x *Overlay_AnimationFade) GetEndTimeOffset() *durationpb.Duration {
	if x != nil {
		return x.EndTimeOffset
	}
	return nil
}

// End previous overlay animation from the video. Without AnimationEnd, the
// overlay object will keep the state of previous animation until the end of
// the video.
type Overlay_AnimationEnd struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The time to end overlay object, in seconds. Default: 0
	StartTimeOffset *durationpb.Duration `protobuf:"bytes,1,opt,name=start_time_offset,json=startTimeOffset,proto3" json:"start_time_offset,omitempty"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *Overlay_AnimationEnd) Reset() {
	*x = Overlay_AnimationEnd{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[26]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Overlay_AnimationEnd) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Overlay_AnimationEnd) ProtoMessage() {}

func (x *Overlay_AnimationEnd) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[26]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Overlay_AnimationEnd.ProtoReflect.Descriptor instead.
func (*Overlay_AnimationEnd) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{12, 4}
}

func (x *Overlay_AnimationEnd) GetStartTimeOffset() *durationpb.Duration {
	if x != nil {
		return x.StartTimeOffset
	}
	return nil
}

// Animation types.
type Overlay_Animation struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Animations can be static or fade, or they can end the previous animation.
	//
	// Types that are valid to be assigned to AnimationType:
	//
	//	*Overlay_Animation_AnimationStatic
	//	*Overlay_Animation_AnimationFade
	//	*Overlay_Animation_AnimationEnd
	AnimationType isOverlay_Animation_AnimationType `protobuf_oneof:"animation_type"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Overlay_Animation) Reset() {
	*x = Overlay_Animation{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[27]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Overlay_Animation) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Overlay_Animation) ProtoMessage() {}

func (x *Overlay_Animation) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[27]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Overlay_Animation.ProtoReflect.Descriptor instead.
func (*Overlay_Animation) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{12, 5}
}

func (x *Overlay_Animation) GetAnimationType() isOverlay_Animation_AnimationType {
	if x != nil {
		return x.AnimationType
	}
	return nil
}

func (x *Overlay_Animation) GetAnimationStatic() *Overlay_AnimationStatic {
	if x != nil {
		if x, ok := x.AnimationType.(*Overlay_Animation_AnimationStatic); ok {
			return x.AnimationStatic
		}
	}
	return nil
}

func (x *Overlay_Animation) GetAnimationFade() *Overlay_AnimationFade {
	if x != nil {
		if x, ok := x.AnimationType.(*Overlay_Animation_AnimationFade); ok {
			return x.AnimationFade
		}
	}
	return nil
}

func (x *Overlay_Animation) GetAnimationEnd() *Overlay_AnimationEnd {
	if x != nil {
		if x, ok := x.AnimationType.(*Overlay_Animation_AnimationEnd); ok {
			return x.AnimationEnd
		}
	}
	return nil
}

type isOverlay_Animation_AnimationType interface {
	isOverlay_Animation_AnimationType()
}

type Overlay_Animation_AnimationStatic struct {
	// Display static overlay object.
	AnimationStatic *Overlay_AnimationStatic `protobuf:"bytes,1,opt,name=animation_static,json=animationStatic,proto3,oneof"`
}

type Overlay_Animation_AnimationFade struct {
	// Display overlay object with fade animation.
	AnimationFade *Overlay_AnimationFade `protobuf:"bytes,2,opt,name=animation_fade,json=animationFade,proto3,oneof"`
}

type Overlay_Animation_AnimationEnd struct {
	// End previous animation.
	AnimationEnd *Overlay_AnimationEnd `protobuf:"bytes,3,opt,name=animation_end,json=animationEnd,proto3,oneof"`
}

func (*Overlay_Animation_AnimationStatic) isOverlay_Animation_AnimationType() {}

func (*Overlay_Animation_AnimationFade) isOverlay_Animation_AnimationType() {}

func (*Overlay_Animation_AnimationEnd) isOverlay_Animation_AnimationType() {}

// Color preprocessing configuration.
//
// **Note:** This configuration is not supported.
type PreprocessingConfig_Color struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Control color saturation of the video. Enter a value between -1 and 1,
	// where -1 is fully desaturated and 1 is maximum saturation. 0 is no
	// change. The default is 0.
	Saturation float64 `protobuf:"fixed64,1,opt,name=saturation,proto3" json:"saturation,omitempty"`
	// Control black and white contrast of the video. Enter a value between -1
	// and 1, where -1 is minimum contrast and 1 is maximum contrast. 0 is no
	// change. The default is 0.
	Contrast float64 `protobuf:"fixed64,2,opt,name=contrast,proto3" json:"contrast,omitempty"`
	// Control brightness of the video. Enter a value between -1 and 1, where -1
	// is minimum brightness and 1 is maximum brightness. 0 is no change. The
	// default is 0.
	Brightness    float64 `protobuf:"fixed64,3,opt,name=brightness,proto3" json:"brightness,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PreprocessingConfig_Color) Reset() {
	*x = PreprocessingConfig_Color{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[28]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PreprocessingConfig_Color) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PreprocessingConfig_Color) ProtoMessage() {}

func (x *PreprocessingConfig_Color) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[28]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PreprocessingConfig_Color.ProtoReflect.Descriptor instead.
func (*PreprocessingConfig_Color) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{13, 0}
}

func (x *PreprocessingConfig_Color) GetSaturation() float64 {
	if x != nil {
		return x.Saturation
	}
	return 0
}

func (x *PreprocessingConfig_Color) GetContrast() float64 {
	if x != nil {
		return x.Contrast
	}
	return 0
}

func (x *PreprocessingConfig_Color) GetBrightness() float64 {
	if x != nil {
		return x.Brightness
	}
	return 0
}

// Denoise preprocessing configuration.
//
// **Note:** This configuration is not supported.
type PreprocessingConfig_Denoise struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Set strength of the denoise. Enter a value between 0 and 1. The higher
	// the value, the smoother the image. 0 is no denoising. The default is 0.
	Strength float64 `protobuf:"fixed64,1,opt,name=strength,proto3" json:"strength,omitempty"`
	// Set the denoiser mode. The default is `standard`.
	//
	// Supported denoiser modes:
	//
	// - `standard`
	// - `grain`
	Tune          string `protobuf:"bytes,2,opt,name=tune,proto3" json:"tune,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PreprocessingConfig_Denoise) Reset() {
	*x = PreprocessingConfig_Denoise{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[29]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PreprocessingConfig_Denoise) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PreprocessingConfig_Denoise) ProtoMessage() {}

func (x *PreprocessingConfig_Denoise) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[29]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PreprocessingConfig_Denoise.ProtoReflect.Descriptor instead.
func (*PreprocessingConfig_Denoise) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{13, 1}
}

func (x *PreprocessingConfig_Denoise) GetStrength() float64 {
	if x != nil {
		return x.Strength
	}
	return 0
}

func (x *PreprocessingConfig_Denoise) GetTune() string {
	if x != nil {
		return x.Tune
	}
	return ""
}

// Deblock preprocessing configuration.
//
// **Note:** This configuration is not supported.
type PreprocessingConfig_Deblock struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Set strength of the deblocker. Enter a value between 0 and 1. The higher
	// the value, the stronger the block removal. 0 is no deblocking. The
	// default is 0.
	Strength float64 `protobuf:"fixed64,1,opt,name=strength,proto3" json:"strength,omitempty"`
	// Enable deblocker. The default is `false`.
	Enabled       bool `protobuf:"varint,2,opt,name=enabled,proto3" json:"enabled,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PreprocessingConfig_Deblock) Reset() {
	*x = PreprocessingConfig_Deblock{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[30]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PreprocessingConfig_Deblock) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PreprocessingConfig_Deblock) ProtoMessage() {}

func (x *PreprocessingConfig_Deblock) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[30]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PreprocessingConfig_Deblock.ProtoReflect.Descriptor instead.
func (*PreprocessingConfig_Deblock) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{13, 2}
}

func (x *PreprocessingConfig_Deblock) GetStrength() float64 {
	if x != nil {
		return x.Strength
	}
	return 0
}

func (x *PreprocessingConfig_Deblock) GetEnabled() bool {
	if x != nil {
		return x.Enabled
	}
	return false
}

// Audio preprocessing configuration.
type PreprocessingConfig_Audio struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Specify audio loudness normalization in loudness units relative to full
	// scale (LUFS). Enter a value between -24 and 0 (the default), where:
	//
	//   - -24 is the Advanced Television Systems Committee (ATSC A/85) standard
	//   - -23 is the EU R128 broadcast standard
	//   - -19 is the prior standard for online mono audio
	//   - -18 is the ReplayGain standard
	//   - -16 is the prior standard for stereo audio
	//   - -14 is the new online audio standard recommended by Spotify, as well
	//     as Amazon Echo
	//   - 0 disables normalization
	Lufs float64 `protobuf:"fixed64,1,opt,name=lufs,proto3" json:"lufs,omitempty"`
	// Enable boosting high frequency components. The default is `false`.
	//
	// **Note:** This field is not supported.
	HighBoost bool `protobuf:"varint,2,opt,name=high_boost,json=highBoost,proto3" json:"high_boost,omitempty"`
	// Enable boosting low frequency components. The default is `false`.
	//
	// **Note:** This field is not supported.
	LowBoost      bool `protobuf:"varint,3,opt,name=low_boost,json=lowBoost,proto3" json:"low_boost,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PreprocessingConfig_Audio) Reset() {
	*x = PreprocessingConfig_Audio{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[31]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PreprocessingConfig_Audio) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PreprocessingConfig_Audio) ProtoMessage() {}

func (x *PreprocessingConfig_Audio) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[31]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PreprocessingConfig_Audio.ProtoReflect.Descriptor instead.
func (*PreprocessingConfig_Audio) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{13, 3}
}

func (x *PreprocessingConfig_Audio) GetLufs() float64 {
	if x != nil {
		return x.Lufs
	}
	return 0
}

func (x *PreprocessingConfig_Audio) GetHighBoost() bool {
	if x != nil {
		return x.HighBoost
	}
	return false
}

func (x *PreprocessingConfig_Audio) GetLowBoost() bool {
	if x != nil {
		return x.LowBoost
	}
	return false
}

// Video cropping configuration for the input video. The cropped input video
// is scaled to match the output resolution.
type PreprocessingConfig_Crop struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The number of pixels to crop from the top. The default is 0.
	TopPixels int32 `protobuf:"varint,1,opt,name=top_pixels,json=topPixels,proto3" json:"top_pixels,omitempty"`
	// The number of pixels to crop from the bottom. The default is 0.
	BottomPixels int32 `protobuf:"varint,2,opt,name=bottom_pixels,json=bottomPixels,proto3" json:"bottom_pixels,omitempty"`
	// The number of pixels to crop from the left. The default is 0.
	LeftPixels int32 `protobuf:"varint,3,opt,name=left_pixels,json=leftPixels,proto3" json:"left_pixels,omitempty"`
	// The number of pixels to crop from the right. The default is 0.
	RightPixels   int32 `protobuf:"varint,4,opt,name=right_pixels,json=rightPixels,proto3" json:"right_pixels,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PreprocessingConfig_Crop) Reset() {
	*x = PreprocessingConfig_Crop{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[32]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PreprocessingConfig_Crop) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PreprocessingConfig_Crop) ProtoMessage() {}

func (x *PreprocessingConfig_Crop) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[32]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PreprocessingConfig_Crop.ProtoReflect.Descriptor instead.
func (*PreprocessingConfig_Crop) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{13, 4}
}

func (x *PreprocessingConfig_Crop) GetTopPixels() int32 {
	if x != nil {
		return x.TopPixels
	}
	return 0
}

func (x *PreprocessingConfig_Crop) GetBottomPixels() int32 {
	if x != nil {
		return x.BottomPixels
	}
	return 0
}

func (x *PreprocessingConfig_Crop) GetLeftPixels() int32 {
	if x != nil {
		return x.LeftPixels
	}
	return 0
}

func (x *PreprocessingConfig_Crop) GetRightPixels() int32 {
	if x != nil {
		return x.RightPixels
	}
	return 0
}

// Pad filter configuration for the input video. The padded input video
// is scaled after padding with black to match the output resolution.
type PreprocessingConfig_Pad struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The number of pixels to add to the top. The default is 0.
	TopPixels int32 `protobuf:"varint,1,opt,name=top_pixels,json=topPixels,proto3" json:"top_pixels,omitempty"`
	// The number of pixels to add to the bottom. The default is 0.
	BottomPixels int32 `protobuf:"varint,2,opt,name=bottom_pixels,json=bottomPixels,proto3" json:"bottom_pixels,omitempty"`
	// The number of pixels to add to the left. The default is 0.
	LeftPixels int32 `protobuf:"varint,3,opt,name=left_pixels,json=leftPixels,proto3" json:"left_pixels,omitempty"`
	// The number of pixels to add to the right. The default is 0.
	RightPixels   int32 `protobuf:"varint,4,opt,name=right_pixels,json=rightPixels,proto3" json:"right_pixels,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *PreprocessingConfig_Pad) Reset() {
	*x = PreprocessingConfig_Pad{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[33]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PreprocessingConfig_Pad) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PreprocessingConfig_Pad) ProtoMessage() {}

func (x *PreprocessingConfig_Pad) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[33]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PreprocessingConfig_Pad.ProtoReflect.Descriptor instead.
func (*PreprocessingConfig_Pad) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{13, 5}
}

func (x *PreprocessingConfig_Pad) GetTopPixels() int32 {
	if x != nil {
		return x.TopPixels
	}
	return 0
}

func (x *PreprocessingConfig_Pad) GetBottomPixels() int32 {
	if x != nil {
		return x.BottomPixels
	}
	return 0
}

func (x *PreprocessingConfig_Pad) GetLeftPixels() int32 {
	if x != nil {
		return x.LeftPixels
	}
	return 0
}

func (x *PreprocessingConfig_Pad) GetRightPixels() int32 {
	if x != nil {
		return x.RightPixels
	}
	return 0
}

// Deinterlace configuration for input video.
type PreprocessingConfig_Deinterlace struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Specify the video deinterlacing filter. The default is `yadif`.
	//
	// Types that are valid to be assigned to DeinterlacingFilter:
	//
	//	*PreprocessingConfig_Deinterlace_Yadif
	//	*PreprocessingConfig_Deinterlace_Bwdif
	DeinterlacingFilter isPreprocessingConfig_Deinterlace_DeinterlacingFilter `protobuf_oneof:"deinterlacing_filter"`
	unknownFields       protoimpl.UnknownFields
	sizeCache           protoimpl.SizeCache
}

func (x *PreprocessingConfig_Deinterlace) Reset() {
	*x = PreprocessingConfig_Deinterlace{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[34]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PreprocessingConfig_Deinterlace) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PreprocessingConfig_Deinterlace) ProtoMessage() {}

func (x *PreprocessingConfig_Deinterlace) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[34]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PreprocessingConfig_Deinterlace.ProtoReflect.Descriptor instead.
func (*PreprocessingConfig_Deinterlace) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{13, 6}
}

func (x *PreprocessingConfig_Deinterlace) GetDeinterlacingFilter() isPreprocessingConfig_Deinterlace_DeinterlacingFilter {
	if x != nil {
		return x.DeinterlacingFilter
	}
	return nil
}

func (x *PreprocessingConfig_Deinterlace) GetYadif() *PreprocessingConfig_Deinterlace_YadifConfig {
	if x != nil {
		if x, ok := x.DeinterlacingFilter.(*PreprocessingConfig_Deinterlace_Yadif); ok {
			return x.Yadif
		}
	}
	return nil
}

func (x *PreprocessingConfig_Deinterlace) GetBwdif() *PreprocessingConfig_Deinterlace_BwdifConfig {
	if x != nil {
		if x, ok := x.DeinterlacingFilter.(*PreprocessingConfig_Deinterlace_Bwdif); ok {
			return x.Bwdif
		}
	}
	return nil
}

type isPreprocessingConfig_Deinterlace_DeinterlacingFilter interface {
	isPreprocessingConfig_Deinterlace_DeinterlacingFilter()
}

type PreprocessingConfig_Deinterlace_Yadif struct {
	// Specifies the Yet Another Deinterlacing Filter Configuration.
	Yadif *PreprocessingConfig_Deinterlace_YadifConfig `protobuf:"bytes,1,opt,name=yadif,proto3,oneof"`
}

type PreprocessingConfig_Deinterlace_Bwdif struct {
	// Specifies the Bob Weaver Deinterlacing Filter Configuration.
	Bwdif *PreprocessingConfig_Deinterlace_BwdifConfig `protobuf:"bytes,2,opt,name=bwdif,proto3,oneof"`
}

func (*PreprocessingConfig_Deinterlace_Yadif) isPreprocessingConfig_Deinterlace_DeinterlacingFilter() {
}

func (*PreprocessingConfig_Deinterlace_Bwdif) isPreprocessingConfig_Deinterlace_DeinterlacingFilter() {
}

// Yet Another Deinterlacing Filter Configuration.
type PreprocessingConfig_Deinterlace_YadifConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Specifies the deinterlacing mode to adopt.
	// The default is `send_frame`.
	// Supported values:
	//
	// - `send_frame`: Output one frame for each frame
	// - `send_field`: Output one frame for each field
	Mode string `protobuf:"bytes,1,opt,name=mode,proto3" json:"mode,omitempty"`
	// Disable spacial interlacing.
	// The default is `false`.
	DisableSpatialInterlacing bool `protobuf:"varint,2,opt,name=disable_spatial_interlacing,json=disableSpatialInterlacing,proto3" json:"disable_spatial_interlacing,omitempty"`
	// The picture field parity assumed for the input interlaced video.
	// The default is `auto`.
	// Supported values:
	//
	// - `tff`: Assume the top field is first
	// - `bff`: Assume the bottom field is first
	// - `auto`: Enable automatic detection of field parity
	Parity string `protobuf:"bytes,3,opt,name=parity,proto3" json:"parity,omitempty"`
	// Deinterlace all frames rather than just the frames identified as
	// interlaced. The default is `false`.
	DeinterlaceAllFrames bool `protobuf:"varint,4,opt,name=deinterlace_all_frames,json=deinterlaceAllFrames,proto3" json:"deinterlace_all_frames,omitempty"`
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

func (x *PreprocessingConfig_Deinterlace_YadifConfig) Reset() {
	*x = PreprocessingConfig_Deinterlace_YadifConfig{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[35]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PreprocessingConfig_Deinterlace_YadifConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PreprocessingConfig_Deinterlace_YadifConfig) ProtoMessage() {}

func (x *PreprocessingConfig_Deinterlace_YadifConfig) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[35]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PreprocessingConfig_Deinterlace_YadifConfig.ProtoReflect.Descriptor instead.
func (*PreprocessingConfig_Deinterlace_YadifConfig) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{13, 6, 0}
}

func (x *PreprocessingConfig_Deinterlace_YadifConfig) GetMode() string {
	if x != nil {
		return x.Mode
	}
	return ""
}

func (x *PreprocessingConfig_Deinterlace_YadifConfig) GetDisableSpatialInterlacing() bool {
	if x != nil {
		return x.DisableSpatialInterlacing
	}
	return false
}

func (x *PreprocessingConfig_Deinterlace_YadifConfig) GetParity() string {
	if x != nil {
		return x.Parity
	}
	return ""
}

func (x *PreprocessingConfig_Deinterlace_YadifConfig) GetDeinterlaceAllFrames() bool {
	if x != nil {
		return x.DeinterlaceAllFrames
	}
	return false
}

// Bob Weaver Deinterlacing Filter Configuration.
type PreprocessingConfig_Deinterlace_BwdifConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Specifies the deinterlacing mode to adopt.
	// The default is `send_frame`.
	// Supported values:
	//
	// - `send_frame`: Output one frame for each frame
	// - `send_field`: Output one frame for each field
	Mode string `protobuf:"bytes,1,opt,name=mode,proto3" json:"mode,omitempty"`
	// The picture field parity assumed for the input interlaced video.
	// The default is `auto`.
	// Supported values:
	//
	// - `tff`: Assume the top field is first
	// - `bff`: Assume the bottom field is first
	// - `auto`: Enable automatic detection of field parity
	Parity string `protobuf:"bytes,2,opt,name=parity,proto3" json:"parity,omitempty"`
	// Deinterlace all frames rather than just the frames identified as
	// interlaced. The default is `false`.
	DeinterlaceAllFrames bool `protobuf:"varint,3,opt,name=deinterlace_all_frames,json=deinterlaceAllFrames,proto3" json:"deinterlace_all_frames,omitempty"`
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

func (x *PreprocessingConfig_Deinterlace_BwdifConfig) Reset() {
	*x = PreprocessingConfig_Deinterlace_BwdifConfig{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[36]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *PreprocessingConfig_Deinterlace_BwdifConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*PreprocessingConfig_Deinterlace_BwdifConfig) ProtoMessage() {}

func (x *PreprocessingConfig_Deinterlace_BwdifConfig) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[36]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use PreprocessingConfig_Deinterlace_BwdifConfig.ProtoReflect.Descriptor instead.
func (*PreprocessingConfig_Deinterlace_BwdifConfig) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{13, 6, 1}
}

func (x *PreprocessingConfig_Deinterlace_BwdifConfig) GetMode() string {
	if x != nil {
		return x.Mode
	}
	return ""
}

func (x *PreprocessingConfig_Deinterlace_BwdifConfig) GetParity() string {
	if x != nil {
		return x.Parity
	}
	return ""
}

func (x *PreprocessingConfig_Deinterlace_BwdifConfig) GetDeinterlaceAllFrames() bool {
	if x != nil {
		return x.DeinterlaceAllFrames
	}
	return false
}

// H264 codec settings.
type VideoStream_H264CodecSettings struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The width of the video in pixels. Must be an even integer.
	// When not specified, the width is adjusted to match the specified height
	// and input aspect ratio. If both are omitted, the input width is used.
	//
	// For portrait videos that contain horizontal ASR and rotation metadata,
	// provide the width, in pixels, per the horizontal ASR. The API calculates
	// the height per the horizontal ASR. The API detects any rotation metadata
	// and swaps the requested height and width for the output.
	WidthPixels int32 `protobuf:"varint,1,opt,name=width_pixels,json=widthPixels,proto3" json:"width_pixels,omitempty"`
	// The height of the video in pixels. Must be an even integer.
	// When not specified, the height is adjusted to match the specified width
	// and input aspect ratio. If both are omitted, the input height is used.
	//
	// For portrait videos that contain horizontal ASR and rotation metadata,
	// provide the height, in pixels, per the horizontal ASR. The API calculates
	// the width per the horizontal ASR. The API detects any rotation metadata
	// and swaps the requested height and width for the output.
	HeightPixels int32 `protobuf:"varint,2,opt,name=height_pixels,json=heightPixels,proto3" json:"height_pixels,omitempty"`
	// Required. The target video frame rate in frames per second (FPS). Must be
	// less than or equal to 120. Will default to the input frame rate if larger
	// than the input frame rate. The API will generate an output FPS that is
	// divisible by the input FPS, and smaller or equal to the target FPS. See
	// [Calculating frame
	// rate](https://cloud.google.com/transcoder/docs/concepts/frame-rate) for
	// more information.
	FrameRate float64 `protobuf:"fixed64,3,opt,name=frame_rate,json=frameRate,proto3" json:"frame_rate,omitempty"`
	// Required. The video bitrate in bits per second. The minimum value is
	// 1,000. The maximum value is 800,000,000.
	BitrateBps int32 `protobuf:"varint,4,opt,name=bitrate_bps,json=bitrateBps,proto3" json:"bitrate_bps,omitempty"`
	// Pixel format to use. The default is `yuv420p`.
	//
	// Supported pixel formats:
	//
	// - `yuv420p` pixel format
	// - `yuv422p` pixel format
	// - `yuv444p` pixel format
	// - `yuv420p10` 10-bit HDR pixel format
	// - `yuv422p10` 10-bit HDR pixel format
	// - `yuv444p10` 10-bit HDR pixel format
	// - `yuv420p12` 12-bit HDR pixel format
	// - `yuv422p12` 12-bit HDR pixel format
	// - `yuv444p12` 12-bit HDR pixel format
	PixelFormat string `protobuf:"bytes,5,opt,name=pixel_format,json=pixelFormat,proto3" json:"pixel_format,omitempty"`
	// Specify the `rate_control_mode`. The default is `vbr`.
	//
	// Supported rate control modes:
	//
	// - `vbr` - variable bitrate
	// - `crf` - constant rate factor
	RateControlMode string `protobuf:"bytes,6,opt,name=rate_control_mode,json=rateControlMode,proto3" json:"rate_control_mode,omitempty"`
	// Target CRF level. Must be between 10 and 36, where 10 is the highest
	// quality and 36 is the most efficient compression. The default is 21.
	CrfLevel int32 `protobuf:"varint,7,opt,name=crf_level,json=crfLevel,proto3" json:"crf_level,omitempty"`
	// Specifies whether an open Group of Pictures (GOP) structure should be
	// allowed or not. The default is `false`.
	AllowOpenGop bool `protobuf:"varint,8,opt,name=allow_open_gop,json=allowOpenGop,proto3" json:"allow_open_gop,omitempty"`
	// GOP mode can be either by frame count or duration.
	//
	// Types that are valid to be assigned to GopMode:
	//
	//	*VideoStream_H264CodecSettings_GopFrameCount
	//	*VideoStream_H264CodecSettings_GopDuration
	GopMode isVideoStream_H264CodecSettings_GopMode `protobuf_oneof:"gop_mode"`
	// Use two-pass encoding strategy to achieve better video quality.
	// `VideoStream.rate_control_mode` must be `vbr`. The default is `false`.
	EnableTwoPass bool `protobuf:"varint,11,opt,name=enable_two_pass,json=enableTwoPass,proto3" json:"enable_two_pass,omitempty"`
	// Size of the Video Buffering Verifier (VBV) buffer in bits. Must be
	// greater than zero. The default is equal to `VideoStream.bitrate_bps`.
	VbvSizeBits int32 `protobuf:"varint,12,opt,name=vbv_size_bits,json=vbvSizeBits,proto3" json:"vbv_size_bits,omitempty"`
	// Initial fullness of the Video Buffering Verifier (VBV) buffer in bits.
	// Must be greater than zero. The default is equal to 90% of
	// `VideoStream.vbv_size_bits`.
	VbvFullnessBits int32 `protobuf:"varint,13,opt,name=vbv_fullness_bits,json=vbvFullnessBits,proto3" json:"vbv_fullness_bits,omitempty"`
	// The entropy coder to use. The default is `cabac`.
	//
	// Supported entropy coders:
	//
	// - `cavlc`
	// - `cabac`
	EntropyCoder string `protobuf:"bytes,14,opt,name=entropy_coder,json=entropyCoder,proto3" json:"entropy_coder,omitempty"`
	// Allow B-pyramid for reference frame selection. This may not be supported
	// on all decoders. The default is `false`.
	BPyramid bool `protobuf:"varint,15,opt,name=b_pyramid,json=bPyramid,proto3" json:"b_pyramid,omitempty"`
	// The number of consecutive B-frames. Must be greater than or equal to
	// zero. Must be less than `VideoStream.gop_frame_count` if set. The default
	// is 0.
	BFrameCount int32 `protobuf:"varint,16,opt,name=b_frame_count,json=bFrameCount,proto3" json:"b_frame_count,omitempty"`
	// Specify the intensity of the adaptive quantizer (AQ). Must be between 0
	// and 1, where 0 disables the quantizer and 1 maximizes the quantizer. A
	// higher value equals a lower bitrate but smoother image. The default is 0.
	AqStrength float64 `protobuf:"fixed64,17,opt,name=aq_strength,json=aqStrength,proto3" json:"aq_strength,omitempty"`
	// Enforces the specified codec profile. The following profiles are
	// supported:
	//
	// *   `baseline`
	// *   `main`
	// *   `high` (default)
	//
	// The available options are
	// [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.264#Tune).
	// Note that certain values for this field may cause the
	// transcoder to override other fields you set in the `H264CodecSettings`
	// message.
	Profile string `protobuf:"bytes,18,opt,name=profile,proto3" json:"profile,omitempty"`
	// Enforces the specified codec tune. The available options are
	// [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.264#Tune).
	// Note that certain values for this field may cause the
	// transcoder to override other fields you set in the `H264CodecSettings`
	// message.
	Tune string `protobuf:"bytes,19,opt,name=tune,proto3" json:"tune,omitempty"`
	// Enforces the specified codec preset. The default is `veryfast`. The
	// available options are
	// [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.264#Preset).
	// Note that certain values for this field may cause the
	// transcoder to override other fields you set in the `H264CodecSettings`
	// message.
	Preset        string `protobuf:"bytes,20,opt,name=preset,proto3" json:"preset,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *VideoStream_H264CodecSettings) Reset() {
	*x = VideoStream_H264CodecSettings{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[37]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *VideoStream_H264CodecSettings) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*VideoStream_H264CodecSettings) ProtoMessage() {}

func (x *VideoStream_H264CodecSettings) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[37]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use VideoStream_H264CodecSettings.ProtoReflect.Descriptor instead.
func (*VideoStream_H264CodecSettings) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{14, 0}
}

func (x *VideoStream_H264CodecSettings) GetWidthPixels() int32 {
	if x != nil {
		return x.WidthPixels
	}
	return 0
}

func (x *VideoStream_H264CodecSettings) GetHeightPixels() int32 {
	if x != nil {
		return x.HeightPixels
	}
	return 0
}

func (x *VideoStream_H264CodecSettings) GetFrameRate() float64 {
	if x != nil {
		return x.FrameRate
	}
	return 0
}

func (x *VideoStream_H264CodecSettings) GetBitrateBps() int32 {
	if x != nil {
		return x.BitrateBps
	}
	return 0
}

func (x *VideoStream_H264CodecSettings) GetPixelFormat() string {
	if x != nil {
		return x.PixelFormat
	}
	return ""
}

func (x *VideoStream_H264CodecSettings) GetRateControlMode() string {
	if x != nil {
		return x.RateControlMode
	}
	return ""
}

func (x *VideoStream_H264CodecSettings) GetCrfLevel() int32 {
	if x != nil {
		return x.CrfLevel
	}
	return 0
}

func (x *VideoStream_H264CodecSettings) GetAllowOpenGop() bool {
	if x != nil {
		return x.AllowOpenGop
	}
	return false
}

func (x *VideoStream_H264CodecSettings) GetGopMode() isVideoStream_H264CodecSettings_GopMode {
	if x != nil {
		return x.GopMode
	}
	return nil
}

func (x *VideoStream_H264CodecSettings) GetGopFrameCount() int32 {
	if x != nil {
		if x, ok := x.GopMode.(*VideoStream_H264CodecSettings_GopFrameCount); ok {
			return x.GopFrameCount
		}
	}
	return 0
}

func (x *VideoStream_H264CodecSettings) GetGopDuration() *durationpb.Duration {
	if x != nil {
		if x, ok := x.GopMode.(*VideoStream_H264CodecSettings_GopDuration); ok {
			return x.GopDuration
		}
	}
	return nil
}

func (x *VideoStream_H264CodecSettings) GetEnableTwoPass() bool {
	if x != nil {
		return x.EnableTwoPass
	}
	return false
}

func (x *VideoStream_H264CodecSettings) GetVbvSizeBits() int32 {
	if x != nil {
		return x.VbvSizeBits
	}
	return 0
}

func (x *VideoStream_H264CodecSettings) GetVbvFullnessBits() int32 {
	if x != nil {
		return x.VbvFullnessBits
	}
	return 0
}

func (x *VideoStream_H264CodecSettings) GetEntropyCoder() string {
	if x != nil {
		return x.EntropyCoder
	}
	return ""
}

func (x *VideoStream_H264CodecSettings) GetBPyramid() bool {
	if x != nil {
		return x.BPyramid
	}
	return false
}

func (x *VideoStream_H264CodecSettings) GetBFrameCount() int32 {
	if x != nil {
		return x.BFrameCount
	}
	return 0
}

func (x *VideoStream_H264CodecSettings) GetAqStrength() float64 {
	if x != nil {
		return x.AqStrength
	}
	return 0
}

func (x *VideoStream_H264CodecSettings) GetProfile() string {
	if x != nil {
		return x.Profile
	}
	return ""
}

func (x *VideoStream_H264CodecSettings) GetTune() string {
	if x != nil {
		return x.Tune
	}
	return ""
}

func (x *VideoStream_H264CodecSettings) GetPreset() string {
	if x != nil {
		return x.Preset
	}
	return ""
}

type isVideoStream_H264CodecSettings_GopMode interface {
	isVideoStream_H264CodecSettings_GopMode()
}

type VideoStream_H264CodecSettings_GopFrameCount struct {
	// Select the GOP size based on the specified frame count. Must be greater
	// than zero.
	GopFrameCount int32 `protobuf:"varint,9,opt,name=gop_frame_count,json=gopFrameCount,proto3,oneof"`
}

type VideoStream_H264CodecSettings_GopDuration struct {
	// Select the GOP size based on the specified duration. The default is
	// `3s`. Note that `gopDuration` must be less than or equal to
	// [`segmentDuration`](#SegmentSettings), and
	// [`segmentDuration`](#SegmentSettings) must be divisible by
	// `gopDuration`.
	GopDuration *durationpb.Duration `protobuf:"bytes,10,opt,name=gop_duration,json=gopDuration,proto3,oneof"`
}

func (*VideoStream_H264CodecSettings_GopFrameCount) isVideoStream_H264CodecSettings_GopMode() {}

func (*VideoStream_H264CodecSettings_GopDuration) isVideoStream_H264CodecSettings_GopMode() {}

// H265 codec settings.
type VideoStream_H265CodecSettings struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The width of the video in pixels. Must be an even integer.
	// When not specified, the width is adjusted to match the specified height
	// and input aspect ratio. If both are omitted, the input width is used.
	//
	// For portrait videos that contain horizontal ASR and rotation metadata,
	// provide the width, in pixels, per the horizontal ASR. The API calculates
	// the height per the horizontal ASR. The API detects any rotation metadata
	// and swaps the requested height and width for the output.
	WidthPixels int32 `protobuf:"varint,1,opt,name=width_pixels,json=widthPixels,proto3" json:"width_pixels,omitempty"`
	// The height of the video in pixels. Must be an even integer.
	// When not specified, the height is adjusted to match the specified width
	// and input aspect ratio. If both are omitted, the input height is used.
	//
	// For portrait videos that contain horizontal ASR and rotation metadata,
	// provide the height, in pixels, per the horizontal ASR. The API calculates
	// the width per the horizontal ASR. The API detects any rotation metadata
	// and swaps the requested height and width for the output.
	HeightPixels int32 `protobuf:"varint,2,opt,name=height_pixels,json=heightPixels,proto3" json:"height_pixels,omitempty"`
	// Required. The target video frame rate in frames per second (FPS). Must be
	// less than or equal to 120. Will default to the input frame rate if larger
	// than the input frame rate. The API will generate an output FPS that is
	// divisible by the input FPS, and smaller or equal to the target FPS. See
	// [Calculating frame
	// rate](https://cloud.google.com/transcoder/docs/concepts/frame-rate) for
	// more information.
	FrameRate float64 `protobuf:"fixed64,3,opt,name=frame_rate,json=frameRate,proto3" json:"frame_rate,omitempty"`
	// Required. The video bitrate in bits per second. The minimum value is
	// 1,000. The maximum value is 800,000,000.
	BitrateBps int32 `protobuf:"varint,4,opt,name=bitrate_bps,json=bitrateBps,proto3" json:"bitrate_bps,omitempty"`
	// Pixel format to use. The default is `yuv420p`.
	//
	// Supported pixel formats:
	//
	// - `yuv420p` pixel format
	// - `yuv422p` pixel format
	// - `yuv444p` pixel format
	// - `yuv420p10` 10-bit HDR pixel format
	// - `yuv422p10` 10-bit HDR pixel format
	// - `yuv444p10` 10-bit HDR pixel format
	// - `yuv420p12` 12-bit HDR pixel format
	// - `yuv422p12` 12-bit HDR pixel format
	// - `yuv444p12` 12-bit HDR pixel format
	PixelFormat string `protobuf:"bytes,5,opt,name=pixel_format,json=pixelFormat,proto3" json:"pixel_format,omitempty"`
	// Specify the `rate_control_mode`. The default is `vbr`.
	//
	// Supported rate control modes:
	//
	// - `vbr` - variable bitrate
	// - `crf` - constant rate factor
	RateControlMode string `protobuf:"bytes,6,opt,name=rate_control_mode,json=rateControlMode,proto3" json:"rate_control_mode,omitempty"`
	// Target CRF level. Must be between 10 and 36, where 10 is the highest
	// quality and 36 is the most efficient compression. The default is 21.
	CrfLevel int32 `protobuf:"varint,7,opt,name=crf_level,json=crfLevel,proto3" json:"crf_level,omitempty"`
	// Specifies whether an open Group of Pictures (GOP) structure should be
	// allowed or not. The default is `false`.
	AllowOpenGop bool `protobuf:"varint,8,opt,name=allow_open_gop,json=allowOpenGop,proto3" json:"allow_open_gop,omitempty"`
	// GOP mode can be either by frame count or duration.
	//
	// Types that are valid to be assigned to GopMode:
	//
	//	*VideoStream_H265CodecSettings_GopFrameCount
	//	*VideoStream_H265CodecSettings_GopDuration
	GopMode isVideoStream_H265CodecSettings_GopMode `protobuf_oneof:"gop_mode"`
	// Use two-pass encoding strategy to achieve better video quality.
	// `VideoStream.rate_control_mode` must be `vbr`. The default is `false`.
	EnableTwoPass bool `protobuf:"varint,11,opt,name=enable_two_pass,json=enableTwoPass,proto3" json:"enable_two_pass,omitempty"`
	// Size of the Video Buffering Verifier (VBV) buffer in bits. Must be
	// greater than zero. The default is equal to `VideoStream.bitrate_bps`.
	VbvSizeBits int32 `protobuf:"varint,12,opt,name=vbv_size_bits,json=vbvSizeBits,proto3" json:"vbv_size_bits,omitempty"`
	// Initial fullness of the Video Buffering Verifier (VBV) buffer in bits.
	// Must be greater than zero. The default is equal to 90% of
	// `VideoStream.vbv_size_bits`.
	VbvFullnessBits int32 `protobuf:"varint,13,opt,name=vbv_fullness_bits,json=vbvFullnessBits,proto3" json:"vbv_fullness_bits,omitempty"`
	// Allow B-pyramid for reference frame selection. This may not be supported
	// on all decoders. The default is `false`.
	BPyramid bool `protobuf:"varint,14,opt,name=b_pyramid,json=bPyramid,proto3" json:"b_pyramid,omitempty"`
	// The number of consecutive B-frames. Must be greater than or equal to
	// zero. Must be less than `VideoStream.gop_frame_count` if set. The default
	// is 0.
	BFrameCount int32 `protobuf:"varint,15,opt,name=b_frame_count,json=bFrameCount,proto3" json:"b_frame_count,omitempty"`
	// Specify the intensity of the adaptive quantizer (AQ). Must be between 0
	// and 1, where 0 disables the quantizer and 1 maximizes the quantizer. A
	// higher value equals a lower bitrate but smoother image. The default is 0.
	AqStrength float64 `protobuf:"fixed64,16,opt,name=aq_strength,json=aqStrength,proto3" json:"aq_strength,omitempty"`
	// Enforces the specified codec profile. The following profiles are
	// supported:
	//
	// *   8-bit profiles
	//   - `main` (default)
	//   - `main-intra`
	//   - `mainstillpicture`
	//
	// *   10-bit profiles
	//   - `main10` (default)
	//   - `main10-intra`
	//   - `main422-10`
	//   - `main422-10-intra`
	//   - `main444-10`
	//   - `main444-10-intra`
	//
	// *   12-bit profiles
	//   - `main12` (default)
	//   - `main12-intra`
	//   - `main422-12`
	//   - `main422-12-intra`
	//   - `main444-12`
	//   - `main444-12-intra`
	//
	// The available options are
	// [FFmpeg-compatible](https://x265.readthedocs.io/).
	// Note that certain values for this field may cause the
	// transcoder to override other fields you set in the `H265CodecSettings`
	// message.
	Profile string `protobuf:"bytes,17,opt,name=profile,proto3" json:"profile,omitempty"`
	// Enforces the specified codec tune. The available options are
	// [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.265).
	// Note that certain values for this field may cause the
	// transcoder to override other fields you set in the `H265CodecSettings`
	// message.
	Tune string `protobuf:"bytes,18,opt,name=tune,proto3" json:"tune,omitempty"`
	// Enforces the specified codec preset. The default is `veryfast`. The
	// available options are
	// [FFmpeg-compatible](https://trac.ffmpeg.org/wiki/Encode/H.265).
	// Note that certain values for this field may cause the
	// transcoder to override other fields you set in the `H265CodecSettings`
	// message.
	Preset        string `protobuf:"bytes,19,opt,name=preset,proto3" json:"preset,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *VideoStream_H265CodecSettings) Reset() {
	*x = VideoStream_H265CodecSettings{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[38]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *VideoStream_H265CodecSettings) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*VideoStream_H265CodecSettings) ProtoMessage() {}

func (x *VideoStream_H265CodecSettings) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[38]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use VideoStream_H265CodecSettings.ProtoReflect.Descriptor instead.
func (*VideoStream_H265CodecSettings) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{14, 1}
}

func (x *VideoStream_H265CodecSettings) GetWidthPixels() int32 {
	if x != nil {
		return x.WidthPixels
	}
	return 0
}

func (x *VideoStream_H265CodecSettings) GetHeightPixels() int32 {
	if x != nil {
		return x.HeightPixels
	}
	return 0
}

func (x *VideoStream_H265CodecSettings) GetFrameRate() float64 {
	if x != nil {
		return x.FrameRate
	}
	return 0
}

func (x *VideoStream_H265CodecSettings) GetBitrateBps() int32 {
	if x != nil {
		return x.BitrateBps
	}
	return 0
}

func (x *VideoStream_H265CodecSettings) GetPixelFormat() string {
	if x != nil {
		return x.PixelFormat
	}
	return ""
}

func (x *VideoStream_H265CodecSettings) GetRateControlMode() string {
	if x != nil {
		return x.RateControlMode
	}
	return ""
}

func (x *VideoStream_H265CodecSettings) GetCrfLevel() int32 {
	if x != nil {
		return x.CrfLevel
	}
	return 0
}

func (x *VideoStream_H265CodecSettings) GetAllowOpenGop() bool {
	if x != nil {
		return x.AllowOpenGop
	}
	return false
}

func (x *VideoStream_H265CodecSettings) GetGopMode() isVideoStream_H265CodecSettings_GopMode {
	if x != nil {
		return x.GopMode
	}
	return nil
}

func (x *VideoStream_H265CodecSettings) GetGopFrameCount() int32 {
	if x != nil {
		if x, ok := x.GopMode.(*VideoStream_H265CodecSettings_GopFrameCount); ok {
			return x.GopFrameCount
		}
	}
	return 0
}

func (x *VideoStream_H265CodecSettings) GetGopDuration() *durationpb.Duration {
	if x != nil {
		if x, ok := x.GopMode.(*VideoStream_H265CodecSettings_GopDuration); ok {
			return x.GopDuration
		}
	}
	return nil
}

func (x *VideoStream_H265CodecSettings) GetEnableTwoPass() bool {
	if x != nil {
		return x.EnableTwoPass
	}
	return false
}

func (x *VideoStream_H265CodecSettings) GetVbvSizeBits() int32 {
	if x != nil {
		return x.VbvSizeBits
	}
	return 0
}

func (x *VideoStream_H265CodecSettings) GetVbvFullnessBits() int32 {
	if x != nil {
		return x.VbvFullnessBits
	}
	return 0
}

func (x *VideoStream_H265CodecSettings) GetBPyramid() bool {
	if x != nil {
		return x.BPyramid
	}
	return false
}

func (x *VideoStream_H265CodecSettings) GetBFrameCount() int32 {
	if x != nil {
		return x.BFrameCount
	}
	return 0
}

func (x *VideoStream_H265CodecSettings) GetAqStrength() float64 {
	if x != nil {
		return x.AqStrength
	}
	return 0
}

func (x *VideoStream_H265CodecSettings) GetProfile() string {
	if x != nil {
		return x.Profile
	}
	return ""
}

func (x *VideoStream_H265CodecSettings) GetTune() string {
	if x != nil {
		return x.Tune
	}
	return ""
}

func (x *VideoStream_H265CodecSettings) GetPreset() string {
	if x != nil {
		return x.Preset
	}
	return ""
}

type isVideoStream_H265CodecSettings_GopMode interface {
	isVideoStream_H265CodecSettings_GopMode()
}

type VideoStream_H265CodecSettings_GopFrameCount struct {
	// Select the GOP size based on the specified frame count. Must be greater
	// than zero.
	GopFrameCount int32 `protobuf:"varint,9,opt,name=gop_frame_count,json=gopFrameCount,proto3,oneof"`
}

type VideoStream_H265CodecSettings_GopDuration struct {
	// Select the GOP size based on the specified duration. The default is
	// `3s`. Note that `gopDuration` must be less than or equal to
	// [`segmentDuration`](#SegmentSettings), and
	// [`segmentDuration`](#SegmentSettings) must be divisible by
	// `gopDuration`.
	GopDuration *durationpb.Duration `protobuf:"bytes,10,opt,name=gop_duration,json=gopDuration,proto3,oneof"`
}

func (*VideoStream_H265CodecSettings_GopFrameCount) isVideoStream_H265CodecSettings_GopMode() {}

func (*VideoStream_H265CodecSettings_GopDuration) isVideoStream_H265CodecSettings_GopMode() {}

// VP9 codec settings.
type VideoStream_Vp9CodecSettings struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The width of the video in pixels. Must be an even integer.
	// When not specified, the width is adjusted to match the specified height
	// and input aspect ratio. If both are omitted, the input width is used.
	//
	// For portrait videos that contain horizontal ASR and rotation metadata,
	// provide the width, in pixels, per the horizontal ASR. The API calculates
	// the height per the horizontal ASR. The API detects any rotation metadata
	// and swaps the requested height and width for the output.
	WidthPixels int32 `protobuf:"varint,1,opt,name=width_pixels,json=widthPixels,proto3" json:"width_pixels,omitempty"`
	// The height of the video in pixels. Must be an even integer.
	// When not specified, the height is adjusted to match the specified width
	// and input aspect ratio. If both are omitted, the input height is used.
	//
	// For portrait videos that contain horizontal ASR and rotation metadata,
	// provide the height, in pixels, per the horizontal ASR. The API calculates
	// the width per the horizontal ASR. The API detects any rotation metadata
	// and swaps the requested height and width for the output.
	HeightPixels int32 `protobuf:"varint,2,opt,name=height_pixels,json=heightPixels,proto3" json:"height_pixels,omitempty"`
	// Required. The target video frame rate in frames per second (FPS). Must be
	// less than or equal to 120. Will default to the input frame rate if larger
	// than the input frame rate. The API will generate an output FPS that is
	// divisible by the input FPS, and smaller or equal to the target FPS. See
	// [Calculating frame
	// rate](https://cloud.google.com/transcoder/docs/concepts/frame-rate) for
	// more information.
	FrameRate float64 `protobuf:"fixed64,3,opt,name=frame_rate,json=frameRate,proto3" json:"frame_rate,omitempty"`
	// Required. The video bitrate in bits per second. The minimum value is
	// 1,000. The maximum value is 480,000,000.
	BitrateBps int32 `protobuf:"varint,4,opt,name=bitrate_bps,json=bitrateBps,proto3" json:"bitrate_bps,omitempty"`
	// Pixel format to use. The default is `yuv420p`.
	//
	// Supported pixel formats:
	//
	// - `yuv420p` pixel format
	// - `yuv422p` pixel format
	// - `yuv444p` pixel format
	// - `yuv420p10` 10-bit HDR pixel format
	// - `yuv422p10` 10-bit HDR pixel format
	// - `yuv444p10` 10-bit HDR pixel format
	// - `yuv420p12` 12-bit HDR pixel format
	// - `yuv422p12` 12-bit HDR pixel format
	// - `yuv444p12` 12-bit HDR pixel format
	PixelFormat string `protobuf:"bytes,5,opt,name=pixel_format,json=pixelFormat,proto3" json:"pixel_format,omitempty"`
	// Specify the `rate_control_mode`. The default is `vbr`.
	//
	// Supported rate control modes:
	//
	// - `vbr` - variable bitrate
	RateControlMode string `protobuf:"bytes,6,opt,name=rate_control_mode,json=rateControlMode,proto3" json:"rate_control_mode,omitempty"`
	// Target CRF level. Must be between 10 and 36, where 10 is the highest
	// quality and 36 is the most efficient compression. The default is 21.
	//
	// **Note:** This field is not supported.
	CrfLevel int32 `protobuf:"varint,7,opt,name=crf_level,json=crfLevel,proto3" json:"crf_level,omitempty"`
	// GOP mode can be either by frame count or duration.
	//
	// Types that are valid to be assigned to GopMode:
	//
	//	*VideoStream_Vp9CodecSettings_GopFrameCount
	//	*VideoStream_Vp9CodecSettings_GopDuration
	GopMode isVideoStream_Vp9CodecSettings_GopMode `protobuf_oneof:"gop_mode"`
	// Enforces the specified codec profile. The following profiles are
	// supported:
	//
	// *   `profile0` (default)
	// *   `profile1`
	// *   `profile2`
	// *   `profile3`
	//
	// The available options are
	// [WebM-compatible](https://www.webmproject.org/vp9/profiles/).
	// Note that certain values for this field may cause the
	// transcoder to override other fields you set in the `Vp9CodecSettings`
	// message.
	Profile       string `protobuf:"bytes,10,opt,name=profile,proto3" json:"profile,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *VideoStream_Vp9CodecSettings) Reset() {
	*x = VideoStream_Vp9CodecSettings{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[39]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *VideoStream_Vp9CodecSettings) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*VideoStream_Vp9CodecSettings) ProtoMessage() {}

func (x *VideoStream_Vp9CodecSettings) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[39]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use VideoStream_Vp9CodecSettings.ProtoReflect.Descriptor instead.
func (*VideoStream_Vp9CodecSettings) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{14, 2}
}

func (x *VideoStream_Vp9CodecSettings) GetWidthPixels() int32 {
	if x != nil {
		return x.WidthPixels
	}
	return 0
}

func (x *VideoStream_Vp9CodecSettings) GetHeightPixels() int32 {
	if x != nil {
		return x.HeightPixels
	}
	return 0
}

func (x *VideoStream_Vp9CodecSettings) GetFrameRate() float64 {
	if x != nil {
		return x.FrameRate
	}
	return 0
}

func (x *VideoStream_Vp9CodecSettings) GetBitrateBps() int32 {
	if x != nil {
		return x.BitrateBps
	}
	return 0
}

func (x *VideoStream_Vp9CodecSettings) GetPixelFormat() string {
	if x != nil {
		return x.PixelFormat
	}
	return ""
}

func (x *VideoStream_Vp9CodecSettings) GetRateControlMode() string {
	if x != nil {
		return x.RateControlMode
	}
	return ""
}

func (x *VideoStream_Vp9CodecSettings) GetCrfLevel() int32 {
	if x != nil {
		return x.CrfLevel
	}
	return 0
}

func (x *VideoStream_Vp9CodecSettings) GetGopMode() isVideoStream_Vp9CodecSettings_GopMode {
	if x != nil {
		return x.GopMode
	}
	return nil
}

func (x *VideoStream_Vp9CodecSettings) GetGopFrameCount() int32 {
	if x != nil {
		if x, ok := x.GopMode.(*VideoStream_Vp9CodecSettings_GopFrameCount); ok {
			return x.GopFrameCount
		}
	}
	return 0
}

func (x *VideoStream_Vp9CodecSettings) GetGopDuration() *durationpb.Duration {
	if x != nil {
		if x, ok := x.GopMode.(*VideoStream_Vp9CodecSettings_GopDuration); ok {
			return x.GopDuration
		}
	}
	return nil
}

func (x *VideoStream_Vp9CodecSettings) GetProfile() string {
	if x != nil {
		return x.Profile
	}
	return ""
}

type isVideoStream_Vp9CodecSettings_GopMode interface {
	isVideoStream_Vp9CodecSettings_GopMode()
}

type VideoStream_Vp9CodecSettings_GopFrameCount struct {
	// Select the GOP size based on the specified frame count. Must be greater
	// than zero.
	GopFrameCount int32 `protobuf:"varint,8,opt,name=gop_frame_count,json=gopFrameCount,proto3,oneof"`
}

type VideoStream_Vp9CodecSettings_GopDuration struct {
	// Select the GOP size based on the specified duration. The default is
	// `3s`. Note that `gopDuration` must be less than or equal to
	// [`segmentDuration`](#SegmentSettings), and
	// [`segmentDuration`](#SegmentSettings) must be divisible by
	// `gopDuration`.
	GopDuration *durationpb.Duration `protobuf:"bytes,9,opt,name=gop_duration,json=gopDuration,proto3,oneof"`
}

func (*VideoStream_Vp9CodecSettings_GopFrameCount) isVideoStream_Vp9CodecSettings_GopMode() {}

func (*VideoStream_Vp9CodecSettings_GopDuration) isVideoStream_Vp9CodecSettings_GopMode() {}

// The mapping for the `Job.edit_list` atoms with audio `EditAtom.inputs`.
type AudioStream_AudioMapping struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Required. The `EditAtom.key` that references the atom with audio inputs
	// in the `Job.edit_list`.
	AtomKey string `protobuf:"bytes,1,opt,name=atom_key,json=atomKey,proto3" json:"atom_key,omitempty"`
	// Required. The `Input.key` that identifies the input file.
	InputKey string `protobuf:"bytes,2,opt,name=input_key,json=inputKey,proto3" json:"input_key,omitempty"`
	// Required. The zero-based index of the track in the input file.
	InputTrack int32 `protobuf:"varint,3,opt,name=input_track,json=inputTrack,proto3" json:"input_track,omitempty"`
	// Required. The zero-based index of the channel in the input audio stream.
	InputChannel int32 `protobuf:"varint,4,opt,name=input_channel,json=inputChannel,proto3" json:"input_channel,omitempty"`
	// Required. The zero-based index of the channel in the output audio stream.
	OutputChannel int32 `protobuf:"varint,5,opt,name=output_channel,json=outputChannel,proto3" json:"output_channel,omitempty"`
	// Audio volume control in dB. Negative values decrease volume,
	// positive values increase. The default is 0.
	GainDb        float64 `protobuf:"fixed64,6,opt,name=gain_db,json=gainDb,proto3" json:"gain_db,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AudioStream_AudioMapping) Reset() {
	*x = AudioStream_AudioMapping{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[40]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AudioStream_AudioMapping) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AudioStream_AudioMapping) ProtoMessage() {}

func (x *AudioStream_AudioMapping) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[40]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AudioStream_AudioMapping.ProtoReflect.Descriptor instead.
func (*AudioStream_AudioMapping) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{15, 0}
}

func (x *AudioStream_AudioMapping) GetAtomKey() string {
	if x != nil {
		return x.AtomKey
	}
	return ""
}

func (x *AudioStream_AudioMapping) GetInputKey() string {
	if x != nil {
		return x.InputKey
	}
	return ""
}

func (x *AudioStream_AudioMapping) GetInputTrack() int32 {
	if x != nil {
		return x.InputTrack
	}
	return 0
}

func (x *AudioStream_AudioMapping) GetInputChannel() int32 {
	if x != nil {
		return x.InputChannel
	}
	return 0
}

func (x *AudioStream_AudioMapping) GetOutputChannel() int32 {
	if x != nil {
		return x.OutputChannel
	}
	return 0
}

func (x *AudioStream_AudioMapping) GetGainDb() float64 {
	if x != nil {
		return x.GainDb
	}
	return 0
}

// The mapping for the `Job.edit_list` atoms with text `EditAtom.inputs`.
type TextStream_TextMapping struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Required. The `EditAtom.key` that references atom with text inputs in the
	// `Job.edit_list`.
	AtomKey string `protobuf:"bytes,1,opt,name=atom_key,json=atomKey,proto3" json:"atom_key,omitempty"`
	// Required. The `Input.key` that identifies the input file.
	InputKey string `protobuf:"bytes,2,opt,name=input_key,json=inputKey,proto3" json:"input_key,omitempty"`
	// Required. The zero-based index of the track in the input file.
	InputTrack    int32 `protobuf:"varint,3,opt,name=input_track,json=inputTrack,proto3" json:"input_track,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TextStream_TextMapping) Reset() {
	*x = TextStream_TextMapping{}
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[41]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TextStream_TextMapping) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TextStream_TextMapping) ProtoMessage() {}

func (x *TextStream_TextMapping) ProtoReflect() protoreflect.Message {
	mi := &file_cloud_video_transcoder_v1_data_proto_msgTypes[41]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TextStream_TextMapping.ProtoReflect.Descriptor instead.
func (*TextStream_TextMapping) Descriptor() ([]byte, []int) {
	return file_cloud_video_transcoder_v1_data_proto_rawDescGZIP(), []int{16, 0}
}

func (x *TextStream_TextMapping) GetAtomKey() string {
	if x != nil {
		return x.AtomKey
	}
	return ""
}

func (x *TextStream_TextMapping) GetInputKey() string {
	if x != nil {
		return x.InputKey
	}
	return ""
}

func (x *TextStream_TextMapping) GetInputTrack() int32 {
	if x != nil {
		return x.InputTrack
	}
	return 0
}

var File_cloud_video_transcoder_v1_data_proto protoreflect.FileDescriptor

const file_cloud_video_transcoder_v1_data_proto_rawDesc = "" +
	"\n" +
	"$cloud/video/transcoder/v1/data.proto\x12'google.events.cloud.video.transcoder.v1\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\x17google/rpc/status.proto\"\x94\a\n" +
	"\x03Job\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12L\n" +
	"\x06config\x18\x05 \x01(\v22.google.events.cloud.video.transcoder.v1.JobConfigH\x00R\x06config\x12R\n" +
	"\x05state\x18\b \x01(\x0e2<.google.events.cloud.video.transcoder.v1.Job.ProcessingStateR\x05state\x12;\n" +
	"\vcreate_time\x18\f \x01(\v2\x1a.google.protobuf.TimestampR\n" +
	"createTime\x129\n" +
	"\n" +
	"start_time\x18\r \x01(\v2\x1a.google.protobuf.TimestampR\tstartTime\x125\n" +
	"\bend_time\x18\x0e \x01(\v2\x1a.google.protobuf.TimestampR\aendTime\x129\n" +
	"\x19ttl_after_completion_days\x18\x0f \x01(\x05R\x16ttlAfterCompletionDays\x12P\n" +
	"\x06labels\x18\x10 \x03(\v28.google.events.cloud.video.transcoder.v1.Job.LabelsEntryR\x06labels\x12(\n" +
	"\x05error\x18\x11 \x01(\v2\x12.google.rpc.StatusR\x05error\x12O\n" +
	"\x04mode\x18\x14 \x01(\x0e2;.google.events.cloud.video.transcoder.v1.Job.ProcessingModeR\x04mode\x1a9\n" +
	"\vLabelsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"h\n" +
	"\x0fProcessingState\x12 \n" +
	"\x1cPROCESSING_STATE_UNSPECIFIED\x10\x00\x12\v\n" +
	"\aPENDING\x10\x01\x12\v\n" +
	"\aRUNNING\x10\x02\x12\r\n" +
	"\tSUCCEEDED\x10\x03\x12\n" +
	"\n" +
	"\x06FAILED\x10\x04\"m\n" +
	"\x0eProcessingMode\x12\x1f\n" +
	"\x1bPROCESSING_MODE_UNSPECIFIED\x10\x00\x12\x1f\n" +
	"\x1bPROCESSING_MODE_INTERACTIVE\x10\x01\x12\x19\n" +
	"\x15PROCESSING_MODE_BATCH\x10\x02B\f\n" +
	"\n" +
	"job_config\"\x82\x02\n" +
	"\vJobTemplate\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12J\n" +
	"\x06config\x18\x02 \x01(\v22.google.events.cloud.video.transcoder.v1.JobConfigR\x06config\x12X\n" +
	"\x06labels\x18\x03 \x03(\v2@.google.events.cloud.video.transcoder.v1.JobTemplate.LabelsEntryR\x06labels\x1a9\n" +
	"\vLabelsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\xdf\x06\n" +
	"\tJobConfig\x12F\n" +
	"\x06inputs\x18\x01 \x03(\v2..google.events.cloud.video.transcoder.v1.InputR\x06inputs\x12N\n" +
	"\tedit_list\x18\x02 \x03(\v21.google.events.cloud.video.transcoder.v1.EditAtomR\beditList\x12h\n" +
	"\x12elementary_streams\x18\x03 \x03(\v29.google.events.cloud.video.transcoder.v1.ElementaryStreamR\x11elementaryStreams\x12S\n" +
	"\vmux_streams\x18\x04 \x03(\v22.google.events.cloud.video.transcoder.v1.MuxStreamR\n" +
	"muxStreams\x12O\n" +
	"\tmanifests\x18\x05 \x03(\v21.google.events.cloud.video.transcoder.v1.ManifestR\tmanifests\x12G\n" +
	"\x06output\x18\x06 \x01(\v2/.google.events.cloud.video.transcoder.v1.OutputR\x06output\x12M\n" +
	"\tad_breaks\x18\a \x03(\v20.google.events.cloud.video.transcoder.v1.AdBreakR\badBreaks\x12i\n" +
	"\x12pubsub_destination\x18\b \x01(\v2:.google.events.cloud.video.transcoder.v1.PubsubDestinationR\x11pubsubDestination\x12Y\n" +
	"\rsprite_sheets\x18\t \x03(\v24.google.events.cloud.video.transcoder.v1.SpriteSheetR\fspriteSheets\x12L\n" +
	"\boverlays\x18\n" +
	" \x03(\v20.google.events.cloud.video.transcoder.v1.OverlayR\boverlays\"\x9c\x01\n" +
	"\x05Input\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x10\n" +
	"\x03uri\x18\x02 \x01(\tR\x03uri\x12o\n" +
	"\x14preprocessing_config\x18\x03 \x01(\v2<.google.events.cloud.video.transcoder.v1.PreprocessingConfigR\x13preprocessingConfig\"\x1a\n" +
	"\x06Output\x12\x10\n" +
	"\x03uri\x18\x01 \x01(\tR\x03uri\"\xbe\x01\n" +
	"\bEditAtom\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x16\n" +
	"\x06inputs\x18\x02 \x03(\tR\x06inputs\x12A\n" +
	"\x0fend_time_offset\x18\x03 \x01(\v2\x19.google.protobuf.DurationR\rendTimeOffset\x12E\n" +
	"\x11start_time_offset\x18\x04 \x01(\v2\x19.google.protobuf.DurationR\x0fstartTimeOffset\"P\n" +
	"\aAdBreak\x12E\n" +
	"\x11start_time_offset\x18\x01 \x01(\v2\x19.google.protobuf.DurationR\x0fstartTimeOffset\"\xc7\x02\n" +
	"\x10ElementaryStream\x12\x10\n" +
	"\x03key\x18\x04 \x01(\tR\x03key\x12Y\n" +
	"\fvideo_stream\x18\x01 \x01(\v24.google.events.cloud.video.transcoder.v1.VideoStreamH\x00R\vvideoStream\x12Y\n" +
	"\faudio_stream\x18\x02 \x01(\v24.google.events.cloud.video.transcoder.v1.AudioStreamH\x00R\vaudioStream\x12V\n" +
	"\vtext_stream\x18\x03 \x01(\v23.google.events.cloud.video.transcoder.v1.TextStreamH\x00R\n" +
	"textStreamB\x13\n" +
	"\x11elementary_stream\"\xec\x01\n" +
	"\tMuxStream\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x1b\n" +
	"\tfile_name\x18\x02 \x01(\tR\bfileName\x12\x1c\n" +
	"\tcontainer\x18\x03 \x01(\tR\tcontainer\x12-\n" +
	"\x12elementary_streams\x18\x04 \x03(\tR\x11elementaryStreams\x12c\n" +
	"\x10segment_settings\x18\x05 \x01(\v28.google.events.cloud.video.transcoder.v1.SegmentSettingsR\x0fsegmentSettings\"\xde\x01\n" +
	"\bManifest\x12\x1b\n" +
	"\tfile_name\x18\x01 \x01(\tR\bfileName\x12R\n" +
	"\x04type\x18\x02 \x01(\x0e2>.google.events.cloud.video.transcoder.v1.Manifest.ManifestTypeR\x04type\x12\x1f\n" +
	"\vmux_streams\x18\x03 \x03(\tR\n" +
	"muxStreams\"@\n" +
	"\fManifestType\x12\x1d\n" +
	"\x19MANIFEST_TYPE_UNSPECIFIED\x10\x00\x12\a\n" +
	"\x03HLS\x10\x01\x12\b\n" +
	"\x04DASH\x10\x02\")\n" +
	"\x11PubsubDestination\x12\x14\n" +
	"\x05topic\x18\x01 \x01(\tR\x05topic\"\xff\x03\n" +
	"\vSpriteSheet\x12\x16\n" +
	"\x06format\x18\x01 \x01(\tR\x06format\x12\x1f\n" +
	"\vfile_prefix\x18\x02 \x01(\tR\n" +
	"filePrefix\x12.\n" +
	"\x13sprite_width_pixels\x18\x03 \x01(\x05R\x11spriteWidthPixels\x120\n" +
	"\x14sprite_height_pixels\x18\x04 \x01(\x05R\x12spriteHeightPixels\x12!\n" +
	"\fcolumn_count\x18\x05 \x01(\x05R\vcolumnCount\x12\x1b\n" +
	"\trow_count\x18\x06 \x01(\x05R\browCount\x12E\n" +
	"\x11start_time_offset\x18\a \x01(\v2\x19.google.protobuf.DurationR\x0fstartTimeOffset\x12A\n" +
	"\x0fend_time_offset\x18\b \x01(\v2\x19.google.protobuf.DurationR\rendTimeOffset\x12!\n" +
	"\vtotal_count\x18\t \x01(\x05H\x00R\n" +
	"totalCount\x127\n" +
	"\binterval\x18\n" +
	" \x01(\v2\x19.google.protobuf.DurationH\x00R\binterval\x12\x18\n" +
	"\aquality\x18\v \x01(\x05R\aqualityB\x15\n" +
	"\x13extraction_strategy\"\xf4\n" +
	"\n" +
	"\aOverlay\x12L\n" +
	"\x05image\x18\x01 \x01(\v26.google.events.cloud.video.transcoder.v1.Overlay.ImageR\x05image\x12Z\n" +
	"\n" +
	"animations\x18\x02 \x03(\v2:.google.events.cloud.video.transcoder.v1.Overlay.AnimationR\n" +
	"animations\x1a2\n" +
	"\x14NormalizedCoordinate\x12\f\n" +
	"\x01x\x18\x01 \x01(\x01R\x01x\x12\f\n" +
	"\x01y\x18\x02 \x01(\x01R\x01y\x1a\x96\x01\n" +
	"\x05Image\x12\x10\n" +
	"\x03uri\x18\x01 \x01(\tR\x03uri\x12e\n" +
	"\n" +
	"resolution\x18\x02 \x01(\v2E.google.events.cloud.video.transcoder.v1.Overlay.NormalizedCoordinateR\n" +
	"resolution\x12\x14\n" +
	"\x05alpha\x18\x03 \x01(\x01R\x05alpha\x1a\xaf\x01\n" +
	"\x0fAnimationStatic\x12U\n" +
	"\x02xy\x18\x01 \x01(\v2E.google.events.cloud.video.transcoder.v1.Overlay.NormalizedCoordinateR\x02xy\x12E\n" +
	"\x11start_time_offset\x18\x02 \x01(\v2\x19.google.protobuf.DurationR\x0fstartTimeOffset\x1a\xc8\x02\n" +
	"\rAnimationFade\x12V\n" +
	"\tfade_type\x18\x01 \x01(\x0e29.google.events.cloud.video.transcoder.v1.Overlay.FadeTypeR\bfadeType\x12U\n" +
	"\x02xy\x18\x02 \x01(\v2E.google.events.cloud.video.transcoder.v1.Overlay.NormalizedCoordinateR\x02xy\x12E\n" +
	"\x11start_time_offset\x18\x03 \x01(\v2\x19.google.protobuf.DurationR\x0fstartTimeOffset\x12A\n" +
	"\x0fend_time_offset\x18\x04 \x01(\v2\x19.google.protobuf.DurationR\rendTimeOffset\x1aU\n" +
	"\fAnimationEnd\x12E\n" +
	"\x11start_time_offset\x18\x01 \x01(\v2\x19.google.protobuf.DurationR\x0fstartTimeOffset\x1a\xdb\x02\n" +
	"\tAnimation\x12m\n" +
	"\x10animation_static\x18\x01 \x01(\v2@.google.events.cloud.video.transcoder.v1.Overlay.AnimationStaticH\x00R\x0fanimationStatic\x12g\n" +
	"\x0eanimation_fade\x18\x02 \x01(\v2>.google.events.cloud.video.transcoder.v1.Overlay.AnimationFadeH\x00R\ranimationFade\x12d\n" +
	"\ranimation_end\x18\x03 \x01(\v2=.google.events.cloud.video.transcoder.v1.Overlay.AnimationEndH\x00R\fanimationEndB\x10\n" +
	"\x0eanimation_type\"@\n" +
	"\bFadeType\x12\x19\n" +
	"\x15FADE_TYPE_UNSPECIFIED\x10\x00\x12\v\n" +
	"\aFADE_IN\x10\x01\x12\f\n" +
	"\bFADE_OUT\x10\x02\"\xa2\x0e\n" +
	"\x13PreprocessingConfig\x12X\n" +
	"\x05color\x18\x01 \x01(\v2B.google.events.cloud.video.transcoder.v1.PreprocessingConfig.ColorR\x05color\x12^\n" +
	"\adenoise\x18\x02 \x01(\v2D.google.events.cloud.video.transcoder.v1.PreprocessingConfig.DenoiseR\adenoise\x12^\n" +
	"\adeblock\x18\x03 \x01(\v2D.google.events.cloud.video.transcoder.v1.PreprocessingConfig.DeblockR\adeblock\x12X\n" +
	"\x05audio\x18\x04 \x01(\v2B.google.events.cloud.video.transcoder.v1.PreprocessingConfig.AudioR\x05audio\x12U\n" +
	"\x04crop\x18\x05 \x01(\v2A.google.events.cloud.video.transcoder.v1.PreprocessingConfig.CropR\x04crop\x12R\n" +
	"\x03pad\x18\x06 \x01(\v2@.google.events.cloud.video.transcoder.v1.PreprocessingConfig.PadR\x03pad\x12j\n" +
	"\vdeinterlace\x18\a \x01(\v2H.google.events.cloud.video.transcoder.v1.PreprocessingConfig.DeinterlaceR\vdeinterlace\x1ac\n" +
	"\x05Color\x12\x1e\n" +
	"\n" +
	"saturation\x18\x01 \x01(\x01R\n" +
	"saturation\x12\x1a\n" +
	"\bcontrast\x18\x02 \x01(\x01R\bcontrast\x12\x1e\n" +
	"\n" +
	"brightness\x18\x03 \x01(\x01R\n" +
	"brightness\x1a9\n" +
	"\aDenoise\x12\x1a\n" +
	"\bstrength\x18\x01 \x01(\x01R\bstrength\x12\x12\n" +
	"\x04tune\x18\x02 \x01(\tR\x04tune\x1a?\n" +
	"\aDeblock\x12\x1a\n" +
	"\bstrength\x18\x01 \x01(\x01R\bstrength\x12\x18\n" +
	"\aenabled\x18\x02 \x01(\bR\aenabled\x1aW\n" +
	"\x05Audio\x12\x12\n" +
	"\x04lufs\x18\x01 \x01(\x01R\x04lufs\x12\x1d\n" +
	"\n" +
	"high_boost\x18\x02 \x01(\bR\thighBoost\x12\x1b\n" +
	"\tlow_boost\x18\x03 \x01(\bR\blowBoost\x1a\x8e\x01\n" +
	"\x04Crop\x12\x1d\n" +
	"\n" +
	"top_pixels\x18\x01 \x01(\x05R\ttopPixels\x12#\n" +
	"\rbottom_pixels\x18\x02 \x01(\x05R\fbottomPixels\x12\x1f\n" +
	"\vleft_pixels\x18\x03 \x01(\x05R\n" +
	"leftPixels\x12!\n" +
	"\fright_pixels\x18\x04 \x01(\x05R\vrightPixels\x1a\x8d\x01\n" +
	"\x03Pad\x12\x1d\n" +
	"\n" +
	"top_pixels\x18\x01 \x01(\x05R\ttopPixels\x12#\n" +
	"\rbottom_pixels\x18\x02 \x01(\x05R\fbottomPixels\x12\x1f\n" +
	"\vleft_pixels\x18\x03 \x01(\x05R\n" +
	"leftPixels\x12!\n" +
	"\fright_pixels\x18\x04 \x01(\x05R\vrightPixels\x1a\xa4\x04\n" +
	"\vDeinterlace\x12l\n" +
	"\x05yadif\x18\x01 \x01(\v2T.google.events.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace.YadifConfigH\x00R\x05yadif\x12l\n" +
	"\x05bwdif\x18\x02 \x01(\v2T.google.events.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace.BwdifConfigH\x00R\x05bwdif\x1a\xaf\x01\n" +
	"\vYadifConfig\x12\x12\n" +
	"\x04mode\x18\x01 \x01(\tR\x04mode\x12>\n" +
	"\x1bdisable_spatial_interlacing\x18\x02 \x01(\bR\x19disableSpatialInterlacing\x12\x16\n" +
	"\x06parity\x18\x03 \x01(\tR\x06parity\x124\n" +
	"\x16deinterlace_all_frames\x18\x04 \x01(\bR\x14deinterlaceAllFrames\x1ao\n" +
	"\vBwdifConfig\x12\x12\n" +
	"\x04mode\x18\x01 \x01(\tR\x04mode\x12\x16\n" +
	"\x06parity\x18\x02 \x01(\tR\x06parity\x124\n" +
	"\x16deinterlace_all_frames\x18\x03 \x01(\bR\x14deinterlaceAllFramesB\x16\n" +
	"\x14deinterlacing_filter\"\x80\x11\n" +
	"\vVideoStream\x12\\\n" +
	"\x04h264\x18\x01 \x01(\v2F.google.events.cloud.video.transcoder.v1.VideoStream.H264CodecSettingsH\x00R\x04h264\x12\\\n" +
	"\x04h265\x18\x02 \x01(\v2F.google.events.cloud.video.transcoder.v1.VideoStream.H265CodecSettingsH\x00R\x04h265\x12Y\n" +
	"\x03vp9\x18\x03 \x01(\v2E.google.events.cloud.video.transcoder.v1.VideoStream.Vp9CodecSettingsH\x00R\x03vp9\x1a\xe8\x05\n" +
	"\x11H264CodecSettings\x12!\n" +
	"\fwidth_pixels\x18\x01 \x01(\x05R\vwidthPixels\x12#\n" +
	"\rheight_pixels\x18\x02 \x01(\x05R\fheightPixels\x12\x1d\n" +
	"\n" +
	"frame_rate\x18\x03 \x01(\x01R\tframeRate\x12\x1f\n" +
	"\vbitrate_bps\x18\x04 \x01(\x05R\n" +
	"bitrateBps\x12!\n" +
	"\fpixel_format\x18\x05 \x01(\tR\vpixelFormat\x12*\n" +
	"\x11rate_control_mode\x18\x06 \x01(\tR\x0frateControlMode\x12\x1b\n" +
	"\tcrf_level\x18\a \x01(\x05R\bcrfLevel\x12$\n" +
	"\x0eallow_open_gop\x18\b \x01(\bR\fallowOpenGop\x12(\n" +
	"\x0fgop_frame_count\x18\t \x01(\x05H\x00R\rgopFrameCount\x12>\n" +
	"\fgop_duration\x18\n" +
	" \x01(\v2\x19.google.protobuf.DurationH\x00R\vgopDuration\x12&\n" +
	"\x0fenable_two_pass\x18\v \x01(\bR\renableTwoPass\x12\"\n" +
	"\rvbv_size_bits\x18\f \x01(\x05R\vvbvSizeBits\x12*\n" +
	"\x11vbv_fullness_bits\x18\r \x01(\x05R\x0fvbvFullnessBits\x12#\n" +
	"\rentropy_coder\x18\x0e \x01(\tR\fentropyCoder\x12\x1b\n" +
	"\tb_pyramid\x18\x0f \x01(\bR\bbPyramid\x12\"\n" +
	"\rb_frame_count\x18\x10 \x01(\x05R\vbFrameCount\x12\x1f\n" +
	"\vaq_strength\x18\x11 \x01(\x01R\n" +
	"aqStrength\x12\x18\n" +
	"\aprofile\x18\x12 \x01(\tR\aprofile\x12\x12\n" +
	"\x04tune\x18\x13 \x01(\tR\x04tune\x12\x16\n" +
	"\x06preset\x18\x14 \x01(\tR\x06presetB\n" +
	"\n" +
	"\bgop_mode\x1a\xc3\x05\n" +
	"\x11H265CodecSettings\x12!\n" +
	"\fwidth_pixels\x18\x01 \x01(\x05R\vwidthPixels\x12#\n" +
	"\rheight_pixels\x18\x02 \x01(\x05R\fheightPixels\x12\x1d\n" +
	"\n" +
	"frame_rate\x18\x03 \x01(\x01R\tframeRate\x12\x1f\n" +
	"\vbitrate_bps\x18\x04 \x01(\x05R\n" +
	"bitrateBps\x12!\n" +
	"\fpixel_format\x18\x05 \x01(\tR\vpixelFormat\x12*\n" +
	"\x11rate_control_mode\x18\x06 \x01(\tR\x0frateControlMode\x12\x1b\n" +
	"\tcrf_level\x18\a \x01(\x05R\bcrfLevel\x12$\n" +
	"\x0eallow_open_gop\x18\b \x01(\bR\fallowOpenGop\x12(\n" +
	"\x0fgop_frame_count\x18\t \x01(\x05H\x00R\rgopFrameCount\x12>\n" +
	"\fgop_duration\x18\n" +
	" \x01(\v2\x19.google.protobuf.DurationH\x00R\vgopDuration\x12&\n" +
	"\x0fenable_two_pass\x18\v \x01(\bR\renableTwoPass\x12\"\n" +
	"\rvbv_size_bits\x18\f \x01(\x05R\vvbvSizeBits\x12*\n" +
	"\x11vbv_fullness_bits\x18\r \x01(\x05R\x0fvbvFullnessBits\x12\x1b\n" +
	"\tb_pyramid\x18\x0e \x01(\bR\bbPyramid\x12\"\n" +
	"\rb_frame_count\x18\x0f \x01(\x05R\vbFrameCount\x12\x1f\n" +
	"\vaq_strength\x18\x10 \x01(\x01R\n" +
	"aqStrength\x12\x18\n" +
	"\aprofile\x18\x11 \x01(\tR\aprofile\x12\x12\n" +
	"\x04tune\x18\x12 \x01(\tR\x04tune\x12\x16\n" +
	"\x06preset\x18\x13 \x01(\tR\x06presetB\n" +
	"\n" +
	"\bgop_mode\x1a\x96\x03\n" +
	"\x10Vp9CodecSettings\x12!\n" +
	"\fwidth_pixels\x18\x01 \x01(\x05R\vwidthPixels\x12#\n" +
	"\rheight_pixels\x18\x02 \x01(\x05R\fheightPixels\x12\x1d\n" +
	"\n" +
	"frame_rate\x18\x03 \x01(\x01R\tframeRate\x12\x1f\n" +
	"\vbitrate_bps\x18\x04 \x01(\x05R\n" +
	"bitrateBps\x12!\n" +
	"\fpixel_format\x18\x05 \x01(\tR\vpixelFormat\x12*\n" +
	"\x11rate_control_mode\x18\x06 \x01(\tR\x0frateControlMode\x12\x1b\n" +
	"\tcrf_level\x18\a \x01(\x05R\bcrfLevel\x12(\n" +
	"\x0fgop_frame_count\x18\b \x01(\x05H\x00R\rgopFrameCount\x12>\n" +
	"\fgop_duration\x18\t \x01(\v2\x19.google.protobuf.DurationH\x00R\vgopDuration\x12\x18\n" +
	"\aprofile\x18\n" +
	" \x01(\tR\aprofileB\n" +
	"\n" +
	"\bgop_modeB\x10\n" +
	"\x0ecodec_settings\"\xb0\x04\n" +
	"\vAudioStream\x12\x14\n" +
	"\x05codec\x18\x01 \x01(\tR\x05codec\x12\x1f\n" +
	"\vbitrate_bps\x18\x02 \x01(\x05R\n" +
	"bitrateBps\x12#\n" +
	"\rchannel_count\x18\x03 \x01(\x05R\fchannelCount\x12%\n" +
	"\x0echannel_layout\x18\x04 \x03(\tR\rchannelLayout\x12[\n" +
	"\amapping\x18\x05 \x03(\v2A.google.events.cloud.video.transcoder.v1.AudioStream.AudioMappingR\amapping\x12*\n" +
	"\x11sample_rate_hertz\x18\x06 \x01(\x05R\x0fsampleRateHertz\x12#\n" +
	"\rlanguage_code\x18\a \x01(\tR\flanguageCode\x12!\n" +
	"\fdisplay_name\x18\b \x01(\tR\vdisplayName\x1a\xcc\x01\n" +
	"\fAudioMapping\x12\x19\n" +
	"\batom_key\x18\x01 \x01(\tR\aatomKey\x12\x1b\n" +
	"\tinput_key\x18\x02 \x01(\tR\binputKey\x12\x1f\n" +
	"\vinput_track\x18\x03 \x01(\x05R\n" +
	"inputTrack\x12#\n" +
	"\rinput_channel\x18\x04 \x01(\x05R\finputChannel\x12%\n" +
	"\x0eoutput_channel\x18\x05 \x01(\x05R\routputChannel\x12\x17\n" +
	"\again_db\x18\x06 \x01(\x01R\x06gainDb\"\xad\x02\n" +
	"\n" +
	"TextStream\x12\x14\n" +
	"\x05codec\x18\x01 \x01(\tR\x05codec\x12#\n" +
	"\rlanguage_code\x18\x02 \x01(\tR\flanguageCode\x12Y\n" +
	"\amapping\x18\x03 \x03(\v2?.google.events.cloud.video.transcoder.v1.TextStream.TextMappingR\amapping\x12!\n" +
	"\fdisplay_name\x18\x04 \x01(\tR\vdisplayName\x1af\n" +
	"\vTextMapping\x12\x19\n" +
	"\batom_key\x18\x01 \x01(\tR\aatomKey\x12\x1b\n" +
	"\tinput_key\x18\x02 \x01(\tR\binputKey\x12\x1f\n" +
	"\vinput_track\x18\x03 \x01(\x05R\n" +
	"inputTrack\"\x88\x01\n" +
	"\x0fSegmentSettings\x12D\n" +
	"\x10segment_duration\x18\x01 \x01(\v2\x19.google.protobuf.DurationR\x0fsegmentDuration\x12/\n" +
	"\x13individual_segments\x18\x03 \x01(\bR\x12individualSegments\"g\n" +
	"\fJobEventData\x12K\n" +
	"\apayload\x18\x01 \x01(\v2,.google.events.cloud.video.transcoder.v1.JobH\x00R\apayload\x88\x01\x01B\n" +
	"\n" +
	"\b_payload\"w\n" +
	"\x14JobTemplateEventData\x12S\n" +
	"\apayload\x18\x01 \x01(\v24.google.events.cloud.video.transcoder.v1.JobTemplateH\x00R\apayload\x88\x01\x01B\n" +
	"\n" +
	"\b_payloadB\x8c\x01\xaa\x020Google.Events.Protobuf.Cloud.Video.Transcoder.V1\xca\x02'Google\\Events\\Cloud\\Video\\Transcoder\\V1\xea\x02,Google::Events::Cloud::Video::Transcoder::V1b\x06proto3"

var (
	file_cloud_video_transcoder_v1_data_proto_rawDescOnce sync.Once
	file_cloud_video_transcoder_v1_data_proto_rawDescData []byte
)

func file_cloud_video_transcoder_v1_data_proto_rawDescGZIP() []byte {
	file_cloud_video_transcoder_v1_data_proto_rawDescOnce.Do(func() {
		file_cloud_video_transcoder_v1_data_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_cloud_video_transcoder_v1_data_proto_rawDesc), len(file_cloud_video_transcoder_v1_data_proto_rawDesc)))
	})
	return file_cloud_video_transcoder_v1_data_proto_rawDescData
}

var file_cloud_video_transcoder_v1_data_proto_enumTypes = make([]protoimpl.EnumInfo, 4)
var file_cloud_video_transcoder_v1_data_proto_msgTypes = make([]protoimpl.MessageInfo, 42)
var file_cloud_video_transcoder_v1_data_proto_goTypes = []any{
	(Job_ProcessingState)(0),                // 0: google.events.cloud.video.transcoder.v1.Job.ProcessingState
	(Job_ProcessingMode)(0),                 // 1: google.events.cloud.video.transcoder.v1.Job.ProcessingMode
	(Manifest_ManifestType)(0),              // 2: google.events.cloud.video.transcoder.v1.Manifest.ManifestType
	(Overlay_FadeType)(0),                   // 3: google.events.cloud.video.transcoder.v1.Overlay.FadeType
	(*Job)(nil),                             // 4: google.events.cloud.video.transcoder.v1.Job
	(*JobTemplate)(nil),                     // 5: google.events.cloud.video.transcoder.v1.JobTemplate
	(*JobConfig)(nil),                       // 6: google.events.cloud.video.transcoder.v1.JobConfig
	(*Input)(nil),                           // 7: google.events.cloud.video.transcoder.v1.Input
	(*Output)(nil),                          // 8: google.events.cloud.video.transcoder.v1.Output
	(*EditAtom)(nil),                        // 9: google.events.cloud.video.transcoder.v1.EditAtom
	(*AdBreak)(nil),                         // 10: google.events.cloud.video.transcoder.v1.AdBreak
	(*ElementaryStream)(nil),                // 11: google.events.cloud.video.transcoder.v1.ElementaryStream
	(*MuxStream)(nil),                       // 12: google.events.cloud.video.transcoder.v1.MuxStream
	(*Manifest)(nil),                        // 13: google.events.cloud.video.transcoder.v1.Manifest
	(*PubsubDestination)(nil),               // 14: google.events.cloud.video.transcoder.v1.PubsubDestination
	(*SpriteSheet)(nil),                     // 15: google.events.cloud.video.transcoder.v1.SpriteSheet
	(*Overlay)(nil),                         // 16: google.events.cloud.video.transcoder.v1.Overlay
	(*PreprocessingConfig)(nil),             // 17: google.events.cloud.video.transcoder.v1.PreprocessingConfig
	(*VideoStream)(nil),                     // 18: google.events.cloud.video.transcoder.v1.VideoStream
	(*AudioStream)(nil),                     // 19: google.events.cloud.video.transcoder.v1.AudioStream
	(*TextStream)(nil),                      // 20: google.events.cloud.video.transcoder.v1.TextStream
	(*SegmentSettings)(nil),                 // 21: google.events.cloud.video.transcoder.v1.SegmentSettings
	(*JobEventData)(nil),                    // 22: google.events.cloud.video.transcoder.v1.JobEventData
	(*JobTemplateEventData)(nil),            // 23: google.events.cloud.video.transcoder.v1.JobTemplateEventData
	nil,                                     // 24: google.events.cloud.video.transcoder.v1.Job.LabelsEntry
	nil,                                     // 25: google.events.cloud.video.transcoder.v1.JobTemplate.LabelsEntry
	(*Overlay_NormalizedCoordinate)(nil),    // 26: google.events.cloud.video.transcoder.v1.Overlay.NormalizedCoordinate
	(*Overlay_Image)(nil),                   // 27: google.events.cloud.video.transcoder.v1.Overlay.Image
	(*Overlay_AnimationStatic)(nil),         // 28: google.events.cloud.video.transcoder.v1.Overlay.AnimationStatic
	(*Overlay_AnimationFade)(nil),           // 29: google.events.cloud.video.transcoder.v1.Overlay.AnimationFade
	(*Overlay_AnimationEnd)(nil),            // 30: google.events.cloud.video.transcoder.v1.Overlay.AnimationEnd
	(*Overlay_Animation)(nil),               // 31: google.events.cloud.video.transcoder.v1.Overlay.Animation
	(*PreprocessingConfig_Color)(nil),       // 32: google.events.cloud.video.transcoder.v1.PreprocessingConfig.Color
	(*PreprocessingConfig_Denoise)(nil),     // 33: google.events.cloud.video.transcoder.v1.PreprocessingConfig.Denoise
	(*PreprocessingConfig_Deblock)(nil),     // 34: google.events.cloud.video.transcoder.v1.PreprocessingConfig.Deblock
	(*PreprocessingConfig_Audio)(nil),       // 35: google.events.cloud.video.transcoder.v1.PreprocessingConfig.Audio
	(*PreprocessingConfig_Crop)(nil),        // 36: google.events.cloud.video.transcoder.v1.PreprocessingConfig.Crop
	(*PreprocessingConfig_Pad)(nil),         // 37: google.events.cloud.video.transcoder.v1.PreprocessingConfig.Pad
	(*PreprocessingConfig_Deinterlace)(nil), // 38: google.events.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace
	(*PreprocessingConfig_Deinterlace_YadifConfig)(nil), // 39: google.events.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace.YadifConfig
	(*PreprocessingConfig_Deinterlace_BwdifConfig)(nil), // 40: google.events.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace.BwdifConfig
	(*VideoStream_H264CodecSettings)(nil),               // 41: google.events.cloud.video.transcoder.v1.VideoStream.H264CodecSettings
	(*VideoStream_H265CodecSettings)(nil),               // 42: google.events.cloud.video.transcoder.v1.VideoStream.H265CodecSettings
	(*VideoStream_Vp9CodecSettings)(nil),                // 43: google.events.cloud.video.transcoder.v1.VideoStream.Vp9CodecSettings
	(*AudioStream_AudioMapping)(nil),                    // 44: google.events.cloud.video.transcoder.v1.AudioStream.AudioMapping
	(*TextStream_TextMapping)(nil),                      // 45: google.events.cloud.video.transcoder.v1.TextStream.TextMapping
	(*timestamppb.Timestamp)(nil),                       // 46: google.protobuf.Timestamp
	(*status.Status)(nil),                               // 47: google.rpc.Status
	(*durationpb.Duration)(nil),                         // 48: google.protobuf.Duration
}
var file_cloud_video_transcoder_v1_data_proto_depIdxs = []int32{
	6,  // 0: google.events.cloud.video.transcoder.v1.Job.config:type_name -> google.events.cloud.video.transcoder.v1.JobConfig
	0,  // 1: google.events.cloud.video.transcoder.v1.Job.state:type_name -> google.events.cloud.video.transcoder.v1.Job.ProcessingState
	46, // 2: google.events.cloud.video.transcoder.v1.Job.create_time:type_name -> google.protobuf.Timestamp
	46, // 3: google.events.cloud.video.transcoder.v1.Job.start_time:type_name -> google.protobuf.Timestamp
	46, // 4: google.events.cloud.video.transcoder.v1.Job.end_time:type_name -> google.protobuf.Timestamp
	24, // 5: google.events.cloud.video.transcoder.v1.Job.labels:type_name -> google.events.cloud.video.transcoder.v1.Job.LabelsEntry
	47, // 6: google.events.cloud.video.transcoder.v1.Job.error:type_name -> google.rpc.Status
	1,  // 7: google.events.cloud.video.transcoder.v1.Job.mode:type_name -> google.events.cloud.video.transcoder.v1.Job.ProcessingMode
	6,  // 8: google.events.cloud.video.transcoder.v1.JobTemplate.config:type_name -> google.events.cloud.video.transcoder.v1.JobConfig
	25, // 9: google.events.cloud.video.transcoder.v1.JobTemplate.labels:type_name -> google.events.cloud.video.transcoder.v1.JobTemplate.LabelsEntry
	7,  // 10: google.events.cloud.video.transcoder.v1.JobConfig.inputs:type_name -> google.events.cloud.video.transcoder.v1.Input
	9,  // 11: google.events.cloud.video.transcoder.v1.JobConfig.edit_list:type_name -> google.events.cloud.video.transcoder.v1.EditAtom
	11, // 12: google.events.cloud.video.transcoder.v1.JobConfig.elementary_streams:type_name -> google.events.cloud.video.transcoder.v1.ElementaryStream
	12, // 13: google.events.cloud.video.transcoder.v1.JobConfig.mux_streams:type_name -> google.events.cloud.video.transcoder.v1.MuxStream
	13, // 14: google.events.cloud.video.transcoder.v1.JobConfig.manifests:type_name -> google.events.cloud.video.transcoder.v1.Manifest
	8,  // 15: google.events.cloud.video.transcoder.v1.JobConfig.output:type_name -> google.events.cloud.video.transcoder.v1.Output
	10, // 16: google.events.cloud.video.transcoder.v1.JobConfig.ad_breaks:type_name -> google.events.cloud.video.transcoder.v1.AdBreak
	14, // 17: google.events.cloud.video.transcoder.v1.JobConfig.pubsub_destination:type_name -> google.events.cloud.video.transcoder.v1.PubsubDestination
	15, // 18: google.events.cloud.video.transcoder.v1.JobConfig.sprite_sheets:type_name -> google.events.cloud.video.transcoder.v1.SpriteSheet
	16, // 19: google.events.cloud.video.transcoder.v1.JobConfig.overlays:type_name -> google.events.cloud.video.transcoder.v1.Overlay
	17, // 20: google.events.cloud.video.transcoder.v1.Input.preprocessing_config:type_name -> google.events.cloud.video.transcoder.v1.PreprocessingConfig
	48, // 21: google.events.cloud.video.transcoder.v1.EditAtom.end_time_offset:type_name -> google.protobuf.Duration
	48, // 22: google.events.cloud.video.transcoder.v1.EditAtom.start_time_offset:type_name -> google.protobuf.Duration
	48, // 23: google.events.cloud.video.transcoder.v1.AdBreak.start_time_offset:type_name -> google.protobuf.Duration
	18, // 24: google.events.cloud.video.transcoder.v1.ElementaryStream.video_stream:type_name -> google.events.cloud.video.transcoder.v1.VideoStream
	19, // 25: google.events.cloud.video.transcoder.v1.ElementaryStream.audio_stream:type_name -> google.events.cloud.video.transcoder.v1.AudioStream
	20, // 26: google.events.cloud.video.transcoder.v1.ElementaryStream.text_stream:type_name -> google.events.cloud.video.transcoder.v1.TextStream
	21, // 27: google.events.cloud.video.transcoder.v1.MuxStream.segment_settings:type_name -> google.events.cloud.video.transcoder.v1.SegmentSettings
	2,  // 28: google.events.cloud.video.transcoder.v1.Manifest.type:type_name -> google.events.cloud.video.transcoder.v1.Manifest.ManifestType
	48, // 29: google.events.cloud.video.transcoder.v1.SpriteSheet.start_time_offset:type_name -> google.protobuf.Duration
	48, // 30: google.events.cloud.video.transcoder.v1.SpriteSheet.end_time_offset:type_name -> google.protobuf.Duration
	48, // 31: google.events.cloud.video.transcoder.v1.SpriteSheet.interval:type_name -> google.protobuf.Duration
	27, // 32: google.events.cloud.video.transcoder.v1.Overlay.image:type_name -> google.events.cloud.video.transcoder.v1.Overlay.Image
	31, // 33: google.events.cloud.video.transcoder.v1.Overlay.animations:type_name -> google.events.cloud.video.transcoder.v1.Overlay.Animation
	32, // 34: google.events.cloud.video.transcoder.v1.PreprocessingConfig.color:type_name -> google.events.cloud.video.transcoder.v1.PreprocessingConfig.Color
	33, // 35: google.events.cloud.video.transcoder.v1.PreprocessingConfig.denoise:type_name -> google.events.cloud.video.transcoder.v1.PreprocessingConfig.Denoise
	34, // 36: google.events.cloud.video.transcoder.v1.PreprocessingConfig.deblock:type_name -> google.events.cloud.video.transcoder.v1.PreprocessingConfig.Deblock
	35, // 37: google.events.cloud.video.transcoder.v1.PreprocessingConfig.audio:type_name -> google.events.cloud.video.transcoder.v1.PreprocessingConfig.Audio
	36, // 38: google.events.cloud.video.transcoder.v1.PreprocessingConfig.crop:type_name -> google.events.cloud.video.transcoder.v1.PreprocessingConfig.Crop
	37, // 39: google.events.cloud.video.transcoder.v1.PreprocessingConfig.pad:type_name -> google.events.cloud.video.transcoder.v1.PreprocessingConfig.Pad
	38, // 40: google.events.cloud.video.transcoder.v1.PreprocessingConfig.deinterlace:type_name -> google.events.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace
	41, // 41: google.events.cloud.video.transcoder.v1.VideoStream.h264:type_name -> google.events.cloud.video.transcoder.v1.VideoStream.H264CodecSettings
	42, // 42: google.events.cloud.video.transcoder.v1.VideoStream.h265:type_name -> google.events.cloud.video.transcoder.v1.VideoStream.H265CodecSettings
	43, // 43: google.events.cloud.video.transcoder.v1.VideoStream.vp9:type_name -> google.events.cloud.video.transcoder.v1.VideoStream.Vp9CodecSettings
	44, // 44: google.events.cloud.video.transcoder.v1.AudioStream.mapping:type_name -> google.events.cloud.video.transcoder.v1.AudioStream.AudioMapping
	45, // 45: google.events.cloud.video.transcoder.v1.TextStream.mapping:type_name -> google.events.cloud.video.transcoder.v1.TextStream.TextMapping
	48, // 46: google.events.cloud.video.transcoder.v1.SegmentSettings.segment_duration:type_name -> google.protobuf.Duration
	4,  // 47: google.events.cloud.video.transcoder.v1.JobEventData.payload:type_name -> google.events.cloud.video.transcoder.v1.Job
	5,  // 48: google.events.cloud.video.transcoder.v1.JobTemplateEventData.payload:type_name -> google.events.cloud.video.transcoder.v1.JobTemplate
	26, // 49: google.events.cloud.video.transcoder.v1.Overlay.Image.resolution:type_name -> google.events.cloud.video.transcoder.v1.Overlay.NormalizedCoordinate
	26, // 50: google.events.cloud.video.transcoder.v1.Overlay.AnimationStatic.xy:type_name -> google.events.cloud.video.transcoder.v1.Overlay.NormalizedCoordinate
	48, // 51: google.events.cloud.video.transcoder.v1.Overlay.AnimationStatic.start_time_offset:type_name -> google.protobuf.Duration
	3,  // 52: google.events.cloud.video.transcoder.v1.Overlay.AnimationFade.fade_type:type_name -> google.events.cloud.video.transcoder.v1.Overlay.FadeType
	26, // 53: google.events.cloud.video.transcoder.v1.Overlay.AnimationFade.xy:type_name -> google.events.cloud.video.transcoder.v1.Overlay.NormalizedCoordinate
	48, // 54: google.events.cloud.video.transcoder.v1.Overlay.AnimationFade.start_time_offset:type_name -> google.protobuf.Duration
	48, // 55: google.events.cloud.video.transcoder.v1.Overlay.AnimationFade.end_time_offset:type_name -> google.protobuf.Duration
	48, // 56: google.events.cloud.video.transcoder.v1.Overlay.AnimationEnd.start_time_offset:type_name -> google.protobuf.Duration
	28, // 57: google.events.cloud.video.transcoder.v1.Overlay.Animation.animation_static:type_name -> google.events.cloud.video.transcoder.v1.Overlay.AnimationStatic
	29, // 58: google.events.cloud.video.transcoder.v1.Overlay.Animation.animation_fade:type_name -> google.events.cloud.video.transcoder.v1.Overlay.AnimationFade
	30, // 59: google.events.cloud.video.transcoder.v1.Overlay.Animation.animation_end:type_name -> google.events.cloud.video.transcoder.v1.Overlay.AnimationEnd
	39, // 60: google.events.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace.yadif:type_name -> google.events.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace.YadifConfig
	40, // 61: google.events.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace.bwdif:type_name -> google.events.cloud.video.transcoder.v1.PreprocessingConfig.Deinterlace.BwdifConfig
	48, // 62: google.events.cloud.video.transcoder.v1.VideoStream.H264CodecSettings.gop_duration:type_name -> google.protobuf.Duration
	48, // 63: google.events.cloud.video.transcoder.v1.VideoStream.H265CodecSettings.gop_duration:type_name -> google.protobuf.Duration
	48, // 64: google.events.cloud.video.transcoder.v1.VideoStream.Vp9CodecSettings.gop_duration:type_name -> google.protobuf.Duration
	65, // [65:65] is the sub-list for method output_type
	65, // [65:65] is the sub-list for method input_type
	65, // [65:65] is the sub-list for extension type_name
	65, // [65:65] is the sub-list for extension extendee
	0,  // [0:65] is the sub-list for field type_name
}

func init() { file_cloud_video_transcoder_v1_data_proto_init() }
func file_cloud_video_transcoder_v1_data_proto_init() {
	if File_cloud_video_transcoder_v1_data_proto != nil {
		return
	}
	file_cloud_video_transcoder_v1_data_proto_msgTypes[0].OneofWrappers = []any{
		(*Job_Config)(nil),
	}
	file_cloud_video_transcoder_v1_data_proto_msgTypes[7].OneofWrappers = []any{
		(*ElementaryStream_VideoStream)(nil),
		(*ElementaryStream_AudioStream)(nil),
		(*ElementaryStream_TextStream)(nil),
	}
	file_cloud_video_transcoder_v1_data_proto_msgTypes[11].OneofWrappers = []any{
		(*SpriteSheet_TotalCount)(nil),
		(*SpriteSheet_Interval)(nil),
	}
	file_cloud_video_transcoder_v1_data_proto_msgTypes[14].OneofWrappers = []any{
		(*VideoStream_H264)(nil),
		(*VideoStream_H265)(nil),
		(*VideoStream_Vp9)(nil),
	}
	file_cloud_video_transcoder_v1_data_proto_msgTypes[18].OneofWrappers = []any{}
	file_cloud_video_transcoder_v1_data_proto_msgTypes[19].OneofWrappers = []any{}
	file_cloud_video_transcoder_v1_data_proto_msgTypes[27].OneofWrappers = []any{
		(*Overlay_Animation_AnimationStatic)(nil),
		(*Overlay_Animation_AnimationFade)(nil),
		(*Overlay_Animation_AnimationEnd)(nil),
	}
	file_cloud_video_transcoder_v1_data_proto_msgTypes[34].OneofWrappers = []any{
		(*PreprocessingConfig_Deinterlace_Yadif)(nil),
		(*PreprocessingConfig_Deinterlace_Bwdif)(nil),
	}
	file_cloud_video_transcoder_v1_data_proto_msgTypes[37].OneofWrappers = []any{
		(*VideoStream_H264CodecSettings_GopFrameCount)(nil),
		(*VideoStream_H264CodecSettings_GopDuration)(nil),
	}
	file_cloud_video_transcoder_v1_data_proto_msgTypes[38].OneofWrappers = []any{
		(*VideoStream_H265CodecSettings_GopFrameCount)(nil),
		(*VideoStream_H265CodecSettings_GopDuration)(nil),
	}
	file_cloud_video_transcoder_v1_data_proto_msgTypes[39].OneofWrappers = []any{
		(*VideoStream_Vp9CodecSettings_GopFrameCount)(nil),
		(*VideoStream_Vp9CodecSettings_GopDuration)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_cloud_video_transcoder_v1_data_proto_rawDesc), len(file_cloud_video_transcoder_v1_data_proto_rawDesc)),
			NumEnums:      4,
			NumMessages:   42,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_cloud_video_transcoder_v1_data_proto_goTypes,
		DependencyIndexes: file_cloud_video_transcoder_v1_data_proto_depIdxs,
		EnumInfos:         file_cloud_video_transcoder_v1_data_proto_enumTypes,
		MessageInfos:      file_cloud_video_transcoder_v1_data_proto_msgTypes,
	}.Build()
	File_cloud_video_transcoder_v1_data_proto = out.File
	file_cloud_video_transcoder_v1_data_proto_goTypes = nil
	file_cloud_video_transcoder_v1_data_proto_depIdxs = nil
}
